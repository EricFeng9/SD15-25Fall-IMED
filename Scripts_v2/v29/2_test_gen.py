# -*- coding: utf-8 -*-
"""
ç”Ÿæˆæ¨ç†è„šæœ¬ (å¯¹åº” 1_train_v2.py)
--------------------------------------
åŠŸèƒ½ï¼š
1. è¯»å–æŒ‡å®šçš„è¡€ç®¡åˆ†å‰²å›¾ (å¦‚ vessel_masks_FIVES_0)
2. æ ¹æ®æŒ‡å®šçš„ mode (cf æˆ– fa) å’Œ --nameï¼Œè‡ªåŠ¨åŠ è½½å¯¹åº”çš„ best_checkpoint (UNet LoRA + ControlNet)
3. æŒ‰ç…§åŸæ–‡ä»¶ååˆ›å»ºå­æ–‡ä»¶å¤¹
4. åœ¨å­æ–‡ä»¶å¤¹ä¸­ç”Ÿæˆ cf_gen.png æˆ– fa_gen.pngï¼Œå¹¶å¤åˆ¶ä¿å­˜åŸåˆ†å‰²å›¾ seg.png
"""

import os
import glob
import argparse
import numpy as np
import torch
import cv2
import shutil
import random
from PIL import Image
from diffusers import (StableDiffusionControlNetPipeline, ControlNetModel, 
                       DDPMScheduler, AutoencoderKL, UNet2DConditionModel)
from transformers import CLIPTextModel, CLIPTokenizer
from peft import PeftModel
from torchvision import transforms

try:
    from tqdm import tqdm
except ImportError:
    tqdm = None

# ============ å…¨å±€é…ç½® ============
SIZE = 512
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# è·Ÿ 1_train_v2.py å¯¹é½çš„åŸºå‡†è·¯å¾„
BASE_MODEL_DIR = "/data/student/Fengjunming/SDXL_ControlNet/models/sd15-diffusers"
VAE_MODEL_PATH = "/data/student/Fengjunming/SDXL_ControlNet/models/sd-vae-ft-mse"
TRAIN_OUT_ROOT = "/data/student/Fengjunming/SDXL_ControlNet/results/out_ctrl_sd15_vessel2img"

# æ¨ç†è¾“å‡ºå­˜æ”¾æ ¹ç›®å½•
PRED_OUT_ROOT = "/data/student/Fengjunming/SDXL_ControlNet/results/out_preds_sd15_vessel2img"

def get_medical_prompt(mode):
    if mode == 'fa':
        return "fluorescein angiography, retinal fundus vessel, medical imaging, high contrast, monochrome"
    else:
        return "color fundus photography, retinal image, medical photography"

def add_realistic_fundus_noise(img_pil, noise_level=0.02):
    """
    æ·»åŠ ä¼ æ„Ÿå™¨å™ªå£°ï¼Œæ¢å¤çœŸå®å›¾åƒçš„é¢—ç²’æ„Ÿ
    """
    img_np = np.array(img_pil).astype(np.float32) / 255.0

    # 1. é«˜æ–¯è¯»å‡ºå™ªå£°
    gaussian = np.random.normal(0, noise_level, img_np.shape)
    noisy = img_np + gaussian

    # 2. è½»å¾®è‰²å½©é€šé“åç§»
    for c in range(3):
        shift = np.random.uniform(-0.003, 0.003)
        noisy[:, :, c] += shift

    noisy = np.clip(noisy * 255, 0, 255).astype(np.uint8)
    return Image.fromarray(noisy)

def main():
    parser = argparse.ArgumentParser(description="å¯¹åº” 1_train_v2.py çš„æµ‹è¯•/ç”Ÿæˆè„šæœ¬")
    parser.add_argument("--mode", type=str, choices=["cf", "fa"], required=True, 
                        help="ç”Ÿæˆçš„ç›®æ ‡æ¨¡å¼")
    parser.add_argument("-n", "--name", type=str, required=True,
                        help="è®­ç»ƒæ—¶çš„å®éªŒåç§° (--name)")
    parser.add_argument("--save_dir", type=str, required=True,
                        help="é¢„æµ‹è¾“å‡ºçš„ä¿å­˜æ‰¹æ¬¡æ–‡ä»¶å¤¹åç§°ï¼Œä¾‹å¦‚ 'run_1'")
    parser.add_argument("--mask_dir", type=str, 
                        default=os.path.join(os.path.dirname(__file__), "vessel_masks_FIVES_0"),
                        help="è¡€ç®¡åˆ†å‰²å›¾æ‰€åœ¨çš„ç›®å½•")
    
    # ç”Ÿæˆå‚æ•°
    parser.add_argument("--steps", type=int, default=50)
    parser.add_argument("--cfg", type=float, default=3.5)
    parser.add_argument("--scribble_scale", type=float, default=1.0)
    parser.add_argument("--add_sensor_noise", action="store_true", help="æ˜¯å¦åå¤„ç†åŠ ä¸Šä¼ æ„Ÿå™¨çš„å¾®ç²’å™ªå£°")
    parser.add_argument("--seed", type=int, default=42)
    args = parser.parse_args()

    # è¾“å‡ºç›®å½• (å¯¹åº” PRED_OUT_ROOT / mode / name / save_dir)
    out_dir = os.path.join(PRED_OUT_ROOT, args.mode, args.name, args.save_dir)
    os.makedirs(out_dir, exist_ok=True)
    
    print(f"\n========== é…ç½®ä¿¡æ¯ ==========")
    print(f"æ¨¡å¼: {args.mode}")
    print(f"æ¨¡å‹åç§°: {args.name}")
    print(f"è¾“å…¥åˆ†å‰²ç›®å½•: {args.mask_dir}")
    print(f"è¾“å‡ºæ ¹ç›®å½•: {out_dir}")
    print(f"ç”Ÿæˆå‚æ•°: steps={args.steps}, cfg={args.cfg}, scribble_scale={args.scribble_scale}, noise={args.add_sensor_noise}")

    # ============ åŠ è½½æ¨¡å‹ ============
    ckpt_dir = os.path.join(TRAIN_OUT_ROOT, args.mode, args.name, "best_checkpoint")
    lora_path = os.path.join(ckpt_dir, "unet_lora")
    cn_path = os.path.join(ckpt_dir, "controlnet_scribble")

    if not os.path.exists(ckpt_dir):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°å¯¹åº”çš„ checkpoint ç›®å½•: {ckpt_dir}\nè¯·ç¡®è®¤è®­ç»ƒä»»åŠ¡æ˜¯å¦æˆåŠŸæŠ¥é”™ best_checkpointã€‚")

    print(f"\n========== åŠ è½½æ¨¡å‹ ==========")
    # åŸºç¡€æ¨¡å‹
    tokenizer = CLIPTokenizer.from_pretrained(BASE_MODEL_DIR, subfolder="tokenizer")
    text_encoder = CLIPTextModel.from_pretrained(BASE_MODEL_DIR, subfolder="text_encoder").to(DEVICE)
    vae = AutoencoderKL.from_pretrained(VAE_MODEL_PATH).to(DEVICE)
    unet_base = UNet2DConditionModel.from_pretrained(BASE_MODEL_DIR, subfolder="unet").to(DEVICE)
    
    vae.requires_grad_(False)
    text_encoder.requires_grad_(False)
    unet_base.requires_grad_(False)

    # UNet LoRA
    if os.path.isdir(lora_path):
        print(f"-> æ­£åœ¨åŠ è½½ UNet LoRA: {lora_path}")
        unet_lora = PeftModel.from_pretrained(unet_base, lora_path)
        unet_for_pipe = unet_lora.base_model
    else:
        print(f"-> æœªæ‰¾åˆ° UNet LoRA: {lora_path}, ä½¿ç”¨åŸå§‹ UNet")
        unet_for_pipe = unet_base

    # Scribble ControlNet
    print(f"-> æ­£åœ¨åŠ è½½ ControlNet: {cn_path}")
    controlnet = ControlNetModel.from_pretrained(cn_path, torch_dtype=torch.float32).to(DEVICE)
    controlnet.eval()
    
    noise_scheduler = DDPMScheduler.from_pretrained(BASE_MODEL_DIR, subfolder="scheduler")

    pipe = StableDiffusionControlNetPipeline(
        vae=vae,
        text_encoder=text_encoder,
        tokenizer=tokenizer,
        unet=unet_for_pipe,
        controlnet=controlnet,
        scheduler=noise_scheduler,
        safety_checker=None,
        feature_extractor=None
    ).to(DEVICE)
    pipe.set_progress_bar_config(disable=True)

    print("âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼å¼€å§‹ç”Ÿæˆ...")

    # ============ å¤„ç†å›¾åƒ ============
    mask_files = glob.glob(os.path.join(args.mask_dir, "*.png")) + glob.glob(os.path.join(args.mask_dir, "*.jpg"))
    if not mask_files:
        raise FileNotFoundError(f"åœ¨ç›®å½• {args.mask_dir} ä¸‹æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")

    prompt = get_medical_prompt(args.mode)
    generator = torch.Generator(device=DEVICE).manual_seed(args.seed)

    mask_files = sorted(mask_files)
    if tqdm is not None:
        mask_files_iter = tqdm(mask_files, desc="ç”Ÿæˆè¿›åº¦", ncols=80)
    else:
        mask_files_iter = mask_files

    for i, mask_file in enumerate(mask_files_iter):
        filename = os.path.basename(mask_file)
        basename = os.path.splitext(filename)[0]

        # ä¸ºè¿™å¹…å›¾åˆ›å»ºä¸“å±æ–‡ä»¶å¤¹
        item_out_dir = os.path.join(out_dir, basename)
        os.makedirs(item_out_dir, exist_ok=True)

        img_out_name = "fa_gen.png" if args.mode == 'fa' else "cf_gen.png"
        img_out_path = os.path.join(item_out_dir, img_out_name)
        seg_out_path = os.path.join(item_out_dir, "seg.png")

        # 1. æ‹·è´åŸå§‹åˆ†å‰²å›¾(ä»¥é˜²æœªäºŒå€¼åŒ–çš„å›¾ä¸¢å¤±ä¿¡æ¯)
        shutil.copy(mask_file, seg_out_path)

        # 2. è¯»å–åˆ†å‰²å›¾å¹¶äºŒå€¼åŒ– (å¯¹é½ 1_train_v2.py)
        mask_pil = Image.open(mask_file).convert("RGB")
        mask_pil = mask_pil.resize((SIZE, SIZE), Image.NEAREST)
        mask_np = np.array(mask_pil)
        
        # åº”ç”¨äºŒå€¼åŒ–ç¡¬æ©ç ï¼Œè¿‡æ»¤æ‰ä½æ¦‚ç‡ç°è¾¹ï¼Œé˜²æ­¢è¡€ç®¡æ³›åŒ–è¿‡ç²—
        mask_np = np.where(mask_np > 80, 255, 0).astype(np.uint8)
        cond_pil = Image.fromarray(mask_np)

        # 3. æ¨ç†ç”Ÿæˆ
        with torch.no_grad():
            output_img = pipe(
                prompt=prompt,
                image=cond_pil,
                num_inference_steps=args.steps,
                guidance_scale=args.cfg,
                controlnet_conditioning_scale=args.scribble_scale,
                generator=generator,
                width=SIZE,
                height=SIZE
            ).images[0]

        # 4. (å¯é€‰) å¢åŠ åå¤„ç†ä¼ æ„Ÿå™¨å™ªå£°ï¼Œå¢åŠ è´¨æ„Ÿ
        if args.add_sensor_noise:
            noise_level = random.uniform(0.01, 0.03)
            output_img = add_realistic_fundus_noise(output_img, noise_level)

        # 5. ä¿å­˜ç”Ÿæˆçš„å›¾åƒ
        output_img.save(img_out_path)

        if tqdm is None and (i + 1) % 10 == 0:
            print(f"[{i + 1}/{len(mask_files)}] å¤„ç†å®Œæˆ: {basename}")

    print(f"\nğŸ‰ æ‰¹é‡ç”Ÿæˆå…¨éƒ¨å®Œæˆï¼\nç»“æœä¿å­˜åœ¨ç›®å½•: {out_dir}")

if __name__ == '__main__':
    main()
