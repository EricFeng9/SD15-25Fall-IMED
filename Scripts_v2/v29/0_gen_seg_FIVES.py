# -*- coding: utf-8 -*-
"""
è¡€ç®¡åˆ†å‰²å›¾ç”Ÿæˆè„šæœ¬ - FIVESæ•°æ®é›†ç‰ˆæœ¬
-------------------
åŠŸèƒ½ï¼š
- è¯»å– FIVES æ•°æ®é›†ä¸­çš„æ‰€æœ‰ CF å›¾åƒ
- è°ƒç”¨ FSG-Net-pytorch æ¨¡å‹è¿›è¡Œè¡€ç®¡åˆ†å‰²
- å°†åˆ†å‰²å›¾ä¿å­˜åœ¨å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ä¸‹çš„ vessel_masks_FIVES æ–‡ä»¶å¤¹ä¸­
- æ–‡ä»¶åä¿å­˜ä¸º [åŸå›¾ç¼–å·]_seg.png ï¼ˆä¾‹å¦‚ 1_A_seg.pngï¼‰
"""

import os
import glob
import torch
import numpy as np
import cv2
from PIL import Image
from torchvision import transforms
from tqdm import tqdm
import sys

# ============ è·¯å¾„é…ç½® ============
# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
DATA_ROOT = os.path.join(PROJECT_ROOT, "data/FIVES_extract_origin")
OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "vessel_masks_FIVES")
FSG_NET_DIR = os.path.join(PROJECT_ROOT, "FSG-Net-pytorch")
MODEL_PATH = os.path.join(FSG_NET_DIR, "FSG-Net-HRF.pt")

# æ·»åŠ FSG-Netè·¯å¾„åˆ°sys.path
sys.path.insert(0, FSG_NET_DIR)

# å¯¼å…¥FSG-Netç›¸å…³æ¨¡å—
from models import model_implements

def get_model():
    """åŠ è½½FSG-Netæ¨¡å‹"""
    print(f"Loading FSG-Net model from {MODEL_PATH} ...")
    
    # åˆ›å»ºå‚æ•°å¯¹è±¡
    class Args:
        model_name = 'FSGNet'  # ä½¿ç”¨å®Œæ•´ç‰ˆFSGNetï¼ˆå¸¦GRMï¼‰
        n_classes = 1
        in_channels = 3
        input_channel = 3
    
    args = Args()
    
    # åˆå§‹åŒ–æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = getattr(model_implements, args.model_name)(**vars(args)).to(device)
    model = torch.nn.DataParallel(model)
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    state_dict = torch.load(MODEL_PATH, map_location=device)
    model.load_state_dict(state_dict)
    print("âœ… Model loaded successfully!")
    
    model.eval()
    return model

def process_and_save():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    model = get_model()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 1. æ”¶é›†æ‰€æœ‰ CF å›¾åƒ
    print("ğŸ“‚ æ‰«æFIVESæ•°æ®é›†...")
    all_cf_paths = []
    
    # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(DATA_ROOT):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {DATA_ROOT}")
        return
        
    # éå†æ‰€æœ‰å­ç›®å½•ï¼Œæ‰¾åˆ°æ‰€æœ‰çš„*_cf.pngæ–‡ä»¶
    for subdir in sorted(os.listdir(DATA_ROOT)):
        subdir_path = os.path.join(DATA_ROOT, subdir)
        if not os.path.isdir(subdir_path):
            continue
        # åœ¨æ¯ä¸ªå­ç›®å½•ä¸­æŸ¥æ‰¾*_cf.pngæ–‡ä»¶
        cf_files = glob.glob(os.path.join(subdir_path, "*_cf.png"))
        all_cf_paths.extend(cf_files)
        
    print(f"æ‰¾åˆ° {len(all_cf_paths)} å¼  CF å›¾åƒã€‚")

    # 2. åˆ†å‰²ä¸ä¿å­˜
    # FSG-Netä½¿ç”¨æ ‡å‡†ImageNetå½’ä¸€åŒ–
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    with torch.no_grad():
        for cf_path in tqdm(all_cf_paths, desc="æå–è¡€ç®¡å›¾"):
            # è·å–åŸå›¾ç¼–å·ï¼Œä¾‹å¦‚ 1_A_cf.png -> 1_A
            basename = os.path.basename(cf_path).replace('_cf.png', '')
            out_name = f"{basename}_seg_fsgnet.png"
            out_path = os.path.join(OUTPUT_DIR, out_name)
            
            # å¦‚æœå·²ç»å­˜åœ¨å¯ä»¥è·³è¿‡
            if os.path.exists(out_path):
                continue
            
            # è¯»å–å›¾åƒå¹¶å‡†å¤‡è¾“å…¥
            img = Image.open(cf_path).convert("RGB")
            w, h = img.size
            
            # FSG-Netéœ€è¦çš„è¾“å…¥å°ºå¯¸ï¼Œæ ¹æ®é¢„è®­ç»ƒæ¨¡å‹è°ƒæ•´(HRFæ•°æ®é›†ä½¿ç”¨1344x1344)
            # ä¸ºäº†ä¿æŒé•¿å®½æ¯”ï¼Œæˆ‘ä»¬ä½¿ç”¨zero paddingæ–¹å¼
            input_size = 1344
            
            # è®¡ç®—padding
            max_dim = max(w, h)
            scale = input_size / max_dim
            new_w, new_h = int(w * scale), int(h * scale)
            
            # resizeå›¾åƒ
            img_resized = img.resize((new_w, new_h), Image.BILINEAR)
            
            # åˆ›å»ºpaddingåçš„å›¾åƒ
            img_padded = Image.new("RGB", (input_size, input_size), (0, 0, 0))
            # ä¸­å¿ƒæ”¾ç½®
            paste_x = (input_size - new_w) // 2
            paste_y = (input_size - new_h) // 2
            img_padded.paste(img_resized, (paste_x, paste_y))
            
            # è½¬æ¢ä¸ºtensor
            input_tensor = transform(img_padded).unsqueeze(0).to(device)
                
            # æ¨ç†
            preds = model(input_tensor)
            
            # å¤„ç†è¾“å‡º
            # FSG-Netè¾“å‡ºæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª(ä¸»è¾“å‡º)
            if isinstance(preds, (list, tuple)):
                pred_output = preds[0]
            else:
                pred_output = preds
                
            # å°†é¢„æµ‹ (1, 1, H, W) è½¬åŒ–ä¸º numpy array
            # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥ä¿å­˜æ¦‚ç‡å€¼ï¼Œä¸è¿›è¡Œé˜ˆå€¼åŒ–ï¼ˆå¦‚0.5äºŒå€¼åŒ–ï¼‰
            # æ¦‚ç‡å€¼èŒƒå›´ï¼š0.0-1.0ï¼Œä¼šè¢«æ˜ å°„åˆ° 0-255 çš„ç°åº¦å€¼
            pred_mask = pred_output.squeeze().cpu().numpy()
            
            # å»é™¤paddingï¼Œæ¢å¤åˆ°resizeåçš„å°ºå¯¸
            pred_mask_crop = pred_mask[paste_y:paste_y+new_h, paste_x:paste_x+new_w]
            
            # ç›´æ¥è½¬æ¢æ¦‚ç‡å€¼(0-1)åˆ°ç°åº¦å€¼(0-255)ï¼Œä¸è¿›è¡ŒäºŒå€¼åŒ–
            # è¿™æ ·ä¿ç•™äº†æ¨¡å‹å¯¹æ¯ä¸ªåƒç´ çš„ç½®ä¿¡åº¦ä¿¡æ¯
            pred_mask_uint8 = np.clip(pred_mask_crop * 255, 0, 255).astype(np.uint8)
            
            # resizeå›åŸå›¾å°ºå¯¸ï¼Œä½¿ç”¨INTER_LINEARä¿æŒå¹³æ»‘
            pred_mask_final = cv2.resize(pred_mask_uint8, (w, h), interpolation=cv2.INTER_LINEAR)
                
            # ä¿å­˜ä¸ºç°åº¦å›¾ï¼ˆ0-255ï¼‰ï¼Œä¿ç•™å®Œæ•´çš„æ¦‚ç‡ä¿¡æ¯
            cv2.imwrite(out_path, pred_mask_final)

    print("âœ… å¤„ç†å®Œæˆï¼è¡€ç®¡å›¾ä¿å­˜åœ¨:", OUTPUT_DIR)

if __name__ == "__main__":
    process_and_save()
