# -*- coding: utf-8 -*-
"""
çœ¼ç§‘å›¾åƒæ¨¡æ€è½¬æ¢è¯„ä¼°æŒ‡æ ‡æ¨¡å—
ç”¨äºè¯„ä¼°OCTAå›¾åƒä¸CFå›¾åƒä¹‹é—´çš„ç›¸äº’æ¨¡æ€è½¬æ¢å‡†ç¡®åº¦

ã€ç‰ˆæœ¬æ›´æ–°ã€‘v3.0 - ä½¿ç”¨æƒå¨å®ç°çš„å››å¤§æ ¸å¿ƒæŒ‡æ ‡
æœ¬æ¨¡å—åŒ…å«å››ä¸ªæœ€æƒå¨çš„å›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼š
1. PSNR - å³°å€¼ä¿¡å™ªæ¯”ï¼ˆè‡ªåŠ¨æ’é™¤é»‘è‰²è¾¹ç¼˜ï¼‰
2. MS-SSIM - å¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§ï¼ˆåŸºäº pytorch_msssimï¼‰
3. FID - å¼—é›·æ­‡è·ç¦»ï¼ˆåŸºäº Inception v3ï¼Œè‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼‰
4. IS - Inceptionåˆ†æ•°ï¼ˆåŸºäº Inception v3ï¼Œè‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼‰

æ‰€æœ‰æŒ‡æ ‡å‡ä¼šè‡ªåŠ¨å¤„ç†é…å‡†äº§ç”Ÿçš„é»‘è‰²è¾¹ç¼˜åŒºåŸŸï¼ˆborderValue=0ï¼‰

å‚è€ƒå®ç°ï¼š
- PSNR: åŸºäºæ ‡å‡†å…¬å¼ï¼Œå‚è€ƒ scikit-image
- MS-SSIM: pytorch_msssim (https://github.com/VainF/pytorch-msssim)
- FID: åŸºäºæ ‡å‡†Inception v3å®ç°ï¼Œå‚è€ƒ pytorch-fid (https://github.com/mseitzer/pytorch-fid)
- IS: åŸºäºæ ‡å‡†Inception v3å®ç°ï¼Œå‚è€ƒ torch-fidelity (https://github.com/toshas/torch-fidelity)
"""

import numpy as np
from scipy import linalg
import torch
import torch.nn.functional as F
from torchvision import models, transforms
from PIL import Image
import warnings
import os
import time

# Optional OpenCV for mask smoothing
try:
    import cv2  # type: ignore
    _CV2_AVAILABLE = True
except Exception:
    _CV2_AVAILABLE = False

warnings.filterwarnings('ignore')


def _resize_to_shape(image, target_h, target_w):
    """
    å°† image è°ƒæ•´åˆ° (target_h, target_w)ã€‚ä¿æŒé€šé“æ•°ä¸å˜ã€‚
    ä¼˜å…ˆä½¿ç”¨cv2ï¼Œè‹¥ä¸å¯ç”¨åˆ™ä½¿ç”¨PILã€‚
    """
    arr = np.asarray(image)
    if arr.shape[:2] == (target_h, target_w):
        return arr
    if _CV2_AVAILABLE:
        if arr.ndim == 2:
            resized = cv2.resize(arr.astype(np.float32), (target_w, target_h), interpolation=cv2.INTER_LINEAR)
        else:
            # cv2.resize æœŸæœ› (W,H)ï¼Œä¸”å¯¹å¤šé€šé“è‡ªåŠ¨å¤„ç†
            resized = cv2.resize(arr.astype(np.float32), (target_w, target_h), interpolation=cv2.INTER_LINEAR)
        # å°½é‡ä¿æŒåŸdtypeèŒƒå›´
        if arr.dtype == np.uint8:
            resized = np.clip(resized, 0, 255).astype(np.uint8)
        return resized
    else:
        from PIL import Image
        if arr.ndim == 2:
            im = Image.fromarray(arr)
            im = im.resize((target_w, target_h), resample=Image.BILINEAR)
            return np.array(im)
        else:
            im = Image.fromarray(arr)
            im = im.resize((target_w, target_h), resample=Image.BILINEAR)
            return np.array(im)


def _align_pair_by_resize(img_a, img_b):
    """
    è‹¥å°ºå¯¸ä¸åŒï¼Œå°† img_b è°ƒæ•´ä¸ºä¸ img_a ç›¸åŒçš„ (H,W)ã€‚
    è¿”å› (aligned_a, aligned_b)ã€‚
    """
    a = np.asarray(img_a)
    b = np.asarray(img_b)
    ha, wa = a.shape[0], a.shape[1]
    if b.shape[:2] != (ha, wa):
        b = _resize_to_shape(b, ha, wa)
    return a, b


def create_valid_mask(image1, image2, threshold=1):
    """
    åˆ›å»ºæœ‰æ•ˆåƒç´ æ©ç ï¼Œæ’é™¤çº¯é»‘åƒç´ å—ï¼ˆç”¨äºé¿å…é…å‡†è¾¹ç¼˜é»‘è‰²å¡«å……å½±å“è¯„ä¼°ï¼‰
    
    å‚æ•°:
        image1: numpyæ•°ç»„ï¼Œç¬¬ä¸€å¼ å›¾åƒ
        image2: numpyæ•°ç»„ï¼Œç¬¬äºŒå¼ å›¾åƒ
        threshold: floatï¼Œåˆ¤æ–­ä¸ºé»‘è‰²çš„é˜ˆå€¼ï¼ˆåƒç´ å€¼å°äºç­‰äºæ­¤å€¼è§†ä¸ºé»‘è‰²ï¼‰ï¼Œé»˜è®¤1
    
    è¿”å›:
        mask: å¸ƒå°”æ•°ç»„ï¼ŒTrueè¡¨ç¤ºæœ‰æ•ˆåƒç´ ï¼ˆéé»‘è‰²ï¼‰ï¼Œshapeä¸è¾“å…¥å›¾åƒçš„ç©ºé—´ç»´åº¦ä¸€è‡´
    
    è¯´æ˜:
        é…å‡†çŸ©é˜µä¼šåœ¨å›¾åƒè¾¹ç¼˜äº§ç”Ÿé»‘è‰²å¡«å……åŒºåŸŸï¼ˆborderValue=0ï¼‰ï¼Œè¿™äº›åŒºåŸŸä¸åº”å‚ä¸è¯„ä¼°
        åªè¦ä»»ä¸€å›¾åƒçš„åƒç´ ä¸ºçº¯é»‘ï¼Œå°±å°†å…¶æ’é™¤
    """
    image1 = np.asarray(image1)
    image2 = np.asarray(image2)
    
    # å¦‚æœæ˜¯å¤šé€šé“å›¾åƒ (H, W, C)ï¼Œæ£€æŸ¥æ‰€æœ‰é€šé“æ˜¯å¦éƒ½ <= threshold
    if len(image1.shape) == 3:
        black_mask1 = np.all(image1 <= threshold, axis=-1)  # (H, W)
        black_mask2 = np.all(image2 <= threshold, axis=-1)  # (H, W)
    else:  # å•é€šé“å›¾åƒ (H, W)
        black_mask1 = image1 <= threshold
        black_mask2 = image2 <= threshold
    
    # åªè¦ä»»ä¸€å›¾åƒæ˜¯é»‘è‰²å°±æ’é™¤ï¼ˆORæ“ä½œï¼‰
    valid_mask = ~(black_mask1 | black_mask2)
    
    return valid_mask


def crop_black_borders(image, threshold=1):
    """
    è‡ªåŠ¨è£å‰ªå›¾åƒçš„é»‘è‰²è¾¹ç¼˜åŒºåŸŸï¼ˆç”¨äº FID å’Œ IS ç­‰å…¨å±€æŒ‡æ ‡ï¼‰
    
    å‚æ•°:
        image: numpyæ•°ç»„ï¼Œè¾“å…¥å›¾åƒ (H, W, C) æˆ– (H, W)
        threshold: floatï¼Œåˆ¤æ–­ä¸ºé»‘è‰²çš„é˜ˆå€¼ï¼Œé»˜è®¤1
    
    è¿”å›:
        cropped_image: numpyæ•°ç»„ï¼Œè£å‰ªåçš„å›¾åƒ
        bbox: tupleï¼Œè£å‰ªåŒºåŸŸ (y_min, y_max, x_min, x_max)
    
    è¯´æ˜:
        æ‰¾åˆ°å›¾åƒä¸­éé»‘è‰²åƒç´ çš„æœ€å°åŒ…å›´æ¡†ï¼Œè£å‰ªæ‰çº¯é»‘è¾¹ç¼˜
        å¦‚æœæ•´å¼ å›¾éƒ½æ˜¯é»‘è‰²ï¼Œè¿”å›åŸå›¾
    """
    image = np.asarray(image)
    
    # æ£€æµ‹é»‘è‰²åƒç´ 
    if len(image.shape) == 3:
        # å¤šé€šé“ï¼šæ‰€æœ‰é€šé“éƒ½ <= threshold æ‰æ˜¯é»‘è‰²
        is_black = np.all(image <= threshold, axis=-1)
    else:
        # å•é€šé“
        is_black = image <= threshold
    
    # æ‰¾åˆ°éé»‘è‰²åƒç´ çš„ä½ç½®
    non_black_coords = np.argwhere(~is_black)
    
    if len(non_black_coords) == 0:
        # æ•´å¼ å›¾éƒ½æ˜¯é»‘è‰²ï¼Œè¿”å›åŸå›¾
        return image, (0, image.shape[0], 0, image.shape[1])
    
    # è®¡ç®—éé»‘è‰²åŒºåŸŸçš„è¾¹ç•Œæ¡†
    y_min = non_black_coords[:, 0].min()
    y_max = non_black_coords[:, 0].max() + 1
    x_min = non_black_coords[:, 1].min()
    x_max = non_black_coords[:, 1].max() + 1
    
    # è£å‰ªå›¾åƒ
    if len(image.shape) == 3:
        cropped = image[y_min:y_max, x_min:x_max, :]
    else:
        cropped = image[y_min:y_max, x_min:x_max]
    
    return cropped, (y_min, y_max, x_min, x_max)


def _calculate_mse(generated_image, real_image, exclude_black_pixels=False):
    """
    è®¡ç®—å‡æ–¹è¯¯å·® (Mean Squared Error, MSE) - PSNRçš„å†…éƒ¨è¾…åŠ©å‡½æ•°
    
    åŸå§‹å…¬å¼:
        MSE = Î£(i=1 to n)||yi - xi||Â²â‚‚ / n
    
    å…¶ä¸­:
        yi: ç”Ÿæˆå›¾åƒçš„åƒç´ å€¼
        xi: çœŸå®å›¾åƒçš„åƒç´ å€¼
        n: åƒç´ æ€»æ•°ï¼ˆä»…è®¡ç®—éé»‘è‰²åƒç´ ï¼‰
    
    ã€æ”¹è¿›ã€‘è‡ªåŠ¨æ’é™¤çº¯é»‘åƒç´ ï¼ˆé…å‡†è¾¹ç¼˜å¡«å……åŒºåŸŸï¼‰ï¼Œé¿å…å½±å“è¯„ä¼°å‡†ç¡®æ€§
    
    å‚æ•°:
        generated_image: numpyæ•°ç»„ï¼Œç”Ÿæˆçš„å›¾åƒ (H, W, C) æˆ– (H, W)
        real_image: numpyæ•°ç»„ï¼ŒçœŸå®å›¾åƒ (H, W, C) æˆ– (H, W)
        exclude_black_pixels: bool, æ˜¯å¦æ’é™¤é»‘è‰²åƒç´ ï¼Œé»˜è®¤True
    
    è¿”å›:
        float: MSEå€¼ï¼ŒèŒƒå›´ [0, +âˆ)ï¼Œè¶Šå°è¶Šå¥½
    """
    generated_image = np.asarray(generated_image, dtype=np.float64)
    real_image = np.asarray(real_image, dtype=np.float64)
    
    # åˆ›å»ºæœ‰æ•ˆåƒç´ æ©ç ï¼ˆæ’é™¤çº¯é»‘åƒç´ ï¼‰
    if exclude_black_pixels:
        valid_mask = create_valid_mask(generated_image, real_image)
    else:
        valid_mask = np.ones(generated_image.shape[:2], dtype=bool)  # (H, W)
    
    # å°†maskå¹¿æ’­åˆ°ä¸å›¾åƒç›¸åŒçš„å½¢çŠ¶ï¼Œç”¨äºæ­£ç¡®ç»Ÿè®¡æœ‰æ•ˆå…ƒç´ ä¸ªæ•°
    if generated_image.ndim == 3:
        # (H, W, 1) -> (H, W, C)
        valid_mask_full = np.broadcast_to(valid_mask[:, :, np.newaxis], generated_image.shape)
    else:
        valid_mask_full = valid_mask  # (H, W)
    
    # åªè®¡ç®—æœ‰æ•ˆå…ƒç´ çš„MSE
    valid_elements = valid_mask_full.sum()
    if valid_elements == 0:
        return None
    
    squared_error = (generated_image - real_image) ** 2
    mse = np.sum(squared_error * valid_mask_full) / valid_elements
    return float(mse)


# è”åˆé®ç½©è¾…åŠ©å‡½æ•°ï¼ˆæ”¾åœ¨è®¡ç®—å‡½æ•°ä¹‹å‰ï¼Œé¿å…æœªå®šä¹‰æŠ¥é”™ï¼‰

def generate_black_mask(image, threshold=10, smooth=True, kernel_size=5, threshold_auto=True):
    """
    ç”Ÿæˆé»‘è‰²åŒºåŸŸé®ç½©ï¼šéé»‘è‰²ä¸º1ï¼Œé»‘è‰²ä¸º0ï¼›å¯é€‰å¹³æ»‘ï¼ˆéœ€è¦opencvï¼‰ã€‚
    """
    arr = np.asarray(image)
    # è‡ªåŠ¨é˜ˆå€¼å°ºåº¦åŒ¹é…ï¼šè‹¥æ•°æ®åœ¨[0,1]ä¸”é˜ˆå€¼>1ï¼Œåˆ™æŒ‰255ç¼©æ”¾
    thr = float(threshold)
    if threshold_auto:
        data_max = float(arr.max()) if arr.size else 0.0
        if data_max <= 1.0 and thr > 1.0:
            thr = thr / 255.0
    if arr.ndim == 3:
        # æ‰€æœ‰é€šé“ < threshold æ‰åˆ¤å®šä¸ºé»‘
        is_black = np.all(arr[..., :3] < thr, axis=-1)
    else:
        is_black = arr < thr
    mask = (~is_black).astype(np.uint8)

    if smooth and _CV2_AVAILABLE:
        k = max(1, int(kernel_size))
        if k % 2 == 0:
            k += 1
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask_f = mask.astype(np.float32)
        mask_blur = cv2.GaussianBlur(mask_f, (k, k), 0)
        mask = (mask_blur > 0.5).astype(np.uint8)

    return mask.astype(np.float32)


def apply_joint_black_mask(img_a, img_b, threshold=10, smooth=True, kernel_size=5, mode='intersection', threshold_auto=True):
    """
    ä¸ºä¸¤å¼ å›¾ç”Ÿæˆé»‘è‰²é®ç½©å¹¶åˆå¹¶ååŒæ—¶åº”ç”¨ã€‚
    - mode='intersection': å–ä¸¤å›¾æœ‰æ•ˆåŒºåŸŸäº¤é›†ï¼ˆé»˜è®¤ï¼‰
    - mode='union': å–ä¸¤å›¾æœ‰æ•ˆåŒºåŸŸå¹¶é›†
    è¿”å›: (masked_a, masked_b, joint_mask)
    """
    mask_a = generate_black_mask(img_a, threshold=threshold, smooth=smooth, kernel_size=kernel_size, threshold_auto=threshold_auto)
    mask_b = generate_black_mask(img_b, threshold=threshold, smooth=smooth, kernel_size=kernel_size, threshold_auto=threshold_auto)

    if mode == 'union':
        joint = np.clip(mask_a + mask_b, 0, 1)
    else:
        joint = (mask_a * mask_b)

    a = np.asarray(img_a).astype(np.float32)
    b = np.asarray(img_b).astype(np.float32)

    if a.ndim == 3:
        joint_broadcast = joint[:, :, np.newaxis]
    else:
        joint_broadcast = joint

    masked_a = a * joint_broadcast
    masked_b = b * joint_broadcast
    return masked_a, masked_b, joint


def calculate_psnr(generated_image, real_image, data_range=None, exclude_black_pixels=False, crop_valid_intersection=False,
                   apply_black_mask=False, black_threshold=10, smooth_mask=True, mask_kernel_size=5, mask_mode='intersection',
                   psnr_eps=1e-12):
    """
    è®¡ç®—å³°å€¼ä¿¡å™ªæ¯” (Peak Signal-to-Noise Ratio, PSNR)
    
    åŸå§‹å…¬å¼:
        PSNR = 10 Â· logâ‚â‚€(MAXÂ² / MSE)
    
    å…¶ä¸­:
        MAX: å›¾åƒåƒç´ çš„æœ€å¤§å¯èƒ½å€¼
        MSE: å‡æ–¹è¯¯å·®ï¼ˆä»…è®¡ç®—éé»‘è‰²åƒç´ ï¼‰
    
    PSNR æ•°å€¼è¶Šå¤§ï¼Œè¯´æ˜ç”Ÿæˆå›¾åƒçš„"ä¿¡å™ªæ¯”è¶Šé«˜"ï¼ˆä¿¡å·å¼ºã€å™ªå£°å¼±ï¼‰ï¼Œ
    ä¸çœŸå®å›¾åƒçš„ç»“æ„ç›¸ä¼¼æ€§è¶Šå¼ºï¼Œæ¨¡æ€è½¬æ¢çš„è´¨é‡è¶Šå¥½
    
    ã€æ”¹è¿›ã€‘æ”¯æŒä¸‰ç§æ–¹å¼å¿½ç•¥é»‘è‰²è¾¹ç¼˜ï¼š
      - apply_black_mask: å¯¹ä¸¤å›¾ç”Ÿæˆé»‘è‰²é®ç½©å¹¶å–äº¤é›†/å¹¶é›†åå…±åŒåº”ç”¨
      - exclude_black_pixels: é€šè¿‡æ©ç æ’é™¤é»‘åƒç´ ï¼ˆé€åƒç´ ï¼‰
      - crop_valid_intersection: è£å‰ªåˆ°ä¸¤å›¾åƒéé»‘åŒºåŸŸçš„äº¤é›†
    """
    generated_image = np.asarray(generated_image)
    real_image = np.asarray(real_image)

    # å°ºå¯¸å¯¹é½ï¼šå°† real_image è°ƒæ•´ä¸ºä¸ generated_image ç›¸åŒçš„å°ºå¯¸
    if generated_image.shape[:2] != real_image.shape[:2]:
        _, real_image = _align_pair_by_resize(generated_image, real_image)
    
    # å¯é€‰ï¼šå¯¹ä¸¤å›¾åº”ç”¨è”åˆé®ç½©ï¼ˆä¼˜å…ˆäºè£å‰ª/é€åƒç´ æ©ç ï¼Œé¿å…åŒé‡å¤„ç†ï¼‰
    if apply_black_mask:
        generated_image, real_image, _ = apply_joint_black_mask(
            generated_image, real_image,
            threshold=black_threshold,
            smooth=smooth_mask,
            kernel_size=mask_kernel_size,
            mode=mask_mode,
            threshold_auto=True,
        )
    
    # å¯é€‰ï¼šè£å‰ªåˆ°ä¸¤å›¾éé»‘åŒºåŸŸçš„äº¤é›†
    if crop_valid_intersection and not apply_black_mask:
        def non_black_bbox(img, threshold=1):
            if img.ndim == 3:
                is_black = np.all(img <= threshold, axis=-1)
            else:
                is_black = img <= threshold
            coords = np.argwhere(~is_black)
            if coords.size == 0:
                return (0, img.shape[0], 0, img.shape[1])
            y_min = coords[:, 0].min()
            y_max = coords[:, 0].max() + 1
            x_min = coords[:, 1].min()
            x_max = coords[:, 1].max() + 1
            return (y_min, y_max, x_min, x_max)
        y1_min, y1_max, x1_min, x1_max = non_black_bbox(generated_image)
        y2_min, y2_max, x2_min, x2_max = non_black_bbox(real_image)
        y_min = max(y1_min, y2_min)
        y_max = min(y1_max, y2_max)
        x_min = max(x1_min, x2_min)
        x_max = min(x1_max, x2_max)
        if y_min < y_max and x_min < x_max:
            if generated_image.ndim == 3:
                generated_image = generated_image[y_min:y_max, x_min:x_max, :]
            else:
                generated_image = generated_image[y_min:y_max, x_min:x_max]
            if real_image.ndim == 3:
                real_image = real_image[y_min:y_max, x_min:x_max, :]
            else:
                real_image = real_image[y_min:y_max, x_min:x_max]
    
    # ç¡®ä¿å›¾åƒå½¢çŠ¶ä¸€è‡´ 
    if generated_image.shape != real_image.shape:
        raise ValueError(f"å›¾åƒå½¢çŠ¶ä¸åŒ¹é…: {generated_image.shape} vs {real_image.shape}")
    
    if data_range is None:
        if generated_image.dtype == np.uint8:
            data_range = 255
        else:
            data_range = max(generated_image.max(), real_image.max())
    
    # ä½¿ç”¨å¸¦æ©ç çš„MSEè®¡ç®—ï¼ˆè‹¥å·²åº”ç”¨è”åˆé®ç½©ï¼Œåˆ™åŒæ—¶å¯ç”¨é€åƒç´ é»‘åŒºæ’é™¤ï¼‰
    mse_value = _calculate_mse(
        generated_image,
        real_image,
        exclude_black_pixels=(exclude_black_pixels or apply_black_mask)
    )
    
    if mse_value is None:
        return None
    if mse_value < psnr_eps:
        return None
    
    psnr_value = 10 * np.log10((data_range ** 2) / mse_value)
    return float(psnr_value)


def calculate_ms_ssim(generated_image, real_image, data_range=None, exclude_black_pixels=False, crop_valid_intersection=False,
                      apply_black_mask=False, black_threshold=10, smooth_mask=True, mask_kernel_size=5, mask_mode='intersection'):
    """
    è®¡ç®—å¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•° (Multi-Scale Structural Similarity Index Measure, MS-SSIM)
    """
    # ç¡®ä¿å›¾åƒæ˜¯numpyæ•°ç»„
    generated_image = np.asarray(generated_image)
    real_image = np.asarray(real_image)

    # å°ºå¯¸å¯¹é½ï¼šå°† real_image è°ƒæ•´ä¸ºä¸ generated_image ç›¸åŒçš„å°ºå¯¸
    if generated_image.shape[:2] != real_image.shape[:2]:
        _, real_image = _align_pair_by_resize(generated_image, real_image)
    
    # å¯é€‰ï¼šå¯¹ä¸¤å›¾åº”ç”¨è”åˆé®ç½©
    if apply_black_mask:
        generated_image, real_image, _ = apply_joint_black_mask(
            generated_image, real_image,
            threshold=black_threshold,
            smooth=smooth_mask,
            kernel_size=mask_kernel_size,
            mode=mask_mode,
            threshold_auto=True,
        )
    
    # å¯é€‰ï¼šè£å‰ªåˆ°ä¸¤å›¾åƒéé»‘åŒºåŸŸçš„äº¤é›†
    if crop_valid_intersection and not apply_black_mask:
        def non_black_bbox(img, threshold=1):
            if img.ndim == 3:
                is_black = np.all(img <= threshold, axis=-1)
            else:
                is_black = img <= threshold
            coords = np.argwhere(~is_black)
            if coords.size == 0:
                return (0, img.shape[0], 0, img.shape[1])
            y_min = coords[:, 0].min()
            y_max = coords[:, 0].max() + 1
            x_min = coords[:, 1].min()
            x_max = coords[:, 1].max() + 1
            return (y_min, y_max, x_min, x_max)
        y1_min, y1_max, x1_min, x1_max = non_black_bbox(generated_image)
        y2_min, y2_max, x2_min, x2_max = non_black_bbox(real_image)
        y_min = max(y1_min, y2_min)
        y_max = min(y1_max, y2_max)
        x_min = max(x1_min, x2_min)
        x_max = min(x1_max, x2_max)
        if y_min < y_max and x_min < x_max:
            if generated_image.ndim == 3:
                generated_image = generated_image[y_min:y_max, x_min:x_max, :]
            else:
                generated_image = generated_image[y_min:y_max, x_min:x_max]
            if real_image.ndim == 3:
                real_image = real_image[y_min:y_max, x_min:x_max, :]
            else:
                real_image = real_image[y_min:y_max, x_min:x_max]
    
    # æ£€æŸ¥å›¾åƒå½¢çŠ¶å¹¶ç»Ÿä¸€æ ¼å¼
    if len(generated_image.shape) == 2:
        generated_image = np.expand_dims(generated_image, axis=-1)  # (H, W) -> (H, W, 1)
    if len(real_image.shape) == 2:
        real_image = np.expand_dims(real_image, axis=-1)  # (H, W) -> (H, W, 1)
    
    # ç¡®ä¿ä¸¤ä¸ªå›¾åƒå½¢çŠ¶ä¸€è‡´
    if generated_image.shape != real_image.shape:
        # è°ƒæ•´å°ºå¯¸ä½¿å…¶åŒ¹é…
        min_height = min(generated_image.shape[0], real_image.shape[0])
        min_width = min(generated_image.shape[1], real_image.shape[1])
        generated_image = generated_image[:min_height, :min_width]
        real_image = real_image[:min_height, :min_width]
    
    # åˆ›å»ºæœ‰æ•ˆåƒç´ æ©ç ï¼ˆå¯é€‰ï¼Œé¿å…ä¸è”åˆé®ç½©é‡å¤ï¼‰
    if exclude_black_pixels and not apply_black_mask:
        valid_mask = create_valid_mask(generated_image, real_image)
        
        # å°†Falseåƒç´ è®¾ä¸ºé»‘è‰²ï¼ˆä¿æŒå›¾åƒå½¢çŠ¶ï¼‰
        masked_generated = generated_image.copy()
        masked_real = real_image.copy()
        
        # åº”ç”¨æ©ç 
        if len(masked_generated.shape) == 3:
            # å¤šé€šé“å›¾åƒ
            for c in range(masked_generated.shape[2]):
                masked_generated[~valid_mask, c] = 0
                masked_real[~valid_mask, c] = 0
        else:
            # å•é€šé“å›¾åƒ
            masked_generated[~valid_mask] = 0
            masked_real[~valid_mask] = 0
        
        generated_image = masked_generated
        real_image = masked_real
    
    try:
        # è½¬æ¢ä¸ºtorchå¼ é‡
        generated_image = torch.from_numpy(generated_image).float()
        real_image = torch.from_numpy(real_image).float()
        
        # ç¡®ä¿æ˜¯4Då¼ é‡ (B, C, H, W)
        if len(generated_image.shape) == 3: 
            if generated_image.shape[2] in [1, 3]:
                # (H, W, C) -> (C, H, W)
                generated_image = generated_image.permute(2, 0, 1)
            generated_image = generated_image.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
            
        if len(real_image.shape) == 3: 
            if real_image.shape[2] in [1, 3]:
                # (H, W, C) -> (C, H, W)
                real_image = real_image.permute(2, 0, 1)
            real_image = real_image.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        
        if data_range is None:
            data_range = 1.0 if generated_image.max() <= 1.0 else 255.0
        
        # ä½¿ç”¨pytorch_msssimåº“è®¡ç®—
        from pytorch_msssim import ms_ssim
        ms_ssim_value = ms_ssim(generated_image, real_image, 
                                data_range=data_range, size_average=True)
        return float(ms_ssim_value.item())
        
    except Exception as e:
        print(f"  è®¡ç®—MS-SSIMæ—¶å‡ºé”™: {e}")
        return None

#---------------------------------------------------------------æ•´åˆæ–¹æ³•ï¼šæŒ‰é¡ºåºæ¯”è¾ƒä¸¤å¼ å›¾åƒç›¸ä¼¼åº¦-------------------------------------------------------------------

def compare_images_pairwise(dataset1_path, dataset2_path, metrics=['psnr', 'ms_ssim'], data_range=None):
    """
    æŒ‰é¡ºåºæ¯”è¾ƒä¸¤ä¸ªæ•°æ®é›†ä¸­æ¯å¼ å›¾åƒçš„ç›¸ä¼¼åº¦
    
    å‚æ•°:
        dataset1_path: strï¼Œç¬¬ä¸€ä¸ªæ•°æ®é›†çš„è·¯å¾„
        dataset2_path: strï¼Œç¬¬äºŒä¸ªæ•°æ®é›†çš„è·¯å¾„  
        metrics: listï¼Œè¦è®¡ç®—çš„æŒ‡æ ‡åˆ—è¡¨ï¼Œé»˜è®¤['psnr', 'ms_ssim']
        data_range: floatï¼Œæ•°æ®èŒƒå›´ï¼Œé»˜è®¤è‡ªåŠ¨æ¨æ–­
    
    è¿”å›:
        dict: åŒ…å«æ‰€æœ‰å›¾åƒå¯¹æ¯”è¾ƒç»“æœçš„å­—å…¸
    """
    print("\n" + "="*70)
    print("ğŸ” æŒ‰é¡ºåºæ¯”è¾ƒä¸¤ä¸ªæ•°æ®é›†ä¸­æ¯å¼ å›¾åƒçš„ç›¸ä¼¼åº¦")
    print("="*70)
    print(f"æ•°æ®é›†1: {dataset1_path}")
    print(f"æ•°æ®é›†2: {dataset2_path}")
    print(f"è®¡ç®—æŒ‡æ ‡: {metrics}")
    
    def load_and_sort_images(folder_path):
        """ä»æ–‡ä»¶å¤¹åŠ è½½å¹¶æ’åºå›¾åƒ"""
        if not os.path.exists(folder_path):
            print(f"âŒ é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {folder_path}")
            return None
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']
        image_files = []
        for ext in image_extensions:
            image_files.extend([f for f in os.listdir(folder_path) if f.lower().endswith(ext)])
        
        # æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿é¡ºåºä¸€è‡´
        image_files.sort()
        print(f"åœ¨è·¯å¾„ {folder_path} ä¸­æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        if len(image_files) == 0:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return None
        
        # è¯»å–å›¾åƒ
        print("æ­£åœ¨åŠ è½½å›¾åƒ...")
        images = []
        valid_count = 0
        
        for img_file in image_files:
            try:
                img_path = os.path.join(folder_path, img_file)
                img = Image.open(img_path)
                img_array = np.array(img)
                
                images.append({
                    'filename': img_file,
                    'array': img_array,
                    'path': img_path
                })
                valid_count += 1
                
                if valid_count % 50 == 0:
                    print(f"  å·²åŠ è½½ {valid_count} å¼ å›¾åƒ...")
                    
            except Exception as e:
                print(f"  è­¦å‘Š: åŠ è½½å›¾åƒ {img_file} æ—¶å‡ºé”™: {e}")
                continue
        
        if valid_count == 0:
            print("âŒ é”™è¯¯: æ— æ³•åŠ è½½ä»»ä½•æœ‰æ•ˆå›¾åƒ")
            return None
        
        print(f"âœ… æˆåŠŸåŠ è½½ {valid_count} å¼ å›¾åƒ")
        return images
    
    # åŠ è½½ä¸¤ä¸ªæ•°æ®é›†
    print(f"\nğŸ“ åŠ è½½æ•°æ®é›†1...")
    dataset1_images = load_and_sort_images(dataset1_path)
    
    print(f"\nğŸ“ åŠ è½½æ•°æ®é›†2...")
    dataset2_images = load_and_sort_images(dataset2_path)
    
    if dataset1_images is None or dataset2_images is None:
        print("âŒ é”™è¯¯: æ— æ³•åŠ è½½ä¸€ä¸ªæˆ–ä¸¤ä¸ªæ•°æ®é›†")
        return None
    
    # æ£€æŸ¥å›¾åƒæ•°é‡
    count1 = len(dataset1_images)
    count2 = len(dataset2_images)
    
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  æ•°æ®é›†1: {count1} å¼ å›¾åƒ")
    print(f"  æ•°æ®é›†2: {count2} å¼ å›¾åƒ")
    
    if count1 != count2:
        print(f"âš ï¸  è­¦å‘Š: ä¸¤ä¸ªæ•°æ®é›†çš„å›¾åƒæ•°é‡ä¸åŒï¼Œå°†æ¯”è¾ƒå‰ {min(count1, count2)} å¼ å›¾åƒ")
    
    # ç¡®å®šè¦æ¯”è¾ƒçš„å›¾åƒæ•°é‡
    n_comparisons = min(count1, count2)
    
    print(f"\nğŸ”„ å¼€å§‹æŒ‰é¡ºåºæ¯”è¾ƒ {n_comparisons} å¯¹å›¾åƒ...")
    
    results = {
        'summary': {},
        'pairwise_results': [],
        'metrics_used': metrics
    }

    # ç»Ÿè®¡é®ç½©åçš„æœ‰æ•ˆåƒç´ æ•°é‡ï¼ˆä»…å½“ä½¿ç”¨è”åˆé®ç½©çš„é»˜è®¤é…ç½®æ—¶æœ‰æ„ä¹‰ï¼‰
    mask_valid_counts = []  # æ¯å¯¹çš„æœ‰æ•ˆåƒç´ ä¸ªæ•°ï¼ˆH*Wï¼‰
    mask_total_counts = []  # æ¯å¯¹çš„æ€»åƒç´ ä¸ªæ•°ï¼ˆH*Wï¼‰
    
    # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆå§‹åŒ–ç»Ÿè®¡
    for metric in metrics:
        results['summary'][metric] = {
            'values': [],
            'mean': 0,
            'std': 0,
            'min': float('inf'),
            'max': float('-inf')
        }
    
    # é€å¯¹æ¯”è¾ƒå›¾åƒ
    for i in range(n_comparisons):
        img1_info = dataset1_images[i]
        img2_info = dataset2_images[i]
        
        print(f"  æ¯”è¾ƒç¬¬ {i+1}/{n_comparisons} å¯¹: {img1_info['filename']} vs {img2_info['filename']}")
        
        pair_result = {
            'pair_id': i,
            'image1': img1_info['filename'],
            'image2': img2_info['filename'],
            'metrics': {}
        }
        
        # è®¡ç®—æ¯ä¸ªæŒ‡æ ‡
        for metric in metrics:
            try:
                # å¯¹é½å°ºå¯¸ï¼ˆé¿å…ç»Ÿè®¡é®ç½©æˆ–è®¡ç®—æŒ‡æ ‡æ—¶å› å°ºå¯¸ä¸ä¸€è‡´å‡ºé”™ï¼‰
                a_aligned, b_aligned = _align_pair_by_resize(img1_info['array'], img2_info['array'])

                # åœ¨è®¡ç®—å‰å…ˆç»Ÿè®¡è”åˆé®ç½©åçš„æœ‰æ•ˆåƒç´ æ•°é‡ï¼ˆä¸ä¸‹æ–¹è®¡ç®—ä½¿ç”¨çš„å‚æ•°ä¸€è‡´ï¼‰
                if metric == 'psnr':
                    # ä»…ç»Ÿè®¡ä¸€æ¬¡å³å¯ï¼ˆä¸ä¸‹æ–¹å‚æ•°ä¿æŒä¸€è‡´ï¼šthreshold=3, smooth=False, kernel_size=3ï¼‰
                    if len(mask_valid_counts) == i:
                        m1 = generate_black_mask(a_aligned, threshold=3, smooth=False, kernel_size=3)
                        m2 = generate_black_mask(b_aligned, threshold=3, smooth=False, kernel_size=3)
                        joint = (m1 * m2)  # intersection
                        mask_valid_counts.append(int(joint.sum()))
                        mask_total_counts.append(int(joint.size))
                if metric == 'psnr':
                    value = calculate_psnr(
                        a_aligned,
                        b_aligned,
                        data_range=data_range,
                        exclude_black_pixels=False,
                        crop_valid_intersection=False,
                        apply_black_mask=True,
                        black_threshold=3,
                        smooth_mask=False,
                        mask_kernel_size=3,
                        mask_mode='intersection',
                        psnr_eps=1e-10
                    )
                elif metric == 'ms_ssim':
                    value = calculate_ms_ssim(
                        a_aligned,
                        b_aligned,
                        data_range=data_range,
                        exclude_black_pixels=False,
                        crop_valid_intersection=False,
                        apply_black_mask=True,
                        black_threshold=3,
                        smooth_mask=False,
                        mask_kernel_size=3,
                        mask_mode='intersection'
                    )
                else:
                    print(f"  è­¦å‘Š: æœªçŸ¥æŒ‡æ ‡ {metric}ï¼Œè·³è¿‡")
                    continue
                
                 # åªæœ‰valueä¸æ˜¯Noneæ—¶æ‰æ·»åŠ åˆ°ç»Ÿè®¡ä¸­
                if value is not None:
                    pair_result['metrics'][metric] = value
                    results['summary'][metric]['values'].append(value)
                
                # æ›´æ–°ç»Ÿè®¡ï¼ˆåªæ›´æ–°éNoneå€¼ï¼‰
                    if value is not None:
                        results['summary'][metric]['min'] = min(results['summary'][metric]['min'], value)
                        results['summary'][metric]['max'] = max(results['summary'][metric]['max'], value)
                else:
                    pair_result['metrics'][metric] = None
                    print(f"    æŒ‡æ ‡ {metric} è®¡ç®—è¿”å›None")
                
            except Exception as e:
                print(f"  è­¦å‘Š: è®¡ç®—æŒ‡æ ‡ {metric} æ—¶å‡ºé”™: {e}")
                pair_result['metrics'][metric] = None
        
        results['pairwise_results'].append(pair_result)
    
    # è®¡ç®—ç»Ÿè®¡æ‘˜è¦
    print(f"\nğŸ“ˆ è®¡ç®—ç»Ÿè®¡æ‘˜è¦...")
    for metric in metrics:
        values = results['summary'][metric]['values']
        valid_values = [v for v in values if v is not None]
        
        
        if metric == 'psnr' and all(v == float('inf') for v in valid_values):
        # æ‰€æœ‰PSNRéƒ½æ˜¯infçš„ç‰¹æ®Šæƒ…å†µ
            results['summary'][metric]['mean'] = float('inf')
            results['summary'][metric]['std'] = 0.0  # è€Œä¸æ˜¯nan
            results['summary'][metric]['min'] = float('inf')
            results['summary'][metric]['max'] = float('inf')
            results['summary'][metric]['count'] = len(valid_values)
        elif valid_values:
        # æ­£å¸¸è®¡ç®—
            results['summary'][metric]['mean'] = np.mean(valid_values)
            results['summary'][metric]['std'] = np.std(valid_values)
            results['summary'][metric]['min'] = min(valid_values)
            results['summary'][metric]['max'] = max(valid_values)
            results['summary'][metric]['count'] = len(valid_values)
        else:
            # æ²¡æœ‰æœ‰æ•ˆå€¼çš„æƒ…å†µ
            results['summary'][metric]['mean'] = None
            results['summary'][metric]['std'] = None
            results['summary'][metric]['min'] = None
            results['summary'][metric]['max'] = None
            results['summary'][metric]['count'] = 0
        # if values:
        #     results['summary'][metric]['mean'] = np.mean(valid_values)
        #     results['summary'][metric]['std'] = np.std(valid_values)
        #     results['summary'][metric]['count'] = len(valid_values)
        #     results['summary'][metric]['min'] = min(valid_values)
        #     results['summary'][metric]['max'] = max(valid_values)
        # else:
        #     # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå€¼ï¼Œè®¾ç½®é»˜è®¤å€¼
        #     results['summary'][metric]['mean'] = None
        #     results['summary'][metric]['std'] = None
        #     results['summary'][metric]['count'] = 0
        #     results['summary'][metric]['min'] = None
        #     results['summary'][metric]['max'] = None
        #     print(f"  è­¦å‘Š: æŒ‡æ ‡ {metric} æ²¡æœ‰æœ‰æ•ˆè®¡ç®—ç»“æœ")
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\n" + "="*70)
    print("ğŸ¯ æŒ‰é¡ºåºæ¯”è¾ƒç»“æœ")
    print("="*70)
    
    # æ˜¾ç¤ºæ¯å¯¹å›¾åƒçš„è¯¦ç»†ç»“æœ
    print(f"\nğŸ“Š è¯¦ç»†ç»“æœ (å‰10å¯¹):")
    print("åºå· | å›¾åƒ1 | å›¾åƒ2 | " + " | ".join([m.upper() for m in metrics]))
    print("-" * (50 + 15 * len(metrics)))
    
    for i, result in enumerate(results['pairwise_results'][:10]):
        row = f"{i+1:3d} | {result['image1'][:15]:15} | {result['image2'][:15]:15}"
        for metric in metrics:
            value = result['metrics'].get(metric, None)
            if value is not None:
                if metric == 'psnr':
                    row += f" | {value:6.2f} dB"
                elif metric == 'ms_ssim':
                    row += f" | {value:6.4f}"
                else:
                    row += f" | {value:8.4f}"
            else:
                row += " |    N/A   "
        print(row)
    
    if n_comparisons > 10:
        print(f"... è¿˜æœ‰ {n_comparisons - 10} å¯¹å›¾åƒæœªæ˜¾ç¤º")
    
    # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
    print(f"\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
    print("æŒ‡æ ‡ | å¹³å‡å€¼ | æ ‡å‡†å·® | æœ€å°å€¼ | æœ€å¤§å€¼ | æ ·æœ¬æ•°")
    print("-" * 60)
    
    for metric in metrics:
        stats = results['summary'][metric]
        if stats['count'] > 0:  # åªæœ‰æœ‰æœ‰æ•ˆæ ·æœ¬æ—¶æ‰æ˜¾ç¤º
            if metric == 'psnr':
                print(f"PSNR | {stats['mean']:6.2f} dB | {stats['std']:6.2f} | {stats['min']:6.2f} dB | {stats['max']:6.2f} dB | {stats['count']:6d}")
            elif metric == 'ms_ssim':
                print(f"MS-SSIM | {stats['mean']:6.4f} | {stats['std']:6.4f} | {stats['min']:6.4f} | {stats['max']:6.4f} | {stats['count']:6d}")
        else:
            print(f"{metric.upper()} |   N/A   |   N/A   |   N/A   |   N/A   | {stats['count']:6d}")
    
    # é®ç½©æœ‰æ•ˆåƒç´ ç»Ÿè®¡
    if mask_valid_counts:
        ratios = [v / t if t > 0 else 0.0 for v, t in zip(mask_valid_counts, mask_total_counts)]
        avg_ratio = float(np.mean(ratios))
        min_ratio = float(np.min(ratios))
        max_ratio = float(np.max(ratios))
        avg_pixels = int(np.mean(mask_valid_counts))
        print("\nğŸ§® é®ç½©æœ‰æ•ˆåƒç´ ç»Ÿè®¡ (è”åˆé®ç½©Â·äº¤é›†):")
        print(f"  å¹³å‡å‰©ä½™åƒç´ : {avg_pixels} åƒç´ ")
        print(f"  å¹³å‡å‰©ä½™æ¯”ä¾‹: {avg_ratio*100:.2f}%  (æœ€å° {min_ratio*100:.2f}%, æœ€å¤§ {max_ratio*100:.2f}%)")

    # è´¨é‡è¯„ä¼°ï¼ˆå¤„ç†Noneå€¼ï¼‰
    print(f"\nğŸ“Š æ•´ä½“è´¨é‡è¯„ä¼°:")
    for metric in metrics:
        stats = results['summary'][metric]
        if stats['count'] > 0:
            if metric == 'psnr':
                mean_psnr = stats['mean']
                if mean_psnr > 40:
                    print("  âœ… PSNR: ä¼˜ç§€ - å›¾åƒè´¨é‡éå¸¸é«˜")
                elif mean_psnr > 30:
                    print("  âœ… PSNR: è‰¯å¥½ - å›¾åƒè´¨é‡è¾ƒå¥½")
                elif mean_psnr > 20:
                    print("  âš ï¸  PSNR: ä¸­ç­‰ - å›¾åƒè´¨é‡ä¸€èˆ¬")
                else:
                    print("  âŒ PSNR: è¾ƒå·® - å›¾åƒè´¨é‡éœ€è¦æ”¹è¿›")
            
            elif metric == 'ms_ssim':
                mean_ms_ssim = stats['mean']
                if mean_ms_ssim > 0.9:
                    print("  âœ… MS-SSIM: ä¼˜ç§€ - ç»“æ„ç›¸ä¼¼æ€§éå¸¸é«˜")
                elif mean_ms_ssim > 0.8:
                    print("  âœ… MS-SSIM: è‰¯å¥½ - ç»“æ„ç›¸ä¼¼æ€§è¾ƒå¥½") 
                elif mean_ms_ssim > 0.7:
                    print("  âš ï¸  MS-SSIM: ä¸­ç­‰ - ç»“æ„ç›¸ä¼¼æ€§ä¸€èˆ¬")
                else:
                    print("  âŒ MS-SSIM: è¾ƒå·® - ç»“æ„ç›¸ä¼¼æ€§è¾ƒä½")
        else:
            print(f"  âš ï¸  {metric.upper()}: æ— æ³•è®¡ç®— - æ²¡æœ‰æœ‰æ•ˆç»“æœ")
    
    return results


def export_pairwise_results(results, output_file=None):
    """
    å¯¼å‡ºæŒ‰é¡ºåºæ¯”è¾ƒçš„ç»“æœåˆ°æ–‡ä»¶
    
    å‚æ•°:
        results: dictï¼Œcompare_images_pairwiseå‡½æ•°çš„è¿”å›ç»“æœ
        output_file: strï¼Œè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤Noneï¼ˆä¸å¯¼å‡ºï¼‰
    
    è¿”å›:
        str: å¦‚æœå¯¼å‡ºæˆåŠŸï¼Œè¿”å›æ–‡ä»¶è·¯å¾„
    """
    if output_file is None:
        import tempfile
        output_file = os.path.join(tempfile.gettempdir(), f"pairwise_comparison_{int(time.time())}.txt")
    
    try:
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("æŒ‰é¡ºåºå›¾åƒå¯¹æ¯”è¾ƒç»“æœ\n")
            f.write("=" * 50 + "\n\n")
            
            # å†™å…¥æ‘˜è¦
            f.write("ç»Ÿè®¡æ‘˜è¦:\n")
            f.write("-" * 50 + "\n")
            for metric in results['metrics_used']:
                stats = results['summary'][metric]
                if stats['values']:
                    if metric == 'psnr':
                        f.write(f"PSNR: {stats['mean']:.2f} Â± {stats['std']:.2f} dB (èŒƒå›´: {stats['min']:.2f}-{stats['max']:.2f} dB)\n")
                    elif metric == 'ms_ssim':
                        f.write(f"MS-SSIM: {stats['mean']:.4f} Â± {stats['std']:.4f} (èŒƒå›´: {stats['min']:.4f}-{stats['max']:.4f})\n")
            
            f.write("\nè¯¦ç»†ç»“æœ:\n")
            f.write("-" * 50 + "\n")
            f.write("åºå·,å›¾åƒ1,å›¾åƒ2," + ",".join([m.upper() for m in results['metrics_used']]) + "\n")
            
            for result in results['pairwise_results']:
                row = f"{result['pair_id']+1},{result['image1']},{result['image2']}"
                for metric in results['metrics_used']:
                    value = result['metrics'].get(metric, 'N/A')
                    row += f",{value}"
                f.write(row + "\n")
        
        print(f"âœ… ç»“æœå·²å¯¼å‡ºåˆ°: {output_file}")
        return output_file
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºç»“æœå¤±è´¥: {e}")
        return None


def calculate_fid(real_images, generated_images, batch_size=50, device='cuda', auto_crop=True):
    """
    è®¡ç®—å¼—é›·æ­‡è·ç¦» (FrÃ©chet Inception Distance, FID)
    
    FIDé€šè¿‡ Inception v3 ç½‘ç»œæå–çœŸå®å›¾åƒä¸ç”Ÿæˆå›¾åƒçš„ç‰¹å¾å‘é‡ï¼Œè®¡ç®—ä¸¤è€…æ¦‚ç‡åˆ†å¸ƒçš„ Wasserstein è·ç¦»
    æ•°å€¼è¶Šä½è¡¨ç¤ºç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒçš„åˆ†å¸ƒè¶Šæ¥è¿‘ï¼Œè´¨é‡è¶Šä¼˜
    
    è¯¥æŒ‡æ ‡ä»æ·±åº¦ç‰¹å¾çš„è§’åº¦è¯„ä¼°å›¾åƒè´¨é‡ï¼Œæ›´ç¬¦åˆäººç±»æ„ŸçŸ¥
    
    ã€æ”¹è¿›ã€‘è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼ˆé…å‡†äº§ç”Ÿçš„å¡«å……åŒºåŸŸï¼‰ï¼Œç¡®ä¿è¯„ä¼°åªå…³æ³¨æœ‰æ•ˆåŒºåŸŸ
    
    å‚è€ƒå®ç°: 
    - pytorch-fid (https://github.com/mseitzer/pytorch-fid)
    - clean-fid (https://github.com/GaParmar/clean-fid) - åŸºäºCVPR 2020è®ºæ–‡çš„æ”¹è¿›ç‰ˆ
    - torch-fidelity (https://github.com/toshas/torch-fidelity)
    
    å‚æ•°:
        real_images: numpyæ•°ç»„åˆ—è¡¨æˆ–å•ä¸ª4Dæ•°ç»„ï¼ŒçœŸå®å›¾åƒé›† (N, H, W, C) æˆ– list of (H, W, C)
        generated_images: numpyæ•°ç»„åˆ—è¡¨æˆ–å•ä¸ª4Dæ•°ç»„ï¼Œç”Ÿæˆå›¾åƒé›† (N, H, W, C) æˆ– list of (H, W, C)
        batch_size: intï¼Œæ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤50
        device: strï¼Œè®¡ç®—è®¾å¤‡ 'cuda' æˆ– 'cpu'ï¼Œé»˜è®¤'cuda'
        auto_crop: boolï¼Œæ˜¯å¦è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼Œé»˜è®¤True
    
    è¿”å›:
        float: FIDå€¼ï¼ŒèŒƒå›´ [0, +âˆ)ï¼Œè¶Šå°è¶Šå¥½
    """
    if not torch.cuda.is_available():
        device = 'cpu'
    
    # åŠ è½½é¢„è®­ç»ƒçš„Inception v3æ¨¡å‹
    inception_model = models.inception_v3(pretrained=True, transform_input=False)
    inception_model.fc = torch.nn.Identity()  # ç§»é™¤æœ€åçš„åˆ†ç±»å±‚
    inception_model = inception_model.to(device)
    inception_model.eval()
    
    def preprocess_images(images, auto_crop=True):
        """é¢„å¤„ç†å›¾åƒä»¥é€‚é…Inception v3"""
        # è½¬æ¢ä¸ºåˆ—è¡¨å¤„ç†
        if not isinstance(images, list):
            if len(images.shape) == 3:
                # å•å¼ å›¾åƒ (H, W, C)
                images = [images]
            elif len(images.shape) == 4:
                # æ‰¹é‡å›¾åƒ (N, H, W, C)
                images = [images[i] for i in range(images.shape[0])]
        
        # ã€æ–°å¢ã€‘è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜
        if auto_crop:
            cropped_images = []
            for img in images:
                if len(img.shape) == 2:
                    img = np.expand_dims(img, axis=-1)
                cropped, _ = crop_black_borders(img)
                cropped_images.append(cropped)
            images = cropped_images
        
        # è°ƒæ•´å¤§å°åˆ°299x299å¹¶æ ‡å‡†åŒ–ï¼ˆInception v3è¾“å…¥å°ºå¯¸ï¼‰
        processed = []
        for img in images:
            # è½¬æ¢ä¸º (C, H, W)
            if img.shape[-1] in [1, 3]:
                img = np.transpose(img, (2, 0, 1))
            
            # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœæ˜¯ç°åº¦å›¾ï¼‰
            if img.shape[0] == 1:
                img = np.repeat(img, 3, axis=0)
            
            img_tensor = torch.from_numpy(img).float()
            if img_tensor.max() > 1.0:
                img_tensor = img_tensor / 255.0
            
            img_resized = F.interpolate(img_tensor.unsqueeze(0), 
                                       size=(299, 299), 
                                       mode='bilinear', 
                                       align_corners=False)
            # Inception v3æ ‡å‡†åŒ–
            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                            std=[0.229, 0.224, 0.225])
            img_normalized = normalize(img_resized.squeeze(0))
            processed.append(img_normalized)
        
        return torch.stack(processed)
    
    def get_activations(images, model, batch_size, device):
        """æå–å›¾åƒçš„Inceptionç‰¹å¾"""
        model.eval()
        activations = []
        
        with torch.no_grad():
            for i in range(0, len(images), batch_size):
                batch = images[i:i+batch_size].to(device)
                pred = model(batch)
                activations.append(pred.cpu().numpy())
        
        return np.concatenate(activations, axis=0)
    
    def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):
        """è®¡ç®—ä¸¤ä¸ªå¤šå…ƒé«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„FrÃ©chetè·ç¦»"""
        mu1 = np.atleast_1d(mu1)
        mu2 = np.atleast_1d(mu2)
        sigma1 = np.atleast_2d(sigma1)
        sigma2 = np.atleast_2d(sigma2)
        
        diff = mu1 - mu2
        
        # è®¡ç®— sqrt(sigma1 * sigma2)
        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)
        
        # å¤„ç†æ•°å€¼è¯¯å·®
        if not np.isfinite(covmean).all():
            offset = np.eye(sigma1.shape[0]) * eps
            covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))
        
        # å¤„ç†è™šæ•°éƒ¨åˆ†
        if np.iscomplexobj(covmean):
            if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):
                m = np.max(np.abs(covmean.imag))
                raise ValueError('Imaginary component {}'.format(m))
            covmean = covmean.real
        
        tr_covmean = np.trace(covmean)
        
        fid = diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean

        # å¦‚æœFIDä¸ºè´Ÿæ•°ç›´æ¥èµ‹å€¼ä¸º0ï¼Ÿ
        if fid < 1e-6:
            return 0.00
        else:
            return fid
    
    # é¢„å¤„ç†å›¾åƒ
    real_preprocessed = preprocess_images(real_images, auto_crop=auto_crop)
    generated_preprocessed = preprocess_images(generated_images, auto_crop=auto_crop)
    
    # æå–ç‰¹å¾
    real_activations = get_activations(real_preprocessed, inception_model, batch_size, device)
    generated_activations = get_activations(generated_preprocessed, inception_model, batch_size, device)
    
    # è®¡ç®—ç»Ÿè®¡é‡ï¼ˆå¯¹å°æ ·æœ¬åšç¨³å¥å¤„ç†ï¼Œé¿å…NaNï¼‰
    mu_real = np.mean(real_activations, axis=0)
    mu_generated = np.mean(generated_activations, axis=0)
    if real_activations.shape[0] < 2:
        sigma_real = np.zeros((real_activations.shape[1], real_activations.shape[1]))
    else:
        sigma_real = np.cov(real_activations, rowvar=False)
    if generated_activations.shape[0] < 2:
        sigma_generated = np.zeros((generated_activations.shape[1], generated_activations.shape[1]))
    else:
        sigma_generated = np.cov(generated_activations, rowvar=False)
    
    # è®¡ç®—FID
    fid_value = calculate_frechet_distance(mu_real, sigma_real, 
                                          mu_generated, sigma_generated)
    
    return float(fid_value)



#---------------------------------------------------------------æ•´åˆæ–¹æ³•ï¼šä¸¤ä¸ªæ•°æ®é›†FIDå¯¹æ¯”-------------------------------------------------------------------

def calculate_fid_between_datasets(dataset1_path, dataset2_path, batch_size=50, device='cuda', auto_crop=True):
    """
    æ•´åˆæ–¹æ³•ï¼šè®¡ç®—ä¸¤ä¸ªæ•°æ®é›†ä¹‹é—´çš„FIDå€¼
    
    å‚æ•°:
        dataset1_path: strï¼Œç¬¬ä¸€ä¸ªæ•°æ®é›†çš„è·¯å¾„
        dataset2_path: strï¼Œç¬¬äºŒä¸ªæ•°æ®é›†çš„è·¯å¾„
        batch_size: intï¼Œæ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤50
        device: strï¼Œè®¡ç®—è®¾å¤‡ 'cuda' æˆ– 'cpu'ï¼Œé»˜è®¤'cuda'
        auto_crop: boolï¼Œæ˜¯å¦è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼Œé»˜è®¤True
    
    è¿”å›:
        float: FIDå€¼ï¼Œè¶Šå°è¡¨ç¤ºä¸¤ä¸ªæ•°æ®é›†åˆ†å¸ƒè¶Šæ¥è¿‘
    """
    print("\n" + "="*70)
    print("ğŸ” è®¡ç®—ä¸¤ä¸ªæ•°æ®é›†ä¹‹é—´çš„ FID (FrÃ©chet Inception Distance)")
    print("="*70)
    print(f"æ•°æ®é›†1: {dataset1_path}")
    print(f"æ•°æ®é›†2: {dataset2_path}")
    
    def load_images_from_folder(folder_path):
        """ä»æ–‡ä»¶å¤¹åŠ è½½æ‰€æœ‰å›¾åƒ"""
        if not os.path.exists(folder_path):
            print(f"âŒ é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {folder_path}")
            return None
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']
        image_files = []
        for ext in image_extensions:
            image_files.extend([f for f in os.listdir(folder_path) if f.lower().endswith(ext)])
        
        print(f"åœ¨è·¯å¾„ {folder_path} ä¸­æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        if len(image_files) == 0:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return None
        
        # è¯»å–å›¾åƒ
        print("æ­£åœ¨åŠ è½½å›¾åƒ...")
        images = []
        valid_count = 0
        
        for img_file in image_files:
            try:
                img_path = os.path.join(folder_path, img_file)
                img = Image.open(img_path)
                img_array = np.array(img)
                
                # ç¡®ä¿å›¾åƒæ˜¯3é€šé“
                if len(img_array.shape) == 2:
                    img_array = np.stack([img_array] * 3, axis=-1)
                elif img_array.shape[2] == 4:
                    img_array = img_array[:, :, :3]  # ç§»é™¤alphaé€šé“
                
                images.append(img_array)
                valid_count += 1
                
                if valid_count % 50 == 0:  # æ¯50å¼ å›¾åƒæ‰“å°ä¸€æ¬¡è¿›åº¦
                    print(f"  å·²åŠ è½½ {valid_count} å¼ å›¾åƒ...")
                    
            except Exception as e:
                print(f"  è­¦å‘Š: åŠ è½½å›¾åƒ {img_file} æ—¶å‡ºé”™: {e}")
                continue
        
        if valid_count == 0:
            print("âŒ é”™è¯¯: æ— æ³•åŠ è½½ä»»ä½•æœ‰æ•ˆå›¾åƒ")
            return None
        
        print(f"âœ… æˆåŠŸåŠ è½½ {valid_count} å¼ å›¾åƒ")
        return images
    
    # åŠ è½½ä¸¤ä¸ªæ•°æ®é›†
    print(f"\nğŸ“ åŠ è½½æ•°æ®é›†1...")
    dataset1_images = load_images_from_folder(dataset1_path)
    
    print(f"\nğŸ“ åŠ è½½æ•°æ®é›†2...")
    dataset2_images = load_images_from_folder(dataset2_path)
    
    if dataset1_images is None or dataset2_images is None:
        print("âŒ é”™è¯¯: æ— æ³•åŠ è½½ä¸€ä¸ªæˆ–ä¸¤ä¸ªæ•°æ®é›†")
        return None
    
    # æ£€æŸ¥å›¾åƒæ•°é‡
    count1 = len(dataset1_images)
    count2 = len(dataset2_images)
    
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  æ•°æ®é›†1: {count1} å¼ å›¾åƒ")
    print(f"  æ•°æ®é›†2: {count2} å¼ å›¾åƒ")
    
    # è®¡ç®—FID
    print(f"\nğŸš€ å¼€å§‹è®¡ç®— FID...")
    try:
        fid_value = calculate_fid(
            real_images=dataset1_images,
            generated_images=dataset2_images,
            batch_size=batch_size,
            device=device,
            auto_crop=auto_crop
        )
        
        print(f"\n" + "="*70)
        print("ğŸ¯ FID è®¡ç®—ç»“æœ")
        print("="*70)
        print(f"FID å€¼: {fid_value:.4f}")
        print(f"æ•°æ®é›†1: {count1} å¼ å›¾åƒ")
        print(f"æ•°æ®é›†2: {count2} å¼ å›¾åƒ")
        
        # æä¾›è´¨é‡è§£é‡Š
        print(f"\nğŸ“Š åˆ†å¸ƒç›¸ä¼¼æ€§è¯„ä¼°:")
        if fid_value < 10:
            print("  âœ… éå¸¸ç›¸ä¼¼ - ä¸¤ä¸ªæ•°æ®é›†çš„åˆ†å¸ƒå‡ ä¹ç›¸åŒ")
        elif fid_value < 25:
            print("  âœ… æ¯”è¾ƒç›¸ä¼¼ - ä¸¤ä¸ªæ•°æ®é›†çš„åˆ†å¸ƒè¾ƒä¸ºæ¥è¿‘")
        elif fid_value < 50:
            print("  âš ï¸  ä¸­ç­‰ç›¸ä¼¼ - ä¸¤ä¸ªæ•°æ®é›†çš„åˆ†å¸ƒæœ‰ä¸€å®šå·®å¼‚")
        elif fid_value < 100:
            print("  âš ï¸  å·®å¼‚è¾ƒå¤§ - ä¸¤ä¸ªæ•°æ®é›†çš„åˆ†å¸ƒå·®å¼‚æ˜æ˜¾")
        else:
            print("  âŒ å·®å¼‚å¾ˆå¤§ - ä¸¤ä¸ªæ•°æ®é›†çš„åˆ†å¸ƒéå¸¸ä¸åŒ")
        
        print(f"\nğŸ’¡ FID è¯´æ˜:")
        print("  - FIDå€¼è¶Šä½ï¼Œè¡¨ç¤ºä¸¤ä¸ªæ•°æ®é›†çš„åˆ†å¸ƒè¶Šç›¸ä¼¼")
        print("  - FID=0 è¡¨ç¤ºä¸¤ä¸ªæ•°æ®é›†åˆ†å¸ƒå®Œå…¨ç›¸åŒ")
        print("  - é€šå¸¸FID<50è¡¨ç¤ºä¸¤ä¸ªæ•°æ®é›†æ¯”è¾ƒç›¸ä¼¼")
        print("  - FID>100è¡¨ç¤ºä¸¤ä¸ªæ•°æ®é›†å·®å¼‚å¾ˆå¤§")
        
        return fid_value
        
    except Exception as e:
        print(f"âŒ è®¡ç®—FIDå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


#---------------------------------------------------------------æ•´åˆæ–¹æ³•ï¼šå¤šæ•°æ®é›†FIDå¯¹æ¯”çŸ©é˜µ-------------------------------------------------------------------

def compare_multiple_datasets_fid(dataset_paths, batch_size=50, device='cuda', auto_crop=True):
    """
    æ•´åˆæ–¹æ³•ï¼šå¯¹æ¯”å¤šä¸ªæ•°æ®é›†ä¹‹é—´çš„FIDå€¼ï¼ˆç”ŸæˆFIDçŸ©é˜µï¼‰
    
    å‚æ•°:
        dataset_paths: listï¼Œæ•°æ®é›†è·¯å¾„åˆ—è¡¨
        batch_size: intï¼Œæ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤50
        device: strï¼Œè®¡ç®—è®¾å¤‡ 'cuda' æˆ– 'cpu'ï¼Œé»˜è®¤'cuda'
        auto_crop: boolï¼Œæ˜¯å¦è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼Œé»˜è®¤True
    
    è¿”å›:
        dict: åŒ…å«æ‰€æœ‰FIDå¯¹æ¯”ç»“æœçš„å­—å…¸
    """
    print("\n" + "="*70)
    print("ğŸ” å¯¹æ¯”å¤šä¸ªæ•°æ®é›†ä¹‹é—´çš„ FID å€¼")
    print("="*70)
    
    n_datasets = len(dataset_paths)
    fid_matrix = np.zeros((n_datasets, n_datasets))
    results = {}
    
    # è®¡ç®—æ‰€æœ‰æ•°æ®é›†å¯¹ä¹‹é—´çš„FID
    for i in range(n_datasets):
        for j in range(i, n_datasets):  # åªè®¡ç®—ä¸Šä¸‰è§’çŸ©é˜µï¼Œå› ä¸ºFIDæ˜¯å¯¹ç§°çš„
            if i == j:
                fid_matrix[i, j] = 0.0  # ç›¸åŒæ•°æ®é›†çš„FIDä¸º0
            else:
                print(f"\nğŸ”„ è®¡ç®—æ•°æ®é›† {i+1} å’Œæ•°æ®é›† {j+1} ä¹‹é—´çš„FID...")
                fid_value = calculate_fid_between_datasets(
                    dataset_paths[i], 
                    dataset_paths[j],
                    batch_size=batch_size,
                    device=device,
                    auto_crop=auto_crop
                )
                
                if fid_value is not None:
                    fid_matrix[i, j] = fid_value
                    fid_matrix[j, i] = fid_value  # å¯¹ç§°çŸ©é˜µ
                    results[f'dataset{i+1}_vs_dataset{j+1}'] = {
                        'dataset1': dataset_paths[i],
                        'dataset2': dataset_paths[j],
                        'fid': fid_value
                    }
                else:
                    fid_matrix[i, j] = float('inf')
                    fid_matrix[j, i] = float('inf')
    
    # æ˜¾ç¤ºFIDçŸ©é˜µ
    print(f"\n" + "="*70)
    print("ğŸ“Š FID å¯¹æ¯”çŸ©é˜µ")
    print("="*70)
    
    # è¡¨å¤´
    header = " " * 15
    for i in range(n_datasets):
        header += f"æ•°æ®é›†{i+1}".center(12)
    print(header)
    
    # çŸ©é˜µå†…å®¹
    for i in range(n_datasets):
        row = f"æ•°æ®é›†{i+1}".ljust(15)
        for j in range(n_datasets):
            if i == j:
                row += "    0.0    "
            else:
                row += f"  {fid_matrix[i, j]:7.2f}  "
        print(row)
    
    # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„æ•°æ®é›†å¯¹
    min_fid = float('inf')
    min_pair = None
    
    for i in range(n_datasets):
        for j in range(i+1, n_datasets):
            if fid_matrix[i, j] < min_fid:
                min_fid = fid_matrix[i, j]
                min_pair = (i+1, j+1)
    
    if min_pair is not None:
        print(f"\nâœ… æœ€ç›¸ä¼¼çš„æ•°æ®é›†å¯¹: æ•°æ®é›†{min_pair[0]} å’Œ æ•°æ®é›†{min_pair[1]}")
        print(f"   FIDå€¼: {min_fid:.4f}")
    
    return {
        'fid_matrix': fid_matrix,
        'results': results,
        'dataset_paths': dataset_paths
    }
    
    
    
def calculate_inception_score(generated_images, batch_size=32, splits=10, device='cuda', auto_crop=True):
    """
    è®¡ç®—Inception Score (IS, Inceptionåˆ†æ•°)
    
    ISåŸºäº Inception v3 ç½‘ç»œè®¡ç®—ç”Ÿæˆå›¾åƒçš„"åˆ†ç±»ç½®ä¿¡åº¦"ä¸"ç±»åˆ«å¤šæ ·æ€§"
    æ•°å€¼è¶Šé«˜è¡¨ç¤ºç”Ÿæˆå›¾åƒçš„ç»†èŠ‚è¶Šæ¸…æ™°ã€å¤šæ ·æ€§è¶Šä¼˜ï¼Œè´¨é‡è¶Šå¥½
    
    è¯¥æŒ‡æ ‡è¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¤šæ ·æ€§
    
    ã€æ”¹è¿›ã€‘è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼ˆé…å‡†äº§ç”Ÿçš„å¡«å……åŒºåŸŸï¼‰ï¼Œç¡®ä¿è¯„ä¼°åªå…³æ³¨æœ‰æ•ˆåŒºåŸŸ
    
    å‚è€ƒå®ç°:
    - inception-score-pytorch (https://github.com/sbarratt/inception-score-pytorch)
    - torch-fidelity (https://github.com/toshas/torch-fidelity)
    - torchmetrics (https://torchmetrics.readthedocs.io/)
    
    å‚æ•°:
        generated_images: numpyæ•°ç»„åˆ—è¡¨æˆ–å•ä¸ª4Dæ•°ç»„ï¼Œç”Ÿæˆå›¾åƒé›† (N, H, W, C) æˆ– list of (H, W, C)
        batch_size: intï¼Œæ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤32
        splits: intï¼Œè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®æ—¶çš„åˆ†å‰²æ•°ï¼Œé»˜è®¤10
        device: strï¼Œè®¡ç®—è®¾å¤‡ 'cuda' æˆ– 'cpu'ï¼Œé»˜è®¤'cuda'
        auto_crop: boolï¼Œæ˜¯å¦è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼Œé»˜è®¤True
    
    è¿”å›:
        tuple: (ISå‡å€¼, ISæ ‡å‡†å·®)
    """
    if not torch.cuda.is_available():
        device = 'cpu'
    
    # åŠ è½½é¢„è®­ç»ƒçš„Inception v3æ¨¡å‹
    inception_model = models.inception_v3(pretrained=True, transform_input=False)
    inception_model = inception_model.to(device)
    inception_model.eval()
    
    def preprocess_images(images, auto_crop=True):
        """é¢„å¤„ç†å›¾åƒä»¥é€‚é…Inception v3 - ä¸FIDä½¿ç”¨ç›¸åŒçš„é¢„å¤„ç†é€»è¾‘"""
        # è½¬æ¢ä¸ºåˆ—è¡¨å¤„ç†
        if not isinstance(images, list):
            if len(images.shape) == 3:
                # å•å¼ å›¾åƒ (H, W, C)
                images = [images]
            elif len(images.shape) == 4:
                # æ‰¹é‡å›¾åƒ (N, H, W, C)
                images = [images[i] for i in range(images.shape[0])]
        
        # ã€æ–°å¢ã€‘è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜
        if auto_crop:
            cropped_images = []
            for img in images:
                if len(img.shape) == 2:
                    img = np.expand_dims(img, axis=-1)
                cropped, _ = crop_black_borders(img)
                cropped_images.append(cropped)
            images = cropped_images
        
        # è°ƒæ•´å¤§å°åˆ°299x299å¹¶æ ‡å‡†åŒ–ï¼ˆInception v3è¾“å…¥å°ºå¯¸ï¼‰
        processed = []
        for img in images:
            # è½¬æ¢ä¸º (C, H, W)
            if img.shape[-1] in [1, 3]:
                img = np.transpose(img, (2, 0, 1))
            
            # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœæ˜¯ç°åº¦å›¾ï¼‰
            if img.shape[0] == 1:
                img = np.repeat(img, 3, axis=0)
            
            img_tensor = torch.from_numpy(img).float()
            if img_tensor.max() > 1.0:
                img_tensor = img_tensor / 255.0
            
            img_resized = F.interpolate(img_tensor.unsqueeze(0), 
                                       size=(299, 299), 
                                       mode='bilinear', 
                                       align_corners=False)
            # Inception v3æ ‡å‡†åŒ–
            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                            std=[0.229, 0.224, 0.225])
            img_normalized = normalize(img_resized.squeeze(0))
            processed.append(img_normalized)
        
        return torch.stack(processed)
    
    # é¢„å¤„ç†å›¾åƒ
    preprocessed = preprocess_images(generated_images, auto_crop=auto_crop)
    
    # æ‰¹é‡è®¡ç®—é¢„æµ‹ - ä½¿ç”¨æ‚¨çš„è®¡ç®—é€»è¾‘
    print("å¼€å§‹æ‰¹é‡è®¡ç®—é¢„æµ‹...")
    preds = []
    with torch.no_grad():
        for i in range(0, len(preprocessed), batch_size):
            batch = preprocessed[i:i+batch_size].to(device)
            output = inception_model(batch)
            pred = F.softmax(output, dim=1)
            preds.append(pred.cpu().numpy())
            
            if i % (batch_size * 10) == 0:  # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡è¿›åº¦
                print(f"å·²å¤„ç† {min(i+batch_size, len(preprocessed))}/{len(preprocessed)} å¼ å›¾åƒ")
    
    preds = np.concatenate(preds, axis=0)
    
    # è®¡ç®—Inception Score - ä½¿ç”¨æ‚¨çš„è®¡ç®—é€»è¾‘
    print("è®¡ç®—Inception Score...")
    N = preds.shape[0]
    if N == 0:
        return float("nan"), float("nan")
    splits = max(1, min(splits, N))
    scores = []
    parts = np.array_split(preds, splits, axis=0)
    for part in parts:
        if part.shape[0] == 0:
            continue
        kl_div = part * (np.log(part + 1e-12) - np.log(np.expand_dims(np.mean(part, 0) + 1e-12, 0)))
        kl_div = np.mean(np.sum(kl_div, 1))
        scores.append(np.exp(kl_div))
    
    is_mean = np.mean(scores)
    is_std = np.std(scores)
    
    print(f"Inception Scoreè®¡ç®—å®Œæˆ: {is_mean:.4f} Â± {is_std:.4f}")
    
    return float(is_mean), float(is_std)
# def calculate_inception_score(generated_images, batch_size=32, splits=10, device='cuda', auto_crop=True):
#     """
#     è®¡ç®—Inception Score (IS, Inceptionåˆ†æ•°)
    
#     ISåŸºäº Inception v3 ç½‘ç»œè®¡ç®—ç”Ÿæˆå›¾åƒçš„"åˆ†ç±»ç½®ä¿¡åº¦"ä¸"ç±»åˆ«å¤šæ ·æ€§"
#     æ•°å€¼è¶Šé«˜è¡¨ç¤ºç”Ÿæˆå›¾åƒçš„ç»†èŠ‚è¶Šæ¸…æ™°ã€å¤šæ ·æ€§è¶Šä¼˜ï¼Œè´¨é‡è¶Šå¥½
    
#     è¯¥æŒ‡æ ‡è¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¤šæ ·æ€§
    
#     ã€æ”¹è¿›ã€‘è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼ˆé…å‡†äº§ç”Ÿçš„å¡«å……åŒºåŸŸï¼‰ï¼Œç¡®ä¿è¯„ä¼°åªå…³æ³¨æœ‰æ•ˆåŒºåŸŸ
    
#     å‚è€ƒå®ç°:
#     - inception-score-pytorch (https://github.com/sbarratt/inception-score-pytorch)
#     - torch-fidelity (https://github.com/toshas/torch-fidelity)
#     - torchmetrics (https://torchmetrics.readthedocs.io/)
    
#     å‚æ•°:
#         generated_images: numpyæ•°ç»„åˆ—è¡¨æˆ–å•ä¸ª4Dæ•°ç»„ï¼Œç”Ÿæˆå›¾åƒé›† (N, H, W, C) æˆ– list of (H, W, C)
#         batch_size: intï¼Œæ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤32
#         splits: intï¼Œè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®æ—¶çš„åˆ†å‰²æ•°ï¼Œé»˜è®¤10
#         device: strï¼Œè®¡ç®—è®¾å¤‡ 'cuda' æˆ– 'cpu'ï¼Œé»˜è®¤'cuda'
#         auto_crop: boolï¼Œæ˜¯å¦è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼Œé»˜è®¤True
    
#     è¿”å›:
#         tuple: (ISå‡å€¼, ISæ ‡å‡†å·®)
#     """
#     if not torch.cuda.is_available():
#         device = 'cpu'
    
#     # åŠ è½½é¢„è®­ç»ƒçš„Inception v3æ¨¡å‹
#     inception_model = models.inception_v3(pretrained=True, transform_input=False)
#     inception_model = inception_model.to(device)
#     inception_model.eval()
    
#     def preprocess_images(images, auto_crop=True):
#         """é¢„å¤„ç†å›¾åƒä»¥é€‚é…Inception v3"""
#         # è½¬æ¢ä¸ºåˆ—è¡¨å¤„ç†
#         if not isinstance(images, list):
#             if len(images.shape) == 3:
#                 # å•å¼ å›¾åƒ (H, W, C)
#                 images = [images]
#             elif len(images.shape) == 4:
#                 # æ‰¹é‡å›¾åƒ (N, H, W, C)
#                 images = [images[i] for i in range(images.shape[0])]
        
#         # ã€æ–°å¢ã€‘è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜
#         if auto_crop:
#             cropped_images = []
#             for img in images:
#                 if len(img.shape) == 2:
#                     img = np.expand_dims(img, axis=-1)
#                 cropped, _ = crop_black_borders(img)
#                 cropped_images.append(cropped)
#             images = cropped_images
        
#         # è°ƒæ•´å¤§å°åˆ°299x299å¹¶æ ‡å‡†åŒ–ï¼ˆInception v3è¾“å…¥å°ºå¯¸ï¼‰
#         processed = []
#         for img in images:
#             # è½¬æ¢ä¸º (C, H, W)
#             if img.shape[-1] in [1, 3]:
#                 img = np.transpose(img, (2, 0, 1))
            
#             # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœæ˜¯ç°åº¦å›¾ï¼‰
#             if img.shape[0] == 1:
#                 img = np.repeat(img, 3, axis=0)
            
#             img_tensor = torch.from_numpy(img).float()
#             if img_tensor.max() > 1.0:
#                 img_tensor = img_tensor / 255.0
            
#             img_resized = F.interpolate(img_tensor.unsqueeze(0), 
#                                        size=(299, 299), 
#                                        mode='bilinear', 
#                                        align_corners=False)
#             # Inception v3æ ‡å‡†åŒ–
#             normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
#                                             std=[0.229, 0.224, 0.225])
#             img_normalized = normalize(img_resized.squeeze(0))
#             processed.append(img_normalized)
        
#         return torch.stack(processed)
    
#     def get_predictions(images, model, batch_size, device):
#         """è·å–åˆ†ç±»é¢„æµ‹æ¦‚ç‡"""
#         model.eval()
#         preds = []
        
#         with torch.no_grad():
#             for i in range(0, len(images), batch_size):
#                 batch = images[i:i+batch_size].to(device)
#                 pred = F.softmax(model(batch), dim=1)
#                 preds.append(pred.cpu().numpy())
        
#         return np.concatenate(preds, axis=0)
    
#     # é¢„å¤„ç†å›¾åƒ
#     preprocessed = preprocess_images(generated_images, auto_crop=auto_crop)
    
#     # è·å–é¢„æµ‹æ¦‚ç‡
#     preds = get_predictions(preprocessed, inception_model, batch_size, device)
    
#     # è®¡ç®—Inception Score
#     split_scores = []
#     N = preds.shape[0]
    
#     for k in range(splits):
#         part = preds[k * (N // splits): (k + 1) * (N // splits), :]
#         # p(y)
#         py = np.mean(part, axis=0)
#         # KLæ•£åº¦
#         scores = []
#         for i in range(part.shape[0]):
#             pyx = part[i, :]
#             scores.append(np.sum(pyx * (np.log(pyx + 1e-10) - np.log(py + 1e-10))))
#         split_scores.append(np.exp(np.mean(scores)))
    
#     is_mean = np.mean(split_scores)
#     is_std = np.std(split_scores)
    
#     return float(is_mean), float(is_std)
#---------------------------------------------------------------æ•´åˆæ–¹æ³•ï¼šå•ä¸ªæ•°æ®é›†ISè®¡ç®—-------------------------------------------------------------------

def calculate_dataset_is(dataset_path, batch_size=32, splits=10, auto_crop=True):
    """
    æ•´åˆæ–¹æ³•ï¼šè®¡ç®—å•ä¸ªæ•°æ®é›†çš„Inception Score (IS)
    
    å‚æ•°:
        dataset_path: strï¼Œæ•°æ®é›†çš„è·¯å¾„ï¼ˆåŒ…å«å›¾åƒæ–‡ä»¶çš„æ–‡ä»¶å¤¹ï¼‰
        batch_size: intï¼Œæ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤32
        splits: intï¼Œè®¡ç®—ISæ—¶çš„åˆ†å‰²æ•°ï¼Œé»˜è®¤10
        auto_crop: boolï¼Œæ˜¯å¦è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼Œé»˜è®¤True
    
    è¿”å›:
        tuple: (ISå‡å€¼, ISæ ‡å‡†å·®, å›¾åƒæ•°é‡)
    """
    print("\n" + "="*70)
    print(f"è®¡ç®—æ•°æ®é›† Inception Score")
    print("="*70)
    print(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_path):
        print(f"âŒ é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        return None, None, 0
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']
    image_files = []
    for ext in image_extensions:
        image_files.extend([f for f in os.listdir(dataset_path) if f.lower().endswith(ext)])
    
    print(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    if len(image_files) == 0:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
        return None, None, 0
    
    # è¯»å–å›¾åƒ
    print("æ­£åœ¨åŠ è½½å›¾åƒ...")
    images = []
    valid_count = 0
    
    for img_file in image_files:
        try:
            img_path = os.path.join(dataset_path, img_file)
            img = Image.open(img_path)
            img_array = np.array(img)
            
            # ç¡®ä¿å›¾åƒæ˜¯3é€šé“
            if len(img_array.shape) == 2:
                img_array = np.stack([img_array] * 3, axis=-1)
            elif img_array.shape[2] == 4:
                img_array = img_array[:, :, :3]  # ç§»é™¤alphaé€šé“
            
            images.append(img_array)
            valid_count += 1
            
            if valid_count % 50 == 0:  # æ¯50å¼ å›¾åƒæ‰“å°ä¸€æ¬¡è¿›åº¦
                print(f"  å·²åŠ è½½ {valid_count} å¼ å›¾åƒ...")
                
        except Exception as e:
            print(f"  è­¦å‘Š: åŠ è½½å›¾åƒ {img_file} æ—¶å‡ºé”™: {e}")
            continue
    
    if valid_count == 0:
        print("âŒ é”™è¯¯: æ— æ³•åŠ è½½ä»»ä½•æœ‰æ•ˆå›¾åƒ")
        return None, None, 0
    
    print(f"âœ… æˆåŠŸåŠ è½½ {valid_count} å¼ å›¾åƒ")
    
    # è®¡ç®—IS
    print(f"\nå¼€å§‹è®¡ç®— Inception Score...")
    try:
        is_mean, is_std = calculate_inception_score(
            images, 
            batch_size=batch_size, 
            splits=splits,
            auto_crop=auto_crop
        )
        
        print(f"\n" + "="*70)
        print("ğŸ¯ IS è®¡ç®—ç»“æœ")
        print("="*70)
        print(f"IS åˆ†æ•°: {is_mean:.4f} Â± {is_std:.4f}")
        print(f"å›¾åƒæ•°é‡: {valid_count}")
        
        # æä¾›è´¨é‡è§£é‡Š
        print(f"\nğŸ“Š è´¨é‡è¯„ä¼°:")
        if is_mean > 20:
            print("  âœ… ä¼˜ç§€ - å›¾åƒè´¨é‡å¾ˆé«˜ï¼Œå¤šæ ·æ€§å¾ˆå¥½")
        elif is_mean > 10:
            print("  âœ… è‰¯å¥½ - å›¾åƒè´¨é‡è¾ƒå¥½ï¼Œå¤šæ ·æ€§ä¸é”™")  
        elif is_mean > 5:
            print("  âš ï¸  ä¸­ç­‰ - å›¾åƒè´¨é‡ä¸­ç­‰ï¼Œå¤šæ ·æ€§ä¸€èˆ¬")
        elif is_mean > 2:
            print("  âš ï¸  ä¸€èˆ¬ - å›¾åƒè´¨é‡æˆ–å¤šæ ·æ€§æœ‰å¾…æé«˜")
        else:
            print("  âŒ è¾ƒå·® - å›¾åƒè´¨é‡æˆ–å¤šæ ·æ€§è¾ƒä½")
        
        print(f"\nğŸ’¡ è¯´æ˜:")
        print("  - ISåˆ†æ•°è¶Šé«˜ï¼Œè¡¨ç¤ºå›¾åƒè´¨é‡è¶Šå¥½ã€å¤šæ ·æ€§è¶Šé«˜")
        print("  - é€šå¸¸CIFAR-10çš„ISåœ¨8.0-9.0ä¹‹é—´")
        print("  - é«˜è´¨é‡ç”Ÿæˆæ¨¡å‹çš„ISé€šå¸¸èƒ½è¾¾åˆ°20+")
        
        return is_mean, is_std, valid_count
        
    except Exception as e:
        print(f"âŒ è®¡ç®—ISå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None, 0


#---------------------------------------------------------------æ•´åˆæ–¹æ³•ï¼šå¤šä¸ªæ•°æ®é›†ISå¯¹æ¯”-------------------------------------------------------------------

def compare_datasets_is(dataset_paths, batch_size=32, splits=10, auto_crop=True):
    """
    æ•´åˆæ–¹æ³•ï¼šå¯¹æ¯”å¤šä¸ªæ•°æ®é›†çš„Inception Score (IS)
    
    å‚æ•°:
        dataset_paths: listï¼Œæ•°æ®é›†è·¯å¾„åˆ—è¡¨
        batch_size: intï¼Œæ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤32
        splits: intï¼Œè®¡ç®—ISæ—¶çš„åˆ†å‰²æ•°ï¼Œé»˜è®¤10
        auto_crop: boolï¼Œæ˜¯å¦è‡ªåŠ¨è£å‰ªé»‘è‰²è¾¹ç¼˜ï¼Œé»˜è®¤True
    
    è¿”å›:
        dict: åŒ…å«æ‰€æœ‰æ•°æ®é›†ISç»“æœçš„å­—å…¸
    """
    print("\n" + "="*70)
    print("ğŸ” å¯¹æ¯”å¤šä¸ªæ•°æ®é›†çš„ Inception Score")
    print("="*70)
    
    results = {}
    
    for i, dataset_path in enumerate(dataset_paths, 1):
        print(f"\nğŸ“ å¤„ç†æ•°æ®é›† {i}/{len(dataset_paths)}: {dataset_path}")
        is_mean, is_std, count = calculate_dataset_is(dataset_path, batch_size, splits, auto_crop)
        
        if is_mean is not None:
            results[f'dataset{i}'] = {
                'path': dataset_path,
                'mean': is_mean,
                'std': is_std,
                'count': count
            }
    
    # å¯¹æ¯”åˆ†æ
    if len(results) > 1:
        print("\n" + "="*70)
        print("ğŸ“ˆ å¯¹æ¯”åˆ†æç»“æœ")
        print("="*70)
        
        # æŒ‰ISåˆ†æ•°æ’åº
        sorted_results = sorted(results.items(), key=lambda x: x[1]['mean'], reverse=True)
        
        for rank, (name, data) in enumerate(sorted_results, 1):
            medal = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else f"{rank}."
            print(f"{medal} {name}: {data['mean']:.4f} Â± {data['std']:.4f} (å…± {data['count']} å¼ å›¾åƒ)")
            print(f"   è·¯å¾„: {data['path']}")
        
        # æ˜¾ç¤ºæœ€ä½³æ•°æ®é›†
        best_name, best_data = sorted_results[0]
        print(f"\nâœ… æœ€ä½³æ•°æ®é›†: {best_name}")
        print(f"   ISåˆ†æ•°: {best_data['mean']:.4f}")
        print(f"   è·¯å¾„: {best_data['path']}")
    
    return results

# ä¾¿æ·å‡½æ•°ï¼šæ‰¹é‡è®¡ç®—æ‰€æœ‰æ ¸å¿ƒæŒ‡æ ‡
def calculate_all_metrics(generated_image, real_image, data_range=None):
    """
    æ‰¹é‡è®¡ç®—æ‰€æœ‰æ ¸å¿ƒå›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼ˆPSNR, MS-SSIMï¼‰
    
    æ³¨æ„ï¼šFIDå’ŒISéœ€è¦å¤šå¼ å›¾åƒæ‰èƒ½è®¡ç®—ï¼Œè¯·å•ç‹¬è°ƒç”¨ calculate_fid() å’Œ calculate_inception_score()
    
    å‚æ•°:
        generated_image: numpyæ•°ç»„ï¼Œç”Ÿæˆçš„å›¾åƒ (H, W, C) æˆ– (H, W)
        real_image: numpyæ•°ç»„ï¼ŒçœŸå®å›¾åƒ (H, W, C) æˆ– (H, W)
        data_range: floatï¼Œæ•°æ®èŒƒå›´ï¼Œé»˜è®¤è‡ªåŠ¨æ¨æ–­
    
    è¿”å›:
        dict: åŒ…å«PSNRå’ŒMS-SSIMçš„å­—å…¸
    """
    metrics = {}
    
    try:
        metrics['PSNR'] = calculate_psnr(generated_image, real_image, data_range)
    except Exception as e:
        print("è®¡ç®—PSNRå¤±è´¥: {}".format(e))
        metrics['PSNR'] = None
    
    try:
        metrics['MS-SSIM'] = calculate_ms_ssim(generated_image, real_image, data_range)
    except Exception as e:
        print("è®¡ç®—MS-SSIMå¤±è´¥: {}".format(e))
        metrics['MS-SSIM'] = None
    
    return metrics


# ============ äº®åº¦å½’ä¸€åŒ–ä¸ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ ‡ ============

def histogram_matching(source, template):
    """
    ç›´æ–¹å›¾åŒ¹é…ï¼šå°†sourceçš„ç›´æ–¹å›¾åŒ¹é…åˆ°templateçš„ç›´æ–¹å›¾
    
    å‚æ•°:
        source: numpy array, æºå›¾åƒ (H, W) æˆ– (H, W, C)
        template: numpy array, æ¨¡æ¿å›¾åƒ (H, W) æˆ– (H, W, C)
    
    è¿”å›:
        matched: numpy array, åŒ¹é…åçš„å›¾åƒï¼Œä¸sourceåŒshape
    """
    source = np.asarray(source)
    template = np.asarray(template)
    
    # å¦‚æœæ˜¯å¤šé€šé“ï¼Œå¯¹æ¯ä¸ªé€šé“åˆ†åˆ«å¤„ç†
    if source.ndim == 3:
        matched = np.zeros_like(source)
        for c in range(source.shape[2]):
            matched[:, :, c] = _histogram_match_1d(source[:, :, c], template[:, :, c])
        return matched
    else:
        return _histogram_match_1d(source, template)


def _histogram_match_1d(source, template):
    """å•é€šé“ç›´æ–¹å›¾åŒ¹é…"""
    # è®¡ç®—ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
    source_values, source_counts = np.unique(source, return_counts=True)
    template_values, template_counts = np.unique(template, return_counts=True)
    
    source_cdf = np.cumsum(source_counts).astype(np.float64)
    source_cdf = source_cdf / source_cdf[-1]
    
    template_cdf = np.cumsum(template_counts).astype(np.float64)
    template_cdf = template_cdf / template_cdf[-1]
    
    # åˆ›å»ºæ˜ å°„è¡¨
    matched = np.zeros_like(source)
    for i, val in enumerate(source_values):
        # æ‰¾åˆ°templateä¸­CDFå€¼æœ€æ¥è¿‘çš„åƒç´ å€¼
        idx = np.argmin(np.abs(template_cdf - source_cdf[i]))
        matched[source == val] = template_values[idx]
    
    return matched.astype(source.dtype)


def mean_std_normalization(img1, img2):
    """
    å‡å€¼-æ ‡å‡†å·®å½’ä¸€åŒ–ï¼šå°†img1çš„å‡å€¼å’Œæ ‡å‡†å·®åŒ¹é…åˆ°img2
    
    å‚æ•°:
        img1: numpy array, è¦å½’ä¸€åŒ–çš„å›¾åƒ
        img2: numpy array, ç›®æ ‡å›¾åƒ
    
    è¿”å›:
        normalized: numpy array, å½’ä¸€åŒ–åçš„img1
    """
    img1 = np.asarray(img1, dtype=np.float64)
    img2 = np.asarray(img2, dtype=np.float64)
    
    # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆæ’é™¤é»‘è‰²åŒºåŸŸï¼‰
    mask1 = img1 > 10 if img1.ndim == 2 else np.any(img1 > 10, axis=-1)
    mask2 = img2 > 10 if img2.ndim == 2 else np.any(img2 > 10, axis=-1)
    valid_mask = mask1 & mask2
    
    if img1.ndim == 3:
        for c in range(img1.shape[2]):
            if valid_mask.sum() > 0:
                mean1 = img1[:, :, c][valid_mask].mean()
                std1 = img1[:, :, c][valid_mask].std()
                mean2 = img2[:, :, c][valid_mask].mean()
                std2 = img2[:, :, c][valid_mask].std()
                
                if std1 > 1e-6:
                    img1[:, :, c] = (img1[:, :, c] - mean1) / std1 * std2 + mean2
                else:
                    img1[:, :, c] = img1[:, :, c] - mean1 + mean2
    else:
        if valid_mask.sum() > 0:
            mean1 = img1[valid_mask].mean()
            std1 = img1[valid_mask].std()
            mean2 = img2[valid_mask].mean()
            std2 = img2[valid_mask].std()
            
            if std1 > 1e-6:
                img1 = (img1 - mean1) / std1 * std2 + mean2
            else:
                img1 = img1 - mean1 + mean2
    
    return np.clip(img1, 0, 255).astype(np.uint8)


def gradient_similarity(img1, img2):
    """
    åŸºäºæ¢¯åº¦çš„ç»“æ„ç›¸ä¼¼æ€§ï¼ˆä¸å—äº®åº¦åç§»å½±å“ï¼‰
    
    è¿”å›:
        gradient_sim: float, æ¢¯åº¦ç›¸ä¼¼åº¦ [0, 1]ï¼Œè¶Šé«˜è¶Šå¥½
    """
    img1 = np.asarray(img1, dtype=np.float64)
    img2 = np.asarray(img2, dtype=np.float64)
    
    # è½¬æ¢ä¸ºç°åº¦
    if img1.ndim == 3:
        img1 = np.mean(img1, axis=-1)
    if img2.ndim == 3:
        img2 = np.mean(img2, axis=-1)
    
    # è®¡ç®—æ¢¯åº¦
    if not _CV2_AVAILABLE:
        # å¦‚æœæ²¡æœ‰cv2ï¼Œä½¿ç”¨numpyå®ç°ç®€å•çš„æ¢¯åº¦
        grad1_x = np.diff(img1, axis=1, prepend=img1[:, :1])
        grad1_y = np.diff(img1, axis=0, prepend=img1[:1, :])
        grad1_mag = np.sqrt(grad1_x**2 + grad1_y**2)
        
        grad2_x = np.diff(img2, axis=1, prepend=img2[:, :1])
        grad2_y = np.diff(img2, axis=0, prepend=img2[:1, :])
        grad2_mag = np.sqrt(grad2_x**2 + grad2_y**2)
    else:
        grad1_x = cv2.Sobel(img1, cv2.CV_64F, 1, 0, ksize=3)
        grad1_y = cv2.Sobel(img1, cv2.CV_64F, 0, 1, ksize=3)
        grad1_mag = np.sqrt(grad1_x**2 + grad1_y**2)
        
        grad2_x = cv2.Sobel(img2, cv2.CV_64F, 1, 0, ksize=3)
        grad2_y = cv2.Sobel(img2, cv2.CV_64F, 0, 1, ksize=3)
        grad2_mag = np.sqrt(grad2_x**2 + grad2_y**2)
    
    # å½’ä¸€åŒ–æ¢¯åº¦å¹…å€¼
    if grad1_mag.max() > 0:
        grad1_mag = grad1_mag / grad1_mag.max()
    if grad2_mag.max() > 0:
        grad2_mag = grad2_mag / grad2_mag.max()
    
    # è®¡ç®—ç›¸å…³æ€§
    valid_mask = (grad1_mag > 0.01) | (grad2_mag > 0.01)
    if valid_mask.sum() < 100:
        return 0.0
    
    grad1_flat = grad1_mag[valid_mask].flatten()
    grad2_flat = grad2_mag[valid_mask].flatten()
    
    if grad1_flat.std() < 1e-6 or grad2_flat.std() < 1e-6:
        return 0.0
    
    correlation = np.corrcoef(grad1_flat, grad2_flat)[0, 1]
    return max(0.0, correlation) if not np.isnan(correlation) else 0.0


def edge_similarity(img1, img2):
    """
    åŸºäºè¾¹ç¼˜çš„ç»“æ„ç›¸ä¼¼æ€§ï¼ˆCannyè¾¹ç¼˜æ£€æµ‹ï¼‰
    
    è¿”å›:
        edge_sim: float, è¾¹ç¼˜ç›¸ä¼¼åº¦ [0, 1]ï¼Œè¶Šé«˜è¶Šå¥½
    """
    try:
        from skimage.feature import canny
    except ImportError:
        print("è­¦å‘Š: skimageä¸å¯ç”¨ï¼Œæ— æ³•è®¡ç®—è¾¹ç¼˜ç›¸ä¼¼åº¦")
        return None
    
    img1 = np.asarray(img1, dtype=np.float64)
    img2 = np.asarray(img2, dtype=np.float64)
    
    # è½¬æ¢ä¸ºç°åº¦
    if img1.ndim == 3:
        img1 = np.mean(img1, axis=-1)
    if img2.ndim == 3:
        img2 = np.mean(img2, axis=-1)
    
    # å½’ä¸€åŒ–åˆ°[0, 1]
    if img1.max() > 1:
        img1 = img1 / 255.0
    if img2.max() > 1:
        img2 = img2 / 255.0
    
    # Cannyè¾¹ç¼˜æ£€æµ‹
    edges1 = canny(img1, sigma=1.0)
    edges2 = canny(img2, sigma=1.0)
    
    # è®¡ç®—Diceç³»æ•°
    intersection = (edges1 & edges2).sum()
    union = edges1.sum() + edges2.sum()
    
    if union == 0:
        return 1.0 if (edges1.sum() == 0 and edges2.sum() == 0) else 0.0
    
    dice = 2.0 * intersection / union
    return dice


def vessel_structure_similarity(img1, img2):
    """
    åŸºäºè¡€ç®¡ç»“æ„çš„ç›¸ä¼¼æ€§ï¼ˆä½¿ç”¨Frangiæ»¤æ³¢ï¼‰
    
    è¿”å›:
        vessel_sim: float, è¡€ç®¡ç»“æ„ç›¸ä¼¼åº¦ [0, 1]ï¼Œè¶Šé«˜è¶Šå¥½
    """
    try:
        from skimage.filters import frangi
    except ImportError:
        print("è­¦å‘Š: skimageä¸å¯ç”¨ï¼Œæ— æ³•è®¡ç®—è¡€ç®¡ç»“æ„ç›¸ä¼¼åº¦")
        return None
    
    img1 = np.asarray(img1, dtype=np.float64)
    img2 = np.asarray(img2, dtype=np.float64)
    
    # è½¬æ¢ä¸ºç°åº¦
    if img1.ndim == 3:
        img1 = np.mean(img1, axis=-1)
    if img2.ndim == 3:
        img2 = np.mean(img2, axis=-1)
    
    # å½’ä¸€åŒ–åˆ°[0, 1]
    if img1.max() > 1:
        img1 = img1 / 255.0
    if img2.max() > 1:
        img2 = img2 / 255.0
    
    try:
        # Frangiæ»¤æ³¢æå–è¡€ç®¡
        vessel1 = frangi(img1, sigmas=range(1, 4), beta1=0.5, beta2=15)
        vessel2 = frangi(img2, sigmas=range(1, 4), beta1=0.5, beta2=15)
        
        # å½’ä¸€åŒ–
        if vessel1.max() > 0:
            vessel1 = vessel1 / vessel1.max()
        if vessel2.max() > 0:
            vessel2 = vessel2 / vessel2.max()
        
        # è®¡ç®—ç›¸å…³æ€§
        valid_mask = (vessel1 > 0.01) | (vessel2 > 0.01)
        if valid_mask.sum() < 100:
            return 0.0
        
        v1_flat = vessel1[valid_mask].flatten()
        v2_flat = vessel2[valid_mask].flatten()
        
        if v1_flat.std() < 1e-6 or v2_flat.std() < 1e-6:
            return 0.0
        
        correlation = np.corrcoef(v1_flat, v2_flat)[0, 1]
        return max(0.0, correlation) if not np.isnan(correlation) else 0.0
    except:
        return 0.0


def calculate_all_metrics_with_normalization(pred, gt):
    """
    è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ï¼ˆåŒ…æ‹¬äº®åº¦å½’ä¸€åŒ–åçš„æŒ‡æ ‡ï¼‰
    
    å‚æ•°:
        pred: numpy array, é¢„æµ‹å›¾åƒ (H, W, C) æˆ– (H, W)
        gt: numpy array, çœŸå®å›¾åƒ (H, W, C) æˆ– (H, W)
    
    è¿”å›:
        metrics: dict, åŒ…å«æ‰€æœ‰æŒ‡æ ‡
    """
    metrics = {}
    
    # 1. æ ‡å‡†æŒ‡æ ‡ï¼ˆåŸå§‹ï¼‰
    metrics['PSNR_raw'] = calculate_psnr(
        pred, gt, data_range=255,
        apply_black_mask=True, black_threshold=10
    )
    metrics['MS_SSIM_raw'] = calculate_ms_ssim(
        pred, gt, data_range=255,
        apply_black_mask=True, black_threshold=10
    )
    
    # 2. äº®åº¦å½’ä¸€åŒ–åçš„æŒ‡æ ‡
    # æ–¹æ³•1: å‡å€¼-æ ‡å‡†å·®å½’ä¸€åŒ–
    pred_norm_meanstd = mean_std_normalization(pred.copy(), gt)
    metrics['PSNR_norm_meanstd'] = calculate_psnr(
        pred_norm_meanstd, gt, data_range=255,
        apply_black_mask=True, black_threshold=10
    )
    metrics['MS_SSIM_norm_meanstd'] = calculate_ms_ssim(
        pred_norm_meanstd, gt, data_range=255,
        apply_black_mask=True, black_threshold=10
    )
    
    # æ–¹æ³•2: ç›´æ–¹å›¾åŒ¹é…
    try:
        pred_norm_hist = histogram_matching(pred.copy(), gt)
        metrics['PSNR_norm_hist'] = calculate_psnr(
            pred_norm_hist, gt, data_range=255,
            apply_black_mask=True, black_threshold=10
        )
        metrics['MS_SSIM_norm_hist'] = calculate_ms_ssim(
            pred_norm_hist, gt, data_range=255,
            apply_black_mask=True, black_threshold=10
        )
    except:
        metrics['PSNR_norm_hist'] = None
        metrics['MS_SSIM_norm_hist'] = None
    
    # 3. ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ ‡ï¼ˆä¸å—äº®åº¦å½±å“ï¼‰
    metrics['Gradient_Similarity'] = gradient_similarity(pred, gt)
    edge_sim = edge_similarity(pred, gt)
    if edge_sim is not None:
        metrics['Edge_Similarity'] = edge_sim
    else:
        metrics['Edge_Similarity'] = None
    vessel_sim = vessel_structure_similarity(pred, gt)
    if vessel_sim is not None:
        metrics['Vessel_Structure_Similarity'] = vessel_sim
    else:
        metrics['Vessel_Structure_Similarity'] = None
    
    return metrics


# åœ¨ __main__ éƒ¨åˆ†ä½¿ç”¨æ•´åˆæ–¹æ³•
if __name__ == "__main__":
    # ==================================================
    # ä½¿ç”¨æ–¹æ³•1ï¼šè®¡ç®—å•ä¸ªæ•°æ®é›†çš„IS
    # ==================================================
    # dataset_path = "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test1/segB"
    # print("å¼€å§‹è®¡ç®—å•ä¸ªæ•°æ®é›†çš„ISå€¼...")
    # is_mean, is_std, image_count = calculate_dataset_is(dataset_path)
    
    # ==================================================
    # ä½¿ç”¨æ–¹æ³•2ï¼šå¯¹æ¯”å¤šä¸ªæ•°æ®é›†çš„ISï¼ˆå–æ¶ˆæ³¨é‡Šä½¿ç”¨ï¼‰
    # ==================================================
    # dataset_paths = [
    #     "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test1/segB",
    #     "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test4/segA"
    # ]
    # print("å¼€å§‹å¯¹æ¯”å¤šä¸ªæ•°æ®é›†çš„ISå€¼...")
    # results = compare_datasets_is(dataset_paths)
    
    
    # åœ¨ __main__ éƒ¨åˆ†æ·»åŠ FIDå¯¹æ¯”æµ‹è¯•
    # ==================================================
    # ä½¿ç”¨æ–¹æ³•1ï¼šè®¡ç®—ä¸¤ä¸ªæ•°æ®é›†ä¹‹é—´çš„FID
    # ==================================================
    # dataset1_path = "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test1/segB"
    # dataset2_path = "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test4/segA"
    
    # print("å¼€å§‹è®¡ç®—ä¸¤ä¸ªæ•°æ®é›†ä¹‹é—´çš„FIDå€¼...")
    # fid_value = calculate_fid_between_datasets(dataset1_path, dataset2_path)
    
    # if fid_value is not None:
    #     print(f"\nğŸ‰ FIDå¯¹æ¯”å®Œæˆ!")
    #     print(f"æ•°æ®é›†1: {dataset1_path}")
    #     print(f"æ•°æ®é›†2: {dataset2_path}")
    #     print(f"FIDå€¼: {fid_value:.4f}")
    
    # ==================================================
    # ä½¿ç”¨æ–¹æ³•2ï¼šå¯¹æ¯”å¤šä¸ªæ•°æ®é›†çš„FIDçŸ©é˜µï¼ˆå–æ¶ˆæ³¨é‡Šä½¿ç”¨ï¼‰
    # ==================================================
    # dataset_paths = [
    #     "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test1/segB",
    #     "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test2/segB",
    #     "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test3/testA", # å¦‚æœæœ‰ç¬¬ä¸‰ä¸ªæ•°æ®é›†
    #     "/data/student/Jiangyiming/SDXL_ControlNet2/data/IS/test4/segA"
    # ]
    # print("å¼€å§‹å¯¹æ¯”å¤šä¸ªæ•°æ®é›†çš„FIDçŸ©é˜µ...")
    # results = compare_multiple_datasets_fid(dataset_paths)
     # ==================================================
    # ä½¿ç”¨æ–¹æ³•ï¼šæŒ‰é¡ºåºæ¯”è¾ƒä¸¤ä¸ªæ•°æ®é›†ä¸­æ¯å¼ å›¾åƒçš„ç›¸ä¼¼åº¦
    # ==================================================
    # 1) åŸºäºè„šæœ¬ä½ç½®æ¨å¯¼é¡¹ç›®æ ¹ä¸æ•°æ®æ ¹
    script_path = os.path.abspath(__file__)
    script_dir = os.path.dirname(script_path)
    repo_root = os.path.dirname(script_dir)
    data_root = os.path.join(repo_root, "data", "IS")

    # 2) é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼é€‰æ‹©è¦å¯¹æ¯”çš„æ•°æ®é›†
    dataset1_name = os.environ.get("IS_DATASET1", "test6")
    dataset2_name = os.environ.get("IS_DATASET2", "test7")

    dataset1_path = os.path.join(data_root, dataset1_name)
    dataset2_path = os.path.join(data_root, dataset2_name)
    
    print("å¼€å§‹æŒ‰é¡ºåºæ¯”è¾ƒä¸¤ä¸ªæ•°æ®é›†ä¸­æ¯å¼ å›¾åƒçš„ç›¸ä¼¼åº¦ (PSNR, MS-SSIM)...")
    pairwise_results = compare_images_pairwise(
        dataset1_path,
        dataset2_path,
        metrics=['psnr', 'ms_ssim'],
        data_range=255
    )
    if pairwise_results:
        export_pairwise_results(pairwise_results, os.path.join(data_root, "comparison_results.txt"))

    print("\n" + "="*70)
    print("ğŸ” åˆ†åˆ«è®¡ç®—ä¸¤ä¸ªæ•°æ®é›†çš„ Inception Score (IS)")
    print("="*70)
    is1_mean, is1_std, is1_count = calculate_dataset_is(dataset1_path, batch_size=32, splits=10, auto_crop=True)
    is2_mean, is2_std, is2_count = calculate_dataset_is(dataset2_path, batch_size=32, splits=10, auto_crop=True)
    if is1_mean is not None and is2_mean is not None:
        print(f"\nIS å¯¹æ¯”: ")
        print(f"  æ•°æ®é›†1: {is1_mean:.4f} Â± {is1_std:.4f} (N={is1_count})")
        print(f"  æ•°æ®é›†2: {is2_mean:.4f} Â± {is2_std:.4f} (N={is2_count})")

    print("\n" + "="*70)
    print("ğŸ” è®¡ç®—ä¸¤ä¸ªæ•°æ®é›†ä¹‹é—´çš„ FID")
    print("="*70)
    fid_val = calculate_fid_between_datasets(dataset1_path, dataset2_path, batch_size=50, device='cuda', auto_crop=True)
    if fid_val is not None:
        print(f"FID: {fid_val:.4f}")

    

# if __name__ == "__main__":
#     # 1. è·å–è„šæœ¬ï¼ˆmeasurement.pyï¼‰æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
#     script_path = os.path.abspath(__file__)  # è„šæœ¬å®Œæ•´è·¯å¾„ï¼š/data/student/.../Scripts/measurement.py
#     script_dir = os.path.dirname(script_path)  # è„šæœ¬æ‰€åœ¨ç›®å½•ï¼š/data/student/.../SDXL_ControlNet2/Scripts
    
#     # 2. ä»Scriptsç›®å½•å‘ä¸Šä¸€çº§ï¼Œå¾—åˆ°SDXL_ControlNet2ç›®å½•
#     parent_dir = os.path.dirname(script_dir)  # ç»“æœï¼š/data/student/.../SDXL_ControlNet2
    
#     # 3. æ‹¼æ¥å›¾åƒæ‰€åœ¨çš„measurementç›®å½•ï¼ˆSDXL_ControlNet2/measurement/ï¼‰
#     measurement_image_dir = os.path.join(parent_dir, "measurement")  # å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
    
#     # 4. æ‹¼æ¥1.pngå’Œ2.pngçš„å®Œæ•´è·¯å¾„
#     image1_path = os.path.join(measurement_image_dir, "1.png")  # 1.pngå®Œæ•´è·¯å¾„
#     image2_path = os.path.join(measurement_image_dir, "2.png")  # 2.pngå®Œæ•´è·¯å¾„
    
#     # 5. æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨ï¼ˆé¿å…è·¯å¾„é”™è¯¯ï¼‰
#     if not os.path.exists(image1_path):
#         raise FileNotFoundError(f"å›¾åƒ1ä¸å­˜åœ¨ï¼š{image1_path}\nè¯·ç¡®è®¤æ–‡ä»¶æ˜¯å¦åœ¨è¯¥è·¯å¾„ä¸‹")
#     if not os.path.exists(image2_path):
#         raise FileNotFoundError(f"å›¾åƒ2ä¸å­˜åœ¨ï¼š{image2_path}\nè¯·ç¡®è®¤æ–‡ä»¶æ˜¯å¦åœ¨è¯¥è·¯å¾„ä¸‹")
    
#     # 6. è¯»å–å›¾åƒå¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆä¾›åç»­æŒ‡æ ‡è®¡ç®—ä½¿ç”¨ï¼‰
#     from PIL import Image
#     test_image1 = np.array(Image.open(image1_path))  # å®šä¹‰test_image1ï¼ˆ1.pngï¼‰
#     test_image2 = np.array(Image.open(image2_path))  # å®šä¹‰test_image2ï¼ˆ2.pngï¼‰
    
#     # 7. æ‰“å°ä¿¡æ¯å¹¶è®¡ç®—æŒ‡æ ‡ï¼ˆå’Œä¹‹å‰é€»è¾‘ä¸€è‡´ï¼‰
#     print("\nã€ç¤ºä¾‹ã€‘è®¡ç®—å•å›¾åƒæŒ‡æ ‡ï¼ˆPSNR, MS-SSIMï¼‰")
#     print("å›¾åƒå°ºå¯¸: {}".format(test_image1.shape))
#     total_pixels = test_image1.shape[0] * test_image1.shape[1]
#     print("é»‘è‰²åƒç´ æ¯”ä¾‹: {:.2f}%".format((test_image1 == 0).all(axis=-1).sum() / total_pixels * 100))
    
#     metrics = calculate_all_metrics(test_image2, test_image1, data_range=255)
#     for metric_name, metric_value in metrics.items():
#         if metric_value is not None:
#             print("{}: {:.6f}".format(metric_name, metric_value))
    
#     print("\nã€æ³¨æ„ã€‘FIDå’ŒISéœ€è¦å¤šå¼ å›¾åƒï¼Œè¯·å‚è€ƒä»¥ä¸‹è°ƒç”¨æ–¹å¼ï¼š")
#     print("  fid_score = calculate_fid(real_images, generated_images)")
#     print("  is_mean, is_std = calculate_inception_score(generated_images)")
#     print("=" * 70)

