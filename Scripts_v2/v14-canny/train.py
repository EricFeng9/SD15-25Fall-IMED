# -*- coding: utf-8 -*-
'''
è®­ç»ƒè„šæœ¬ - SD 1.5 + å•è·¯ Canny ControlNetï¼ˆåŸºäº v14 æ”¹é€ ï¼‰

ã€æ¨¡å‹ã€‘Stable Diffusion 1.5 (512Ã—512) + å•è·¯ Canny ControlNet
ã€æ•°æ®é›†ã€‘æ”¯æŒï¼šCF-OCTA, CF-FA, CF_OCT
'''

import os
# ============ è®¾ç½®ç¦»çº¿æ¨¡å¼ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ HF åº“ä¹‹å‰ï¼‰============
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"
os.environ["HF_HUB_DISABLE_TELEMETRY"] = "1"
os.environ["DISABLE_TELEMETRY"] = "1"

import csv, math, itertools
import torch, numpy as np
import cv2
from PIL import Image
from torch import nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from diffusers import (DDPMScheduler, StableDiffusionControlNetPipeline,
                       ControlNetModel, 
                       AutoencoderKL, UNet2DConditionModel)
from transformers import CLIPTextModel, CLIPTokenizer
from pytorch_msssim import MS_SSIM  # ä»…ç”¨äºåƒç´ ç©ºé—´çš„MS-SSIM Lossï¼ŒVessel Losså·²æ”¹ç”¨Dice
import time
import argparse
import numpy as _np_tmp  # for canny helper

from data_loader_all import (
    UnifiedDataset, SIZE,
    GAMMA_CFFA, GAMMA_CFOCTA_CF, GAMMA_CFOCTA_OCTA,  # Frangiå‚æ•°
    GAMMA_CFOCT_CF, GAMMA_CFOCT_OCT, FRANGI_SIGMAS, FRANGI_ALPHA, FRANGI_BETA,
    extract_vessel_map_torch,  # PyTorchå¯å¾®è¡€ç®¡æå–ï¼ˆè®­ç»ƒ/éªŒè¯/æ¨ç†å…±ç”¨ï¼‰
    _strip_seg_prefix_in_path  # è·¯å¾„å¤„ç†å·¥å…·å‡½æ•°
)
from registration_cf_octa import load_affine_matrix, apply_affine_registration

# v14: å¯¼å…¥æœ‰æ•ˆåŒºåŸŸé…å‡†å’Œç­›é€‰å·¥å…·
from effective_area_regist_cut import filter_valid_area, register_image, read_points_from_txt

# v14: å¯¼å…¥ç»Ÿä¸€æ¨ç†æ¥å£
from unified_inference import unified_inference

# ============ Canny ç”Ÿæˆå·¥å…· ============
def make_canny_batch(cond_tile: torch.Tensor, low: int = 100, high: int = 200) -> torch.Tensor:
    """
    è¾“å…¥: cond_tile (B, 3, H, W) in [0,1] (float)
    è¾“å‡º: canny (B, 3, H, W) in [0,1] float
    """
    cond_np = (cond_tile.detach().cpu().clamp(0, 1) * 255).byte().permute(0, 2, 3, 1).numpy()
    outs = []
    for img in cond_np:
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, low, high)
        edges_3c = _np_tmp.stack([edges]*3, axis=-1)
        outs.append(edges_3c)
    outs = torch.from_numpy(_np_tmp.stack(outs)).float() / 255.0  # (B,H,W,3)
    outs = outs.permute(0,3,1,2).to(cond_tile.device)
    return outs

# ============ SD 1.5 + Canny ControlNet æ¨¡å‹è·¯å¾„é…ç½® ============
base_dir = "/data/student/Fengjunming/SDXL_ControlNet/models/sd15-diffusers"
ctrl_canny_dir = "/data/student/Fengjunming/SDXL_ControlNet/models/controlnet-sd15-canny"

# CSV æ•°æ®è·¯å¾„é…ç½®ï¼ˆæ ¹æ®æ¨¡å¼é€‰æ‹©ï¼‰
CFOCTA_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_v2-2_repaired.csv"
CFOCTA_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_v2-2_repaired.csv"
CFFA_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_cffa.csv"
CFFA_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_cffa.csv"
CFOCT_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_cfoct.csv"
CFOCT_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_cfoct.csv"

# è¾“å‡ºç›®å½•
out_root  = "/data/student/Fengjunming/SDXL_ControlNet/results/out_ctrl_sd15_canny"
device    = torch.device("cuda")

# CF-FA åŸå§‹å›¾åƒå°ºå¯¸
CFFA_ORIGINAL_SIZE = (720, 576)  # width, height

# æ³¨æ„ï¼šå›¾åƒå¤„ç†å‚æ•°é…ç½®å·²ç§»è‡³ data_loader_all.py
# ä½¿ç”¨ get_image_params(mode, param_type) è·å–ç»Ÿä¸€é…ç½®
# ç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°

# ============ ç¼–ç å·¥å…·å‡½æ•° ============
def get_prompt_embeds(bs):
    """
    SD 1.5 æ–‡æœ¬ç¼–ç ï¼ˆç®€åŒ–ç‰ˆï¼Œåªè¿”å› prompt_embedsï¼‰
    """
    prompts = [""] * bs
    text_inputs = tokenizer(
        prompts,
        padding="max_length",
        max_length=tokenizer.model_max_length,
        truncation=True,
        return_tensors="pt",
    )
    text_input_ids = text_inputs.input_ids.to(device)
    prompt_embeds = text_encoder(text_input_ids)[0]
    return prompt_embeds

def encode_vae(img):
    """VAE ç¼–ç ï¼šimg [-1,1] â†’ latents"""
    latents = vae.encode(img).latent_dist.sample() * vae_sf
    return latents

def decode_vae(latents):
    """VAE è§£ç ï¼šlatents â†’ img [-1,1]"""
    img = vae.decode(latents / vae_sf).sample
    return img


# ============ æ¢¯åº¦åŒ¹é…å·¥å…·å‡½æ•° ============
def _get_sobel_kernels(device, dtype):
    base_kernel = torch.tensor(
        [[1., 0., -1.],
         [2., 0., -2.],
         [1., 0., -1.]],
        device=device,
        dtype=dtype
    )
    kernel_x = base_kernel.view(1, 1, 3, 3)
    kernel_y = base_kernel.t().view(1, 1, 3, 3)
    return kernel_x, kernel_y


def compute_image_gradients(image):
    """
    è®¡ç®—å›¾åƒçš„ Sobel æ¢¯åº¦ã€‚

    Args:
        image: (B, C, H, W) tensorï¼ŒèŒƒå›´ [0, 1]

    Returns:
        grad_x, grad_y: ä¸è¾“å…¥åŒå½¢çŠ¶çš„æ¢¯åº¦å¼ é‡
    """
    kernel_x, kernel_y = _get_sobel_kernels(image.device, image.dtype)
    kernel_x = kernel_x.expand(image.shape[1], 1, 3, 3)
    kernel_y = kernel_y.expand(image.shape[1], 1, 3, 3)
    grad_x = F.conv2d(image, kernel_x, padding=1, groups=image.shape[1])
    grad_y = F.conv2d(image, kernel_y, padding=1, groups=image.shape[1])
    return grad_x, grad_y


def compute_gradient_match_loss(pred_imgs_01, gt_imgs_01, mask=None, reduction="l1"):
    """
    æ¢¯åº¦åŒ¹é…æŸå¤±ï¼šçº¦æŸé¢„æµ‹å›¾ä¸ç›®æ ‡å›¾åœ¨æ¢¯åº¦ç©ºé—´ä¿æŒä¸€è‡´ã€‚
    
    ã€v14 æ›´æ–°ã€‘mask ä¸º None æ—¶åœ¨å…¨å›¾è®¡ç®—æŸå¤±

    Args:
        pred_imgs_01: (B, 3, H, W) é¢„æµ‹å›¾åƒï¼ŒèŒƒå›´ [0, 1]
        gt_imgs_01: (B, 3, H, W) ç›®æ ‡å›¾åƒï¼ŒèŒƒå›´ [0, 1]
        mask: (B, 1, H, W) å¯é€‰ï¼Œ0 è¡¨ç¤ºå¿½ç•¥åŒºåŸŸï¼ŒNone è¡¨ç¤ºå…¨å›¾è®¡ç®—
        reduction: 'l1' æˆ– 'l2'

    Returns:
        æ ‡é‡æŸå¤±å€¼
    """
    # ä½¿ç”¨ç»¿è‰²é€šé“ä½œä¸ºç°åº¦åŸºç¡€ï¼ˆOCT å¯¹æ¯”åº¦æœ€ä½³ï¼‰
    pred_gray = pred_imgs_01[:, 1:2, :, :]
    gt_gray = gt_imgs_01[:, 1:2, :, :]

    pred_grad_x, pred_grad_y = compute_image_gradients(pred_gray)
    gt_grad_x, gt_grad_y = compute_image_gradients(gt_gray)

    if reduction == "l2":
        diff = (pred_grad_x - gt_grad_x) ** 2 + (pred_grad_y - gt_grad_y) ** 2
    else:
        diff = (pred_grad_x - gt_grad_x).abs() + (pred_grad_y - gt_grad_y).abs()

    if mask is not None:
        diff = diff * mask

    return diff.mean()


def compute_vessel_loss_frangi(pred_imgs, gt_imgs, mode='cf2fa', sigmas=FRANGI_SIGMAS, 
                                alpha=FRANGI_ALPHA, beta=FRANGI_BETA, 
                                gamma_cffa=GAMMA_CFFA, 
                                gamma_cfocta_cf=GAMMA_CFOCTA_CF, 
                                gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                                gamma_cfoct_cf=GAMMA_CFOCT_CF, 
                                gamma_oct=GAMMA_CFOCT_OCT,
                                debug_dir=None):
    """
    è¡€ç®¡ç»“æ„æŸå¤± - ä½¿ç”¨ Frangi æ»¤æ³¢ + Dice Loss
    
    ã€v14 æ›´æ–°ã€‘ç§»é™¤æ©ç é€»è¾‘ï¼Œç›´æ¥åœ¨å…¨å›¾è®¡ç®—æŸå¤±ï¼ˆå·²é€šè¿‡ filter_valid_area é¢„å¤„ç†ï¼‰
    
    å‚æ•°:
        pred_imgs: é¢„æµ‹å›¾åƒ (B, 3, H, W)ï¼ŒèŒƒå›´ [-1, 1]
        gt_imgs: ç›®æ ‡å›¾åƒ (B, 3, H, W)ï¼ŒèŒƒå›´ [-1, 1]
        mode: è®­ç»ƒæ¨¡å¼ ('cf2fa', 'fa2cf', 'cf2octa', 'octa2cf', 'cf2oct', 'oct2cf')
        debug_dir: è°ƒè¯•å›¾åƒä¿å­˜ç›®å½•ï¼ˆä»…ç¬¬ä¸€æ­¥ä½¿ç”¨ï¼‰
    
    è¿”å›:
        loss: Dice Loss æ ‡é‡
    """
    # 1. è½¬æ¢åˆ° [0, 1] èŒƒå›´
    pred_01 = (pred_imgs.clamp(-1, 1) + 1) / 2  # (B, 3, H, W)
    gt_01 = (gt_imgs.clamp(-1, 1) + 1) / 2
    
    # 2. æå–è¡€ç®¡ç»“æ„ï¼ˆä¸ä½¿ç”¨FOVæ©ç ï¼‰
    # ã€v14.1 æ›´æ–°ã€‘ç¡®å®šç›®æ ‡å›¾åƒç±»å‹ï¼ˆmodeæ ¼å¼: source2targetï¼Œè¿™é‡Œéœ€è¦targetç±»å‹ï¼‰
    target_image_type_map = {
        'cf2fa': 'fa', 'fa2cf': 'cf',
        'cf2octa': 'octa', 'octa2cf': 'cf',
        'cf2oct': 'oct', 'oct2cf': 'cf'
    }
    target_image_type = target_image_type_map.get(mode)
    if target_image_type is None:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}")
    
    # ç¡®å®šæ•°æ®é›†ç±»å‹ï¼ˆä» mode æ¨æ–­ï¼‰
    if mode in ['cf2fa', 'fa2cf']:
        dataset_type = 'CFFA'
    elif mode in ['cf2octa', 'octa2cf']:
        dataset_type = 'CFOCTA'
    elif mode in ['cf2oct', 'oct2cf']:
        dataset_type = 'CFOCT'
    else:
        dataset_type = None
    
    # é¢„æµ‹å›¾çš„è¡€ç®¡æå–ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
    pred_vessel, _ = extract_vessel_map_torch(
        pred_01, 
        image_type=target_image_type,
        dataset_type=dataset_type,
        gamma_cffa=gamma_cffa,
        gamma_cfocta_cf=gamma_cfocta_cf,
        gamma_cfocta_octa=gamma_cfocta_octa,
        gamma_cfoct_cf=gamma_cfoct_cf,
        gamma_oct=gamma_oct,
        sigmas=sigmas,
        alpha=alpha,
        beta=beta,
        apply_fov_mask=False  # ä¸ä½¿ç”¨FOVæ©ç 
    )
    
    # GT å›¾çš„è¡€ç®¡æå–ï¼ˆä¸éœ€è¦æ¢¯åº¦ï¼‰
    with torch.no_grad():
        gt_vessel, _ = extract_vessel_map_torch(
            gt_01, 
            image_type=target_image_type,
            dataset_type=dataset_type,
            gamma_cffa=gamma_cffa,
            gamma_cfocta_cf=gamma_cfocta_cf,
            gamma_cfocta_octa=gamma_cfocta_octa,
            gamma_cfoct_cf=gamma_cfoct_cf,
            gamma_oct=gamma_oct,
            sigmas=sigmas,
            alpha=alpha,
            beta=beta,
            apply_fov_mask=False  # ä¸ä½¿ç”¨FOVæ©ç 
        )
    
    # 3. ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆä»…ç¬¬ä¸€æ­¥ï¼‰
    if debug_dir is not None:
        os.makedirs(debug_dir, exist_ok=True)
        # ä¿å­˜åŸå§‹è¾“å…¥å›¾åƒï¼ˆéœ€è¦ detach æ–­å¼€æ¢¯åº¦ï¼‰
        pred_save = (pred_01[0].detach().cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
        gt_save = (gt_01[0].detach().cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(pred_save).save(os.path.join(debug_dir, "vessel_loss_pred_input.png"))
        Image.fromarray(gt_save).save(os.path.join(debug_dir, "vessel_loss_gt_input.png"))
        
        # ä¿å­˜ Frangi æ»¤æ³¢ç»“æœ
        pred_vessel_save = (pred_vessel[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        gt_vessel_save = (gt_vessel[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(pred_vessel_save).save(os.path.join(debug_dir, "vessel_loss_pred_frangi.png"))
        Image.fromarray(gt_vessel_save).save(os.path.join(debug_dir, "vessel_loss_gt_frangi.png"))
        
        print(f"\nâœ“ Vessel Loss è°ƒè¯•å›¾åƒå·²ä¿å­˜åˆ°: {debug_dir}")
    
    # 4. è®¡ç®— Dice Lossï¼ˆå…¨å›¾è®¡ç®—ï¼‰
    # Dice ç³»æ•° = 2 Ã— |A âˆ© B| / (|A| + |B|)
    smooth = 1e-5  # å¹³æ»‘é¡¹ï¼Œé¿å…é™¤é›¶
    
    # äº¤é›†ï¼šé¢„æµ‹è¡€ç®¡ä¸GTè¡€ç®¡çš„é‡å åŒºåŸŸ
    intersection = (pred_vessel * gt_vessel).sum()
    
    # å¹¶é›†ï¼šé¢„æµ‹è¡€ç®¡ + GTè¡€ç®¡çš„æ€»å’Œ
    pred_sum = pred_vessel.sum()
    gt_sum = gt_vessel.sum()
    
    # Dice ç³»æ•°ï¼ˆèŒƒå›´ [0, 1]ï¼Œ1è¡¨ç¤ºå®Œå…¨é‡å ï¼‰
    dice_coeff = (2.0 * intersection + smooth) / (pred_sum + gt_sum + smooth)
    
    # Dice Loss = 1 - Diceç³»æ•°ï¼ˆèŒƒå›´ [0, 1]ï¼Œ0è¡¨ç¤ºå®Œç¾ï¼‰
    loss = 1.0 - dice_coeff
    
    return loss


def get_dynamic_learning_rate(global_step, max_steps, base_lr=5e-5, min_lr=1e-5):
    """
    å­¦ä¹ ç‡å¹³æ»‘è¡°å‡ï¼ˆCosine Annealingï¼‰
    
    step < 4000: lr = 5e-5
    step >= 4000: Cosine è¡°å‡ 5e-5 â†’ 1e-5
    
    è¿”å›: å½“å‰å­¦ä¹ ç‡
    """
    if global_step < 4000:
        return base_lr
    else:
        # Cosine è¡°å‡
        progress = min((global_step - 4000) / (max_steps - 4000), 1.0)
        lr = min_lr + (base_lr - min_lr) * (1 + math.cos(progress * math.pi)) / 2
        return lr


def compute_total_loss(noise_pred, noise, noisy_latents, latents, timesteps, 
                       args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                       return_components=False, vessel_debug_dir=None):
    """
    è®¡ç®—æ€»æŸå¤±ï¼ˆè®­ç»ƒå’ŒéªŒè¯å…±ç”¨ï¼‰
    
    ã€v14 æ›´æ–°ã€‘ç§»é™¤æ©ç é€»è¾‘ï¼Œç›´æ¥åœ¨å…¨å›¾è®¡ç®—æŸå¤±ï¼ˆå·²é€šè¿‡ filter_valid_area é¢„å¤„ç†ï¼‰
    
    å‚æ•°:
        noise_pred: UNet é¢„æµ‹çš„å™ªå£° (B, 4, H/8, W/8)
        noise: çœŸå®å™ªå£° (B, 4, H/8, W/8)
        noisy_latents: åŠ å™ªåçš„ latents (B, 4, H/8, W/8)
        latents: åŸå§‹ latents (B, 4, H/8, W/8)
        timesteps: æ—¶é—´æ­¥ (B,)
        return_components: æ˜¯å¦è¿”å›å„æŸå¤±åˆ†é‡
        vessel_debug_dir: Vessel Loss è°ƒè¯•å›¾åƒä¿å­˜ç›®å½•
    
    è¿”å›:
        total_loss æˆ– (total_loss, loss_mse, loss_msssim, loss_vessel, loss_grad)
    """
    # 1. MSE æŸå¤±ï¼ˆå™ªå£°ç©ºé—´ï¼Œå…¨å›¾è®¡ç®—ï¼‰
    loss_mse = F.mse_loss(noise_pred, noise)
    
    # 2. åƒç´ ç©ºé—´æŸå¤±ï¼ˆMS-SSIMã€Vesselã€Gradientï¼‰
    with torch.no_grad():
        # scheduler.alphas_cumprod is on CPU, need to move to device
        alphas_cumprod = noise_scheduler.alphas_cumprod.to(device)
        alphas_cumprod_t = alphas_cumprod[timesteps].view(-1, 1, 1, 1)
    
    # ä»å™ªå£°é¢„æµ‹ä¸­æ¢å¤ x0 (åŸå§‹å›¾åƒçš„ latent)
    pred_x0_latents = (noisy_latents - (1 - alphas_cumprod_t).sqrt() * noise_pred) / alphas_cumprod_t.sqrt()
    
    # VAE è§£ç åˆ°åƒç´ ç©ºé—´
    with torch.no_grad():
        tgt_imgs = vae.decode(latents / vae_sf).sample  # GTå›¾ï¼ˆä¸éœ€è¦æ¢¯åº¦ï¼‰
    pred_imgs = vae.decode(pred_x0_latents / vae_sf).sample  # é¢„æµ‹å›¾ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
    
    # è½¬æ¢åˆ° [0, 1] èŒƒå›´
    tgt_imgs_0_1 = (tgt_imgs.clamp(-1, 1) + 1) / 2
    pred_imgs_0_1 = (pred_imgs.clamp(-1, 1) + 1) / 2
    
    # 3. MS-SSIM æŸå¤±ï¼ˆå…¨å›¾è®¡ç®—ï¼‰
    if args.msssim_lambda > 0:
        loss_msssim = 1 - msssim_loss_fn(pred_imgs_0_1, tgt_imgs_0_1)
    else:
        loss_msssim = torch.tensor(0.0, device=device)
    
    # 4. Vessel æŸå¤±ï¼ˆå…¨å›¾è®¡ç®—ï¼Œä¸ä½¿ç”¨FOVæ©ç ï¼‰
    loss_vessel = compute_vessel_loss_frangi(
        pred_imgs, tgt_imgs, 
        mode=args.mode,
        sigmas=FRANGI_SIGMAS,
        alpha=FRANGI_ALPHA, 
        beta=FRANGI_BETA, 
        gamma_cffa=GAMMA_CFFA,
        gamma_cfocta_cf=GAMMA_CFOCTA_CF,
        gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
        gamma_cfoct_cf=GAMMA_CFOCT_CF,
        gamma_oct=GAMMA_CFOCT_OCT,
        debug_dir=vessel_debug_dir
    )
    
    # 5. æ¢¯åº¦åŒ¹é…æŸå¤±ï¼ˆå…¨å›¾è®¡ç®—ï¼‰
    loss_grad = compute_gradient_match_loss(
        pred_imgs_0_1,
        tgt_imgs_0_1,
        mask=None,
        reduction='l1'
    )
    
    # 6. ç»„åˆæ€»æŸå¤±
    total_loss = (loss_mse + 
                  args.msssim_lambda * loss_msssim + 
                  args.vessel_lambda * loss_vessel +
                  args.grad_lambda * loss_grad)
    
    if return_components:
        return total_loss, loss_mse, loss_msssim, loss_vessel, loss_grad
    else:
        return total_loss


def run_inference_test(row_data, step_dir, step_num, mode, fixed_seed=42):
    """
    è¿è¡Œæ¨ç†æµ‹è¯•ï¼ˆæ¯500æ­¥ï¼‰- ä½¿ç”¨ç»Ÿä¸€æ¨ç†æ¥å£
    
    å‚æ•°:
        row_data: CSV è¡Œæ•°æ®å­—å…¸
        step_dir: checkpoint ä¿å­˜ç›®å½•
        step_num: å½“å‰æ­¥æ•°
        mode: è®­ç»ƒæ¨¡å¼
        fixed_seed: å›ºå®šçš„éšæœºç§å­
    """
    print(f"\nè¿è¡Œæ¨ç†æµ‹è¯• (step {step_num}) [{mode}]")
    
    # åˆ›å»ºæ¨ç†æµ‹è¯•ç›®å½•
    infer_dir = os.path.join(step_dir, "inference_test")
    os.makedirs(infer_dir, exist_ok=True)
    
    # åˆ¤æ–­æ•°æ®é›†ç±»å‹
    is_cffa = mode in ["cf2fa", "fa2cf"]
    is_cfoct = mode in ["cf2oct", "oct2cf"]
    is_cfocta = mode in ["cf2octa", "octa2cf"]
    
    # ç¡®å®šæ•°æ®é›†ç±»å‹åç§°
    if is_cffa:
        dataset_type = 'CFFA'
    elif is_cfoct:
        dataset_type = 'CFOCT'
    else:
        dataset_type = 'CFOCTA'
    
    # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©è·¯å¾„
    if is_cffa:
        cf_path = row_data.get("cf_path")
        fa_path = row_data.get("fa_path")
        
        if mode == "cf2fa":
            src_path = cf_path
            target_path = fa_path
            cond_pts_path = row_data.get("cf_pts_path")
            tgt_pts_path = row_data.get("fa_pts_path")
        else:
            src_path = fa_path
            target_path = cf_path
            cond_pts_path = row_data.get("fa_pts_path")
            tgt_pts_path = row_data.get("cf_pts_path")
        affine_path = None
    elif is_cfoct:
        cf_path = row_data.get("cf_path")
        oct_path = row_data.get("oct_path")
        
        if mode == "cf2oct":
            src_path = cf_path
            target_path = oct_path
            cond_pts_path = row_data.get("cf_pts_path")
            tgt_pts_path = row_data.get("oct_pts_path")
        else:
            src_path = oct_path
            target_path = cf_path
            cond_pts_path = row_data.get("cf_pts_path")
            tgt_pts_path = row_data.get("oct_pts_path")
        affine_path = None
    else:
        cf = row_data.get("cf_path")
        octa = row_data.get("octa_path")
        cond = row_data.get("cond_path")
        tgt = row_data.get("target_path")
        affine_cf_to_octa = row_data.get("affine_cf_to_octa_path", "")
        affine_octa_to_cf = row_data.get("affine_octa_to_cf_path", "")
        
        if mode == "cf2octa":
            src_path = cf or cond
            target_path = octa or tgt
            affine_path = affine_octa_to_cf
        else:
            src_path = octa or cond
            target_path = cf or _strip_seg_prefix_in_path(cond or tgt) if (cf or cond or tgt) else None
            affine_path = affine_cf_to_octa
        cond_pts_path = None
        tgt_pts_path = None
    
    if not src_path or not target_path:
        print("  âš  è·³è¿‡æ¨ç†æµ‹è¯•ï¼šè·¯å¾„ä¸å®Œæ•´")
        return
    
    # åŠ è½½åŸå§‹å›¾åƒ
    src_img_original = Image.open(src_path).convert("RGB")
    target_img_original = Image.open(target_path).convert("RGB")
    original_size = src_img_original.size  # (width, height)
    idx = os.path.splitext(os.path.basename(src_path))[0]
    
    # ============ã€v14 ç»Ÿä¸€æ¨ç†æ¥å£ã€‘============
    # ä½¿ç”¨ç»Ÿä¸€çš„æ¨ç†æ¥å£å¤„ç†æ‰€æœ‰æ•°æ®é›†ï¼ˆå•è·¯ Cannyï¼‰
    try:
        controlnet_canny.eval()
        
        pipe = StableDiffusionControlNetPipeline(
            vae=vae,
            text_encoder=text_encoder,
            tokenizer=tokenizer,
            unet=unet,
            controlnet=controlnet_canny,
            scheduler=noise_scheduler,
            safety_checker=None,
            feature_extractor=None
        )
        
        # è°ƒç”¨ç»Ÿä¸€æ¨ç†æ¥å£
        results = unified_inference(
            pipeline=pipe,
            cond_img_pil=src_img_original,
            tgt_img_pil=target_img_original,
            mode=mode,
            cond_pts_path=cond_pts_path,
            tgt_pts_path=tgt_pts_path,
            affine_path=affine_path if is_cfocta else None,
            canny_scale=args.canny_scale,
            cfg=7.5,
            steps=30,
            seed=fixed_seed,
            device=device,
            dataset_type=dataset_type
        )
        
        # æå–ç»“æœ
        pred_img = results['pred']              # 512Ã—512 é¢„æµ‹å›¾
        cond_canny_pil = results['canny_input'] # 512Ã—512 Canny è¾“å…¥
        tgt_512_pil = results['tgt_processed']  # 512Ã—512 å¤„ç†åçš„ç›®æ ‡å›¾
        chessboard_np = results['chessboard']   # 512Ã—512 æ£‹ç›˜å›¾
        filtered_src_pil = results['filtered_cond']  # ç­›é€‰åçš„åŸå°ºå¯¸æ¡ä»¶å›¾
        filtered_tgt_pil = results['filtered_tgt']   # ç­›é€‰åçš„åŸå°ºå¯¸ç›®æ ‡å›¾
        filtered_size = results['filtered_size']     # ç­›é€‰åçš„å°ºå¯¸
        
        print(f"  âœ“ ç»Ÿä¸€æ¨ç†æ¥å£è°ƒç”¨æˆåŠŸ")
        
    except Exception as e:
        print(f"  âš  æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        # æ¢å¤è®­ç»ƒæ¨¡å¼
        controlnet_canny.train()
        return
    
    # ============ ä¿å­˜æ¨ç†ç»“æœ ============
    # 1. ä¿å­˜åŸå›¾
    src_img_original.save(os.path.join(infer_dir, f"{idx}_00_input_original.png"))
    if filtered_src_pil is not None:
        filtered_src_pil.save(os.path.join(infer_dir, f"{idx}_01_input_filtered.png"))
    
    # 2. ä¿å­˜ Canny è¾“å…¥ (512Ã—512)
    cond_canny_pil.save(os.path.join(infer_dir, f"{idx}_02_canny_512x512.png"))
    
    # 3. ä¿å­˜ 512Ã—512 é¢„æµ‹å›¾
    pred_img.save(os.path.join(infer_dir, f"{idx}_03_pred_512x512_step{step_num}.png"))
    
    # 4. ä¿å­˜ 512Ã—512 ç›®æ ‡å›¾å’Œæ£‹ç›˜å›¾
    tgt_512_pil.save(os.path.join(infer_dir, f"{idx}_04_target_512x512.png"))
    Image.fromarray(chessboard_np).save(os.path.join(infer_dir, f"{idx}_05_chessboard_512x512_step{step_num}.png"))
    
    # 5. å¦‚æœæ˜¯ CF-FA/CF-OCTï¼Œä¿å­˜ç­›é€‰åçš„åŸå°ºå¯¸ç›®æ ‡å›¾
    if (is_cffa or is_cfoct) and filtered_tgt_pil is not None:
        filtered_tgt_pil.save(os.path.join(infer_dir, f"{idx}_06_target_filtered.png"))
    
    print(f"âœ“ æ¨ç†æµ‹è¯•å®Œæˆ: {infer_dir}\n")
    
    # æ¢å¤è®­ç»ƒæ¨¡å¼
    controlnet_canny.train()


def main():
    # ============ å‚æ•°è§£æ ============
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", 
                        choices=["cf2octa", "octa2cf", "cf2fa", "fa2cf", "cf2oct", "oct2cf"], 
                        default="cf2octa",
                        help="è®­ç»ƒæ¨¡å¼ï¼šcf2octa(CFâ†’OCTA), octa2cf(OCTAâ†’CF), cf2fa(CFâ†’FA), fa2cf(FAâ†’CF), cf2oct(CFâ†’OCT), oct2cf(OCTâ†’CF)")
    parser.add_argument("-n", "--name", dest="name", default='sd15_v6',
                        help="å®éªŒåç§°ï¼ˆç”¨äºç»„ç»‡è¾“å‡ºç›®å½•ï¼‰")
    parser.add_argument("--train_csv", default=None,
                        help="è®­ç»ƒé›†CSVè·¯å¾„ï¼ˆä¸æŒ‡å®šåˆ™æ ¹æ®modeè‡ªåŠ¨é€‰æ‹©ï¼‰")
    parser.add_argument("--val_csv", default=None,
                        help="æµ‹è¯•é›†CSVè·¯å¾„ï¼ˆä¸æŒ‡å®šåˆ™æ ¹æ®modeè‡ªåŠ¨é€‰æ‹©ï¼‰")
    parser.add_argument("--resume_from", type=str, default=None,
                        help="ä»æŒ‡å®šcheckpointæ¢å¤è®­ç»ƒï¼Œä¾‹å¦‚: /path/to/step_6000")
    parser.add_argument("--max_steps", type=int, default=15000,
                        help="æ€»è®­ç»ƒæ­¥æ•°")
    
    # Canny ControlNet å¼ºåº¦å‚æ•°
    parser.add_argument("--canny_scale", type=float, default=1.0,
                        help="Canny ControlNet å¼ºåº¦ï¼ˆæ¨è 0.6-1.2ï¼‰")
    parser.add_argument("--msssim_lambda", type=float, default=0.1,
                        help="MS-SSIM æ„ŸçŸ¥æŸå¤±çš„æƒé‡ (è®¾ä¸º0åˆ™ç¦ç”¨)")
    parser.add_argument("--vessel_lambda", type=float, default=0.05,
                        help="Vessel Loss è¡€ç®¡ç»“æ„æŸå¤±çš„æƒé‡ (é»˜è®¤0.05)")
    parser.add_argument("--grad_lambda", type=float, default=0.1,
                        help="æ¢¯åº¦åŒ¹é…æŸå¤±çš„æƒé‡ (é»˜è®¤0.1)")
    parser.add_argument("--dynamiclr", "-dlr", action="store_true",
                        help="å¯ç”¨å­¦ä¹ ç‡è¡°å‡ (step<4000: 5e-5, step>=4000: Cosineè¡°å‡ 5e-5â†’1e-5)")
    
    global args
    args, _ = parser.parse_known_args()

    print("âœ“ ç¦»çº¿ç¯å¢ƒå˜é‡å·²åœ¨è„šæœ¬å¼€å§‹æ—¶è®¾ç½® (HF_HUB_OFFLINE=1)")
    
    # åˆ¤æ–­æ•°æ®é›†ç±»å‹
    is_cffa = args.mode in ["cf2fa", "fa2cf"]
    is_cfoct = args.mode in ["cf2oct", "oct2cf"]
    is_cfocta = args.mode in ["cf2octa", "octa2cf"]
    
    # æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©CSVæ–‡ä»¶
    if args.train_csv is None:
        if is_cffa:
            args.train_csv = CFFA_TRAIN_CSV
            args.val_csv = CFFA_VAL_CSV
        elif is_cfoct:
            args.train_csv = CFOCT_TRAIN_CSV
            args.val_csv = CFOCT_VAL_CSV
        else:  # is_cfocta
            args.train_csv = CFOCTA_TRAIN_CSV
            args.val_csv = CFOCTA_VAL_CSV
    elif args.val_csv is None:
        # å¦‚æœæŒ‡å®šäº†train_csvä½†æ²¡æœ‰val_csvï¼Œè‡ªåŠ¨é€‰æ‹©val_csv
        if is_cffa:
            args.val_csv = CFFA_VAL_CSV
        elif is_cfoct:
            args.val_csv = CFOCT_VAL_CSV
        else:
            args.val_csv = CFOCTA_VAL_CSV
    
    # ç¡®å®šæ•°æ®é›†ç±»å‹åç§°
    if is_cffa:
        dataset_type_name = "CF-FA"
    elif is_cfoct:
        dataset_type_name = "CF_OCT"
    else:
        dataset_type_name = "CF-OCTA"
    
    print(f"\næ•°æ®é›†: {dataset_type_name} | è®­ç»ƒ:{args.train_csv} | æµ‹è¯•:{args.val_csv}")

    # è¾“å‡ºç›®å½•
    out_dir = os.path.join(out_root, args.mode, args.name)
    os.makedirs(out_dir, exist_ok=True)

    # ============ æ•°æ®åŠ è½½ï¼ˆv10ï¼šä½¿ç”¨ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ + ç»Ÿä¸€é…ç½®ï¼‰============
    # ã€v10 æ”¹è¿›ã€‘æ‰€æœ‰å¤„ç†å‚æ•°è‡ªåŠ¨ä» data_loader_all.py è·å–ï¼Œä¸éœ€è¦å¤–éƒ¨ä¼ å…¥
    # Single Source of Truthï¼šè®­ç»ƒå’Œæ¨ç†ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°
    train_ds = UnifiedDataset(args.train_csv, args.mode)
    val_ds = UnifiedDataset(args.val_csv, args.mode)
    
    train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, 
                             num_workers=4, drop_last=True)
    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, 
                           num_workers=2, drop_last=False)
    
    print(f"æ ·æœ¬æ•°: è®­ç»ƒ={len(train_ds)} | æµ‹è¯•={len(val_ds)}")

    # ============ å‡†å¤‡å›ºå®šçš„æ¨ç†æµ‹è¯•æ ·æœ¬ï¼ˆä»æµ‹è¯•é›†éšæœºæŠ½å–ï¼‰============
    import random
    random.seed(42)  # å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œé€‰åŒä¸€ä¸ªæ ·æœ¬
    
    # ä»æµ‹è¯•é›†CSVä¸­è¯»å–å¹¶éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬
    with open(args.val_csv) as f:
        val_rows = list(csv.DictReader(f))
    
    if len(val_rows) == 0:
        raise ValueError(f"æµ‹è¯•é›†ä¸ºç©º: {args.val_csv}")
    
    fixed_sample_idx = random.randint(0, len(val_rows) - 1)
    fixed_sample_row = val_rows[fixed_sample_idx]
    
    # æ ¹æ®æ¨¡å¼å’Œæ•°æ®é›†ç±»å‹è·å–è·¯å¾„
    if is_cffa:
        # CF-FA æ•°æ®é›†
        if args.mode == "cf2fa":
            src_path = fixed_sample_row.get("cf_path")
            tgt_path = fixed_sample_row.get("fa_path")
        else:  # fa2cf
            src_path = fixed_sample_row.get("fa_path")
            tgt_path = fixed_sample_row.get("cf_path")
    elif is_cfoct:
        # CF_OCT æ•°æ®é›†
        if args.mode == "cf2oct":
            src_path = fixed_sample_row.get("cf_path")
            tgt_path = fixed_sample_row.get("oct_path")
        else:  # oct2cf
            src_path = fixed_sample_row.get("oct_path")
            tgt_path = fixed_sample_row.get("cf_path")
    else:
        # CF-OCTA æ•°æ®é›†
        if args.mode == "cf2octa":
            src_path = fixed_sample_row.get("cf_path") or fixed_sample_row.get("cond_path")
            tgt_path = fixed_sample_row.get("octa_path") or fixed_sample_row.get("target_path")
        else:  # octa2cf
            src_path = fixed_sample_row.get("octa_path") or fixed_sample_row.get("cond_path")
            tgt_path = fixed_sample_row.get("cf_path") or _strip_seg_prefix_in_path(
                fixed_sample_row.get("cond_path") or fixed_sample_row.get("target_path")
            )
    
    print(f"\nå›ºå®šæµ‹è¯•æ ·æœ¬[{fixed_sample_idx}]: {os.path.basename(src_path)} â†’ {os.path.basename(tgt_path)}")

    # ============ SD 1.5 + Canny ControlNet æ¨¡å‹åŠ è½½ ============
    global vae, unet, text_encoder, tokenizer, controlnet_canny, vae_sf, noise_scheduler
    
    print(f"\n{'='*70}\næ­£åœ¨åŠ è½½ SD 1.5 + Canny ControlNet...")
    
    resume_step = 0
    
    if args.resume_from:
        # ä» checkpoint æ¢å¤
        resume_dir = args.resume_from.strip()
        if not os.path.isabs(resume_dir):
            resume_dir = os.path.abspath(resume_dir)
        print(f"æ¢å¤checkpoint: {resume_dir}")
        
        if not os.path.exists(resume_dir):
            raise FileNotFoundError(f"Checkpoint ç›®å½•ä¸å­˜åœ¨: {resume_dir}")
        
        import re
        match = re.search(r'step_(\d+)', resume_dir)
        if match:
            resume_step = int(match.group(1))
            print(f"  â†’ step {resume_step}")
        
        # åŠ è½½æ¨¡å‹ç»„ä»¶ï¼ˆFP32ï¼‰
        # Canny ControlNet æ¢å¤
        canny_path = os.path.join(resume_dir, "controlnet_canny")
        
        print(f"  Canny è·¯å¾„: {canny_path}")
        print(f"    - è·¯å¾„å­˜åœ¨: {os.path.exists(canny_path)}")
        
        print(f"\n  æ­£åœ¨åŠ è½½ Canny ControlNet...")
        controlnet_canny = ControlNetModel.from_pretrained(
            canny_path, 
            torch_dtype=torch.float32,
            local_files_only=True
        ).to(device)
        print(f"  âœ“ Canny ControlNet åŠ è½½æˆåŠŸ")
        
        vae = AutoencoderKL.from_pretrained(
            base_dir, subfolder="vae", local_files_only=True
        ).to(device)
        unet = UNet2DConditionModel.from_pretrained(
            base_dir, subfolder="unet", local_files_only=True
        ).to(device)
        text_encoder = CLIPTextModel.from_pretrained(
            base_dir, subfolder="text_encoder", local_files_only=True
        ).to(device)
        tokenizer = CLIPTokenizer.from_pretrained(
            base_dir, subfolder="tokenizer", local_files_only=True
        )
        print(f"âœ“ å·²åŠ è½½ Dual ControlNet checkpoint (step {resume_step})")
    else:
        # ä»é¢„è®­ç»ƒæ¨¡å‹å¼€å§‹ï¼ˆFP32ï¼‰
        print("æ­£åœ¨åŠ è½½é¢„è®­ç»ƒçš„ Canny ControlNet...")
        controlnet_canny = ControlNetModel.from_pretrained(
            ctrl_canny_dir, local_files_only=True
        ).to(device)
        print(f"âœ“ Canny ControlNet åŠ è½½å®Œæˆ")
        
        vae = AutoencoderKL.from_pretrained(
            base_dir, subfolder="vae", local_files_only=True
        ).to(device)
        unet = UNet2DConditionModel.from_pretrained(
            base_dir, subfolder="unet", local_files_only=True
        ).to(device)
        text_encoder = CLIPTextModel.from_pretrained(
            base_dir, subfolder="text_encoder", local_files_only=True
        ).to(device)
        tokenizer = CLIPTokenizer.from_pretrained(
            base_dir, subfolder="tokenizer", local_files_only=True
        )
        print(f"âœ“ SD 1.5 åŸºç¡€æ¨¡å‹å·²åŠ è½½ï¼ˆFP32 ç²¾åº¦ï¼‰")

    # å†»ç»“ä¸»å¹²ï¼Œåªè®­ç»ƒ ControlNet
    unet.requires_grad_(False)
    vae.requires_grad_(False)
    text_encoder.requires_grad_(False)
    controlnet_canny.requires_grad_(True)

    # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    noise_scheduler = DDPMScheduler.from_pretrained(
        base_dir, subfolder="scheduler", local_files_only=True
    )

    # ä¼˜åŒ–å™¨ï¼šä»…è®­ç»ƒå•è·¯ Canny ControlNet
    opt = torch.optim.AdamW(
        controlnet_canny.parameters(),
        lr=5e-5, weight_decay=1e-2
    )
    mse = nn.MSELoss()
    if args.msssim_lambda > 0:
        msssim_loss_fn = MS_SSIM(data_range=1.0, size_average=True, channel=3).to(device)
    else:
        msssim_loss_fn = None  # å½“ msssim_lambda == 0 æ—¶è®¾ä¸º None
    vae_sf = vae.config.scaling_factor

    # æ¢å¤ optimizer
    if args.resume_from:
        optimizer_path = os.path.join(args.resume_from, "optimizer.pt")
        if os.path.exists(optimizer_path):
            opt.load_state_dict(torch.load(optimizer_path))
            print("âœ“ å·²æ¢å¤ optimizer çŠ¶æ€")

    # è®¾ç½®è®­ç»ƒæ¨¡å¼
    max_steps = args.max_steps
    global_step = resume_step
    unet.eval()
    vae.eval()
    text_encoder.eval()
    controlnet_canny.train()

    # è®¡æ—¶å’Œç»Ÿè®¡
    if device.type == "cuda":
        torch.cuda.synchronize()
    t_block = time.time()
    loss_accumulator = []
    msssim_loss_accumulator = []  # v8-3: æ€»æ˜¯åˆå§‹åŒ–
    vessel_loss_accumulator = []  # v8-3: æ–°å¢ (Frangi)
    grad_loss_accumulator = []    # v10-2: æ¢¯åº¦åŒ¹é…æŸå¤±
    
    # ============ æ—©åœæœºåˆ¶ç›¸å…³å˜é‡ ============
    best_val_loss = float("inf")
    best_step = 0
    patience = 8  # v10-3: ä»5æ”¹ä¸º8ï¼Œå¢åŠ è®­ç»ƒè€å¿ƒ
    wait = 0
    best_ckpt_dir = os.path.join(out_dir, "best_checkpoint")
    latest_ckpt_dir = os.path.join(out_dir, "latest_checkpoint")  # æ–°å¢ï¼šæœ€æ–°æ£€æŸ¥ç‚¹ç›®å½•
    validate_every = 500
    early_stopped = False
    min_train_steps = 4000  # v10-3: Warm-upæœŸï¼Œå‰4000æ­¥ä¸è§¦å‘æ—©åœ
    fixed_val_indices = None  # v10-3: å›ºå®šéªŒè¯å­é›†çš„ç´¢å¼•ï¼ˆç¬¬ä¸€æ¬¡éªŒè¯æ—¶åˆå§‹åŒ–ï¼‰

    # ============ éªŒè¯å‡½æ•°ï¼ˆç”¨äºæ—©åœï¼‰ ============
    def evaluate(val_dataset, val_indices=None, num_samples=10):
        """
        åœ¨éªŒè¯é›†ä¸Šè®¡ç®—æ€»æŸå¤±ï¼Œç”¨äºæ—©åœåˆ¤æ–­
        
        ã€v10-3 æ›´æ–°ã€‘ä½¿ç”¨å›ºå®šéªŒè¯å­é›†ï¼Œç¡®ä¿æ¯æ¬¡éªŒè¯çš„æ ·æœ¬ä¸€è‡´
        
        å‚æ•°:
            val_dataset: éªŒè¯é›† Dataset å¯¹è±¡
            val_indices: å›ºå®šçš„éªŒè¯æ ·æœ¬ç´¢å¼•åˆ—è¡¨ï¼ˆå¦‚æœä¸ºNoneåˆ™éšæœºæŠ½å–ï¼‰
            num_samples: é‡‡æ ·æ•°é‡ï¼ˆé»˜è®¤10ä¸ªæ ·æœ¬ï¼‰
        
        è¿”å›:
            avg_total_loss: éªŒè¯é›†å¹³å‡æ€»æŸå¤±
            val_indices: ä½¿ç”¨çš„éªŒè¯ç´¢å¼•ï¼ˆç”¨äºåç»­å¤ç”¨ï¼‰
        """
        print(f"\n{'='*70}")
        print(f"æ­£åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹...")
        print(f"{'='*70}")
        
        controlnet_canny.eval()
        
        # ã€v10-3 æ–°å¢ã€‘å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡éªŒè¯ï¼Œéšæœºé€‰æ‹©å›ºå®šå­é›†
        if val_indices is None:
            import random
            random.seed(42)  # å›ºå®šç§å­ç¡®ä¿å¯å¤ç°
            total_val_samples = len(val_dataset)
            num_samples = min(num_samples, total_val_samples)
            val_indices = random.sample(range(total_val_samples), num_samples)
            val_indices.sort()  # æ’åºä¾¿äºæŸ¥çœ‹
            print(f"  ã€é¦–æ¬¡éªŒè¯ã€‘éšæœºé€‰æ‹©å›ºå®šéªŒè¯å­é›†: {val_indices}")
        else:
            print(f"  ã€ä½¿ç”¨å›ºå®šå­é›†ã€‘éªŒè¯ç´¢å¼•: {val_indices}")
        
        val_losses = []
        
        with torch.no_grad():
            for idx in val_indices:
                # ä»æ•°æ®é›†ä¸­ç›´æ¥è·å–æŒ‡å®šç´¢å¼•çš„æ ·æœ¬
                batch_data = val_dataset[idx]
                _, cond_tile, tgt, cond_path, tgt_path = batch_data
                
                # æ·»åŠ  batch ç»´åº¦å¹¶ç§»åˆ°è®¾å¤‡
                cond_tile = cond_tile.unsqueeze(0).to(device)
                tgt = tgt.unsqueeze(0).to(device)
                cond_canny = make_canny_batch(cond_tile)
                b = 1
                
                # VAE ç¼–ç 
                latents = encode_vae(tgt)
                noise = torch.randn_like(latents)
                timesteps = torch.randint(
                    0, noise_scheduler.config.num_train_timesteps, 
                    (b,), device=device, dtype=torch.long
                )
                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
                
                # æ–‡æœ¬ç¼–ç 
                prompt_embeds = get_prompt_embeds(b)
                
                # å•è·¯ Canny ControlNet å‰å‘ä¼ æ’­
                down_samples, mid_sample = controlnet_canny(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=prompt_embeds,
                    controlnet_cond=cond_canny,
                    conditioning_scale=args.canny_scale,
                    return_dict=False
                )
                
                # UNet é¢„æµ‹å™ªå£°
                noise_pred = unet(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=prompt_embeds,
                    down_block_additional_residuals=down_samples,
                    mid_block_additional_residual=mid_sample
                ).sample
                
                # ============ ã€v10-2 ä¼˜åŒ–ã€‘è°ƒç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° ============
                total_loss = compute_total_loss(
                    noise_pred, noise, noisy_latents, latents, timesteps,
                    args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                    return_components=False
                )
                
                val_losses.append(total_loss.item())
        
        # æ¢å¤è®­ç»ƒæ¨¡å¼
        controlnet_canny.train()
        
        avg_total_loss = np.mean(val_losses) if len(val_losses) > 0 else float('inf')
        
        print(f"âœ“ éªŒè¯å®Œæˆ")
        print(f"  éªŒè¯æ ·æœ¬æ•°: {len(val_indices)}")
        print(f"  å¹³å‡æ€»æŸå¤±: {avg_total_loss:.6f}")
        print(f"{'='*70}\n")
        
        return avg_total_loss, val_indices
    
    # ============ è®­ç»ƒä¿¡æ¯æ‰“å° ============
    print("\n" + "="*70)
    print("ã€è®­ç»ƒé…ç½®ã€‘")
    print("="*70)
    print(f"  æ¨¡å‹: SD 1.5 + Dual ControlNet (Scribble + Tile)")
    print(f"  æ•°æ®é›†: {'CF-FA' if is_cffa else ('CF_OCT' if is_cfoct else 'CF-OCTA')}")
    print(f"  è®­ç»ƒæ¨¡å¼: {args.mode}")
    print(f"  è®­ç»ƒå°ºå¯¸: {SIZE}Ã—{SIZE}")
    if is_cffa:
        print(f"  åŸå›¾å°ºå¯¸: {CFFA_ORIGINAL_SIZE[0]}Ã—{CFFA_ORIGINAL_SIZE[1]}")
    print(f"\n  æŸå¤±å‡½æ•°:")
    print(f"    MSE (å™ªå£°ç©ºé—´): 1.0")
    print(f"    MS-SSIM (åƒç´ ç©ºé—´): {args.msssim_lambda}")
    print(f"    Vessel (Frangi+Dice): {args.vessel_lambda}")
    print(f"    Gradient: {args.grad_lambda}")
    print(f"\n  è®­ç»ƒç­–ç•¥:")
    if args.dynamiclr:
        print(f"    å­¦ä¹ ç‡: åŠ¨æ€è¡°å‡ (5e-5 â†’ 1e-5)")
    else:
        print(f"    å­¦ä¹ ç‡: 5e-5 (å›ºå®š)")
    print(f"    æ—©åœæœºåˆ¶: éªŒè¯æŸå¤±è¿ç»­ {patience} æ¬¡æœªæå‡åˆ™åœæ­¢")
    print(f"    éªŒè¯é¢‘ç‡: æ¯ {validate_every} æ­¥")
    print(f"\n  ç²¾åº¦: FP32")
    print(f"  è®­ç»ƒæ ·æœ¬: {len(train_ds)} | æµ‹è¯•æ ·æœ¬: {len(val_ds)}")
    print(f"  è¾“å‡ºç›®å½•: {out_dir}")
    if args.resume_from:
        print(f"  æ¢å¤è®­ç»ƒ: step {resume_step} â†’ {max_steps}")
    else:
        print(f"  è®­ç»ƒæ­¥æ•°: 0 â†’ {max_steps}")
    print("="*70 + "\n")

    # ============ è®­ç»ƒå¾ªç¯ ============
    while global_step < max_steps:
        if early_stopped:
            break  # æ—©åœåé€€å‡ºå¤–å±‚å¾ªç¯
        for batch_data in train_loader:
            if global_step >= max_steps:
                break
            
            # æ•°æ®è§£åŒ…ï¼ˆä¸¤ä¸ªæ•°æ®åŠ è½½å™¨è¿”å›æ ¼å¼ç›¸åŒï¼‰
            # ä½¿ç”¨ cond_tile ç”Ÿæˆ Canny è¾¹ç¼˜
            _, cond_tile, tgt, cond_paths, tgt_paths = batch_data
            cond_tile = cond_tile.to(device)
            tgt = tgt.to(device)
            cond_canny = make_canny_batch(cond_tile)  # [0,1]
            b = tgt.shape[0]
            
            # ç¬¬ä¸€æ­¥ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆåŸå›¾ã€é…å‡†å›¾ã€Tileè¾“å…¥ï¼‰
            if global_step == 0:
                debug_dir = os.path.join(out_dir, "debug_images_step0")
                os.makedirs(debug_dir, exist_ok=True)
                
                # æ–‡ä»¶å
                cond_filename = os.path.splitext(os.path.basename(cond_paths[0]))[0]
                tgt_filename = os.path.splitext(os.path.basename(tgt_paths[0]))[0]
                
                # ä¿å­˜ Canny æ¡ä»¶å›¾
                cond_canny_save = (cond_canny[0].cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(cond_canny_save).save(os.path.join(debug_dir, f"{cond_filename}_canny_input.png"))
                
                # 3. ä¿å­˜é…å‡†åçš„ç›®æ ‡å›¾
                tgt_save = ((tgt[0].cpu().float().permute(1, 2, 0).numpy() + 1) / 2 * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(tgt_save).save(os.path.join(debug_dir, f"{tgt_filename}_registered.png"))
                
                print(f"\nâœ“ Step 0 è°ƒè¯•å›¾åƒå·²ä¿å­˜åˆ°: {debug_dir}\n")

            # è®­ç»ƒæ­¥éª¤
            with torch.no_grad():
                # VAE ç¼–ç 
                latents = encode_vae(tgt)
                noise = torch.randn_like(latents)
                timesteps = torch.randint(
                    0, noise_scheduler.config.num_train_timesteps, 
                    (b,), device=device, dtype=torch.long
                )
                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
                
                # æ–‡æœ¬ç¼–ç ï¼ˆç©º promptï¼‰
                prompt_embeds = get_prompt_embeds(b)
            
            # å•è·¯ Canny ControlNet å‰å‘
            down_samples, mid_sample = controlnet_canny(
                noisy_latents,
                timesteps,
                encoder_hidden_states=prompt_embeds,
                controlnet_cond=cond_canny,
                conditioning_scale=args.canny_scale,
                return_dict=False
            )
            
            # UNet é¢„æµ‹å™ªå£°
            noise_pred = unet(
                noisy_latents,
                timesteps,
                encoder_hidden_states=prompt_embeds,
                down_block_additional_residuals=down_samples,
                mid_block_additional_residual=mid_sample
            ).sample
            
            # ============ ã€v10-2 ä¼˜åŒ–ã€‘è°ƒç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° ============
            # ç¬¬ä¸€æ­¥ä¿å­˜ Vessel Loss è°ƒè¯•å›¾åƒ
            vessel_debug_dir = os.path.join(out_dir, "debug_vessel_loss_step0") if global_step == 0 else None
            
            # è®¡ç®—æ€»æŸå¤±ï¼ˆè¿”å›å„åˆ†é‡ç”¨äºæ—¥å¿—è®°å½•ï¼‰
            loss, loss_mse, loss_msssim, loss_vessel, loss_grad = compute_total_loss(
                noise_pred, noise, noisy_latents, latents, timesteps,
                args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                return_components=True,
                vessel_debug_dir=vessel_debug_dir
            )
            
            # åå‘ä¼ æ’­
            opt.zero_grad(set_to_none=True)
            loss.backward()
            opt.step()
            
            # ============ å­¦ä¹ ç‡ç­–ç•¥ï¼šæ ¹æ® --dynamiclr å‚æ•°å†³å®š ============
            if args.dynamiclr:
                # åŠ¨æ€å­¦ä¹ ç‡è¡°å‡ï¼ˆCosine Annealingï¼‰
                current_lr = get_dynamic_learning_rate(global_step, max_steps)
                for param_group in opt.param_groups:
                    param_group['lr'] = current_lr
            else:
                # å›ºå®šå­¦ä¹ ç‡ 5e-5ï¼ˆæ—©åœæœºåˆ¶ä¾èµ–éªŒè¯æŸå¤±ï¼‰
                current_lr = 5e-5
            
            # ç»Ÿè®¡
            loss_accumulator.append(loss_mse.item())
            if args.msssim_lambda > 0:
                msssim_loss_accumulator.append(loss_msssim.item())
            if args.vessel_lambda > 0:
                vessel_loss_accumulator.append(loss_vessel.item())
            if args.grad_lambda > 0:
                grad_loss_accumulator.append(loss_grad.item())
            global_step += 1
            
            # æ—¥å¿—è¾“å‡ºï¼ˆæ¯100æ­¥ï¼‰
            if global_step % 100 == 0:
                if device.type == "cuda":
                    torch.cuda.synchronize()
                elapsed = time.time() - t_block
                
                # è®¡ç®—å¹³å‡æŸå¤±
                avg_mse = np.mean(loss_accumulator)
                loss_accumulator = []
                
                # è®¡ç®—è¡€ç®¡æŸå¤±å¹³å‡å€¼
                if args.vessel_lambda > 0 and len(vessel_loss_accumulator) > 0:
                    avg_vessel = np.mean(vessel_loss_accumulator)
                    vessel_loss_accumulator = []
                else:
                    avg_vessel = 0.0
                
                if len(msssim_loss_accumulator) > 0:
                    avg_msssim = np.mean(msssim_loss_accumulator)
                    msssim_loss_accumulator = []
                else:
                    avg_msssim = 0.0

                if args.grad_lambda > 0 and len(grad_loss_accumulator) > 0:
                    avg_grad = np.mean(grad_loss_accumulator)
                    grad_loss_accumulator = []
                else:
                    avg_grad = 0.0
                
                t_val = timesteps[0].item()
                
                # æ„å»ºæ—¥å¿—æ¶ˆæ¯
                msg_parts = [
                    f"[SD15-v10] step {global_step}/{max_steps}",
                    f"lr:{current_lr:.2e}",
                    f"mse:{avg_mse:.4f}",
                ]
                
                # æ˜¾ç¤ºè¡€ç®¡æŸå¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if args.vessel_lambda > 0:
                    msg_parts.append(f"vessel:{avg_vessel:.4f}(Î»={args.vessel_lambda})")
                
                if args.msssim_lambda > 0:
                    msg_parts.append(f"msssim:{avg_msssim:.4f}(Î»={args.msssim_lambda})")

                if args.grad_lambda > 0:
                    msg_parts.append(f"grad:{avg_grad:.4f}(Î»={args.grad_lambda})")

                msg_parts.extend([
                    f"t={t_val:3d}",
                    f"Canny:{args.canny_scale}",
                    f"{elapsed:.1f}s"
                ])
                msg = " | ".join(msg_parts)
                
                print(msg)
                
                # ä¿å­˜æ—¥å¿—åˆ°ç»Ÿä¸€çš„è®­ç»ƒæ—¥å¿—æ–‡ä»¶
                train_log_path = os.path.join(out_dir, "training_log.txt")
                with open(train_log_path, "a") as f:
                    f.write(msg + "\n")
                
                if device.type == "cuda":
                    torch.cuda.synchronize()
                t_block = time.time()
            
            # ============ v10-3: éªŒè¯é›†è¯„ä¼° + æ—©åœæœºåˆ¶ + ä¿å­˜ checkpointï¼ˆæ¯500æ­¥ï¼‰============
            if global_step % validate_every == 0:
                # 1. å…ˆåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼ˆä½¿ç”¨å›ºå®šéªŒè¯å­é›†ï¼‰
                val_loss, fixed_val_indices = evaluate(val_ds, val_indices=fixed_val_indices, num_samples=10)
                
                # 2. åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
                is_best = False
                if val_loss < best_val_loss - 1e-4:  # æ˜æ˜¾ä¸‹é™ï¼ˆ1e-4 æ˜¯é˜ˆå€¼ï¼‰
                    best_val_loss = val_loss
                    best_step = global_step
                    wait = 0
                    is_best = True
                    
                    print(f"\n{'='*70}")
                    print(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³æ¨¡å‹ï¼")
                    print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
                    print(f"  æœ€ä½³æ­¥æ•°: {best_step}")
                    print(f"{'='*70}\n")
                else:
                    # ã€v10-3 ä¿®å¤ã€‘åªåœ¨ warm-up æœŸä¹‹åæ‰å¢åŠ  wait è®¡æ•°
                    if global_step >= min_train_steps:
                        wait += 1
                        print(f"\n{'='*70}")
                        print(f"âš  éªŒè¯æŸå¤±æœªæå‡ï¼ˆè¿ç»­ {wait}/{patience} æ¬¡ï¼‰")
                        print(f"  å½“å‰éªŒè¯æŸå¤±: {val_loss:.6f}")
                        print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f} (step {best_step})")
                        print(f"{'='*70}\n")
                    else:
                        print(f"\n{'='*70}")
                        print(f"â„¹ï¸  Warm-up æœŸï¼Œä¸è®¡å…¥ patience")
                        print(f"  å½“å‰éªŒè¯æŸå¤±: {val_loss:.6f}")
                        print(f"{'='*70}\n")
                
                # 3. ä¿å­˜ latest_checkpointï¼ˆæ¯æ¬¡è¦†ç›–ï¼‰
                os.makedirs(latest_ckpt_dir, exist_ok=True)
                
                controlnet_canny.save_pretrained(os.path.join(latest_ckpt_dir, "controlnet_canny"))
                torch.save(opt.state_dict(), os.path.join(latest_ckpt_dir, "optimizer.pt"))
                
                # ä¿å­˜ latest çš„å…ƒä¿¡æ¯ï¼ˆæ ‡æ³¨å½“å‰æ­¥æ•°ï¼‰
                with open(os.path.join(latest_ckpt_dir, "latest_info.txt"), "w") as f:
                    f.write(f"Latest Step: {global_step}\n")
                    f.write(f"Validation Loss: {val_loss:.6f}\n")
                    f.write(f"Best Loss: {best_val_loss:.6f} (step {best_step})\n")
                
                print(f"\n{'='*70}")
                print(f"âœ“ Latest Checkpoint å·²ä¿å­˜: {latest_ckpt_dir}")
                print(f"  - Latest Step: {global_step}")
                print(f"  - Validation Loss: {val_loss:.6f}")
                print(f"  - controlnet_canny/")
                print(f"  - latest_info.txt")
                print(f"{'='*70}\n")
                
                # 4. å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜åˆ° best_checkpoint ç›®å½•
                if is_best:
                    os.makedirs(best_ckpt_dir, exist_ok=True)
                    
                    controlnet_canny.save_pretrained(os.path.join(best_ckpt_dir, "controlnet_canny"))
                    torch.save(opt.state_dict(), os.path.join(best_ckpt_dir, "optimizer.pt"))
                    
                    # ä¿å­˜æœ€ä½³æ¨¡å‹çš„å…ƒä¿¡æ¯
                    with open(os.path.join(best_ckpt_dir, "best_info.txt"), "w") as f:
                        f.write(f"Best Step: {best_step}\n")
                        f.write(f"Best Validation Loss: {best_val_loss:.6f}\n")
                    
                    print(f"\n{'='*70}")
                    print(f"ğŸ’¾ Best Checkpoint å·²ä¿å­˜: {best_ckpt_dir}")
                    print(f"{'='*70}\n")
                
                # 5. åˆ›å»ºæ¨ç†æµ‹è¯•ç›®å½•ï¼ˆåªä¿å­˜æ¨ç†å›¾åƒï¼Œä¸ä¿å­˜æƒé‡ï¼‰
                step_inference_dir = os.path.join(out_dir, f"step_{global_step}")
                os.makedirs(step_inference_dir, exist_ok=True)
                
                # 6. è¿è¡Œæ¨ç†æµ‹è¯•ï¼ˆæ¨ç†å›¾ä¿å­˜åˆ° step_XXX ç›®å½•ï¼‰
                run_inference_test(fixed_sample_row, step_inference_dir, global_step, args.mode)
                
                # 7. æ—©åœåˆ¤æ–­ï¼ˆåªåœ¨ warm-up æœŸåè§¦å‘ï¼‰
                if global_step >= min_train_steps and wait >= patience:
                    print(f"\n{'='*70}")
                    print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼")
                    print(f"  éªŒè¯æŸå¤±è¿ç»­ {patience} æ¬¡æœªæå‡")
                    print(f"  æœ€ä½³æ­¥æ•°: {best_step}")
                    print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
                    print(f"  å½“å‰æ­¥æ•°: {global_step}")
                    print(f"{'='*70}\n")
                    
                    early_stopped = True
                    break  # é€€å‡ºè®­ç»ƒå¾ªç¯

    # ============ æœ€ç»ˆè¾“å‡º ============
    print("\n" + "="*70)
    print("ã€è®­ç»ƒå®Œæˆã€‘âœ…")
    print("="*70)
    
    if early_stopped:
        print(f"  è®­ç»ƒæ–¹å¼: æ—©åœï¼ˆéªŒè¯æŸå¤±è¿ç»­ {patience} æ¬¡æœªæå‡ï¼‰")
        print(f"  å®é™…è®­ç»ƒæ­¥æ•°: {global_step} / {max_steps}")
    else:
        print(f"  è®­ç»ƒæ–¹å¼: æ­£å¸¸å®Œæˆ")
        print(f"  è®­ç»ƒæ­¥æ•°: {max_steps}")
    
    print(f"\n  æœ€ä½³æ¨¡å‹:")
    print(f"    æ­¥æ•°: {best_step}")
    print(f"    éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    print(f"    è·¯å¾„: {best_ckpt_dir}")
    
    print(f"\n  æœ€æ–°æ¨¡å‹:")
    print(f"    æ­¥æ•°: {global_step}")
    print(f"    è·¯å¾„: {latest_ckpt_dir}")
    
    print(f"\n  è®­ç»ƒæ—¥å¿—: {os.path.join(out_dir, 'training_log.txt')}")
    print("="*70 + "\n")


if __name__ == "__main__":
    print("1")
    main()

