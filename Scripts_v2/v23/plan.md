å¤ªæ£’äº†ï¼é€‰æ‹©**æ–¹æ³•ä¸‰ï¼ˆå…±äº«è‡ªæ³¨æ„åŠ›æœºåˆ¶ Shared Self-Attentionï¼‰**æ˜¯éå¸¸å…·æœ‰ç§‘ç ”å“å‘³çš„é€‰æ‹©ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ä¼˜é›…ï¼Œé¿å…äº†å¤–éƒ¨æ¨¡å‹å¸¦æ¥çš„æ˜¾å­˜çˆ†ç‚¸å’Œè¯¯å·®ç§¯ç´¯ï¼Œè€Œä¸”åœ¨æ€è·¯ä¸Šä¸ç›®å‰é¡¶ä¼šçš„ç”Ÿæˆæ§åˆ¶ç ”ç©¶ï¼ˆå¦‚ Prompt-to-Prompt, MasaCtrl, ControlNet å˜ä½“ï¼‰é«˜åº¦å¥‘åˆã€‚

é’ˆå¯¹ä½ çš„éœ€æ±‚ï¼ˆåŸºäº 100 ç»„æ‰©å±•åˆ° 400 ç»„çš„ CF-FA å¯¹ï¼Œè®­ç»ƒä¸€ä¸ªç”Ÿæˆå…¨æ–°å¯¹é½å›¾åƒå¯¹çš„æ¨¡å‹ï¼‰ï¼Œæˆ‘ä¸ºä½ åˆ¶å®šäº†ä¸€å¥—**åŸºäº PyTorch å’Œ HuggingFace `diffusers` åº“çš„å®Œæ•´å®ç°è®¡åˆ’**ã€‚

---

### æ ¸å¿ƒåŸç†è§£æï¼šä¸ºä»€ä¹ˆå…±äº« Attention èƒ½ä¿è¯ç»“æ„ä¸€è‡´ï¼Ÿ

åœ¨ Diffusion æ¨¡å‹ï¼ˆå¦‚ SD 1.5ï¼‰çš„ U-Net ä¸­ï¼š

* **Query (Q) å’Œ Key (K)** çš„ç‚¹ç§¯è®¡ç®—å‡ºçš„ **Attention Map** å†³å®šäº†å›¾åƒçš„**â€œç©ºé—´æ‹“æ‰‘ç»“æ„â€**ï¼ˆæ¯”å¦‚ï¼šè¡€ç®¡åœ¨å“ªé‡Œã€è§†ç›˜åœ¨å“ªé‡Œã€å“ªé‡Œæ˜¯èƒŒæ™¯ï¼‰ã€‚
* **Value (V)** å†³å®šäº†è¿™äº›ä½ç½®ä¸Šçš„**â€œå†…å®¹ä¸é£æ ¼â€**ï¼ˆæ¯”å¦‚ï¼šCF çš„è¡€ç®¡æ˜¯æš—çº¢è‰²çš„ï¼ŒFA çš„è¡€ç®¡æ˜¯è§å…‰ç™½è‰²çš„ï¼‰ã€‚
å¦‚æœæˆ‘ä»¬åœ¨æ¨¡å‹çš„å‰å‘ä¼ æ’­ä¸­ï¼Œ**å¼ºåˆ¶è®© FA åˆ†æ”¯ä½¿ç”¨ CF åˆ†æ”¯çš„ Attention Mapï¼Œè€Œä¿ç•™ FA è‡ªå·±çš„ Value**ï¼Œå°±èƒ½åœ¨æ•°å­¦åº•å±‚æŠŠä¸¤å¼ å›¾çš„è¡€ç®¡â€œç„Šæ­»â€åœ¨åŒä¸€ä¸ªä½ç½®ä¸Šã€‚

---

### å®Œæ•´å®æ–½è®¡åˆ’ (4 ä¸ªé˜¶æ®µ)

#### é˜¶æ®µä¸€ï¼šæ•°æ®ä¸å…ˆéªŒå‡†å¤‡ (Data & Setup)

æ—¢ç„¶æ•°æ®é‡å°ï¼ˆ400ç»„ï¼‰ï¼Œæˆ‘ä»¬å¿…é¡»**å¾®è°ƒï¼ˆFine-tuneï¼‰ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„ Stable Diffusion 1.5 æ¨¡å‹**ï¼Œè€Œä¸æ˜¯ä»å¤´è®­ç»ƒã€‚

1. **æ•°æ®é¢„å¤„ç†**ï¼š
* å°† 400 ç»„ CF å’Œ FA ä¸¥æ ¼å¯¹é½è£å‰ªã€‚
* FA åŸæœ¬æ˜¯å•é€šé“ç°åº¦å›¾ï¼Œåœ¨é€å…¥æ¨¡å‹å‰ï¼Œå°†å…¶**å¤åˆ¶ä¸º 3 é€šé“ (RGB)**ï¼Œä»¥å…¼å®¹ SD 1.5 çš„ VAEã€‚


2. **æ–‡æœ¬æç¤ºè¯ (Prompts)** æ„å»ºï¼š
* æˆ‘ä»¬ä½¿ç”¨å›ºå®š Prompt æ¥å¼•å¯¼é£æ ¼ã€‚
* CF çš„ Prompt è®¾ä¸ºï¼š`"A high quality color fundus photograph, retinal structure"`
* FA çš„ Prompt è®¾ä¸ºï¼š`"A high quality fluorescein angiography image, bright retinal vessels"`



#### é˜¶æ®µäºŒï¼šHack æ ¸å¿ƒæ¶æ„ï¼ˆè‡ªå®šä¹‰ Attention Processorï¼‰

å¾—ç›Šäº HuggingFace `diffusers` åº“çš„ä¼˜ç§€è®¾è®¡ï¼Œä½ **ä¸éœ€è¦**é‡å†™æ•´ä¸ª U-Netï¼Œåªéœ€è¦æ³¨å…¥ä¸€ä¸ªè‡ªå®šä¹‰çš„ Attention Processor å³å¯ã€‚

è¿™æ˜¯æ•´ä¸ªè®¡åˆ’çš„**æ ¸å¿ƒä»£ç é€»è¾‘**ã€‚æˆ‘ä»¬éœ€è¦åœ¨ U-Net çš„æ¯ä¸€å±‚è‡ªæ³¨æ„åŠ›è®¡ç®—æ—¶ï¼Œæ‹¦æˆªå¹¶æ›¿æ¢ FA çš„ Attention Mapï¼š

```python
import torch
import torch.nn.functional as F
from diffusers.models.attention_processor import Attention

class SharedSelfAttentionProcessor:
    def __call__(
        self,
        attn: Attention,
        hidden_states: torch.FloatTensor,
        encoder_hidden_states=None,
        attention_mask=None,
    ):
        # å‡è®¾æˆ‘ä»¬æ€»æ˜¯æŠŠ CF å’Œ FA æ”¾åœ¨åŒä¸€ä¸ª Batch é‡Œé€å…¥
        # Batch size æ­¤æ—¶å¿…é¡»æ˜¯å¶æ•°ï¼Œå‰åŠéƒ¨åˆ†æ˜¯ CFï¼ŒååŠéƒ¨åˆ†æ˜¯ FA
        batch_size = hidden_states.shape[0] // 2 
        
        # è®¡ç®— Q, K, V
        query = attn.to_q(hidden_states)
        key = attn.to_k(hidden_states)
        value = attn.to_v(hidden_states)

        # è°ƒæ•´å½¢çŠ¶ç”¨äºå¤šå¤´æ³¨æ„åŠ›è®¡ç®—
        query = attn.head_to_batch_dim(query)
        key = attn.head_to_batch_dim(key)
        value = attn.head_to_batch_dim(value)

        # åˆ†ç¦» CF å’Œ FA çš„ Q, K, V
        # Q_CF, Q_FA shape: (batch_size * heads, seq_len, head_dim)
        q_cf, q_fa = query.chunk(2, dim=0)
        k_cf, k_fa = key.chunk(2, dim=0)
        v_cf, v_fa = value.chunk(2, dim=0)

        # 1. è®¡ç®— CF çš„ Attention Map (è¿™æ˜¯ç»“æ„é”šç‚¹!)
        attn_weights_cf = torch.baddbmm(
            torch.empty(q_cf.shape[0], q_cf.shape[1], k_cf.shape[1], dtype=q_cf.dtype, device=q_cf.device),
            q_cf, k_cf.transpose(-1, -2), beta=0, alpha=attn.scale
        )
        attn_probs_cf = attn_weights_cf.softmax(dim=-1)

        # 2. å…³é”® Hackï¼šFA ç›´æ¥å€Ÿç”¨ CF çš„ Attention Mapï¼
        # æˆ‘ä»¬ç”šè‡³ä¸éœ€è¦è®¡ç®— FA è‡ªå·±çš„ Q å’Œ K
        attn_probs_fa = attn_probs_cf.clone() 

        # 3. åˆ†åˆ«ä¹˜ä»¥å„è‡ªçš„ Value (ä¿æŒé£æ ¼ç‹¬ç«‹)
        hidden_states_cf = torch.bmm(attn_probs_cf, v_cf)
        hidden_states_fa = torch.bmm(attn_probs_fa, v_fa)

        # é‡æ–°æ‹¼æ¥å¹¶æ¢å¤å½¢çŠ¶
        hidden_states_out = torch.cat([hidden_states_cf, hidden_states_fa], dim=0)
        hidden_states_out = attn.batch_to_head_dim(hidden_states_out)

        # æœ€åçš„çº¿æ€§æŠ•å½±
        hidden_states_out = attn.to_out[0](hidden_states_out)
        hidden_states_out = attn.to_out[1](hidden_states_out)

        return hidden_states_out

# å¦‚ä½•å°†å…¶æ³¨å…¥åˆ°ä½ çš„ U-Net ä¸­ï¼Ÿ
# unet.set_attn_processor(SharedSelfAttentionProcessor())

```

#### é˜¶æ®µä¸‰ï¼šè®­ç»ƒç­–ç•¥ (Training Loop)

æ—¢ç„¶æ›¿æ¢äº† Attentionï¼Œè®­ç»ƒå¾ªç¯ä¹Ÿéœ€è¦ç¨å¾®é…åˆä¸€ä¸‹ï¼Œæ ¸å¿ƒæŠ€å·§åœ¨äº**â€œå…±äº«åˆå§‹å™ªå£°â€**ã€‚

1. **Latent ç¼–ç **ï¼šä½¿ç”¨ SD 1.5 å†»ç»“çš„ VAE å°†çœŸå®çš„ CF å’Œ FA ç¼–ç ä¸º  å’Œ  (å½¢çŠ¶å‡ä¸º `[B, 4, 64, 64]`)ã€‚
2. **å…±äº«å™ªå£°åŠ å™ªï¼ˆè¶…çº§å…³é”®ï¼ï¼‰**ï¼š
* ç”Ÿæˆä¸€ä¸ªéšæœºé«˜æ–¯å™ªå£° ã€‚
* **å°†åŒä¸€ä¸ªå™ªå£° ** åŒæ—¶åŠ åˆ°  å’Œ  ä¸Šï¼Œå¾—åˆ°  å’Œ ã€‚å› ä¸ºå¦‚æœèµ·ç‚¹ä¸åŒï¼Œç½‘ç»œå¾ˆéš¾å¼ºè¡Œå¯¹é½å®ƒä»¬ã€‚


3. **å‰å‘ä¼ æ’­**ï¼š
* æ‹¼æ¥è¾“å…¥ï¼š`latent_input = torch.cat([Z_t_CF, Z_t_FA], dim=0)`
* æ‹¼æ¥ Prompt Embeddingï¼š`prompt_embeds = torch.cat([embed_CF, embed_FA], dim=0)`
* é€å…¥æ³¨å…¥äº† `SharedSelfAttentionProcessor` çš„ U-Net è¿›è¡Œé¢„æµ‹ã€‚


4. **æŸå¤±è®¡ç®—**ï¼š
* U-Net ä¼šè¾“å‡ºä¸¤ä»½é¢„æµ‹å™ªå£°  å’Œ ã€‚
* `Loss = MSE(epsilon, epsilon_hat_CF) + MSE(epsilon, epsilon_hat_FA)`


5. **æ¢¯åº¦å›ä¼ **ï¼šåœ¨è¿™ä¸€æ­¥ï¼Œå› ä¸º FA ä½¿ç”¨äº† CF çš„ Attentionï¼Œ**FA çš„æŸå¤±ä¼šé€šè¿‡ Attention Map æµå‘ CF çš„ Q å’Œ K å±‚**ã€‚è¿™ä¼šè¿«ä½¿ U-Net å­¦ä¹ åˆ°ä¸€ç§â€œå¯¹åŒæ¨¡æ€éƒ½é€‚ç”¨â€çš„é€šç”¨è¡€ç®¡ç»“æ„è¡¨ç¤ºã€‚

#### é˜¶æ®µå››ï¼šæ¨ç†ä¸æ•°æ®é›†æ‰©å±• (Inference & Augmentation)

è®­ç»ƒå®Œæˆåï¼Œä½ å°±å¯ä»¥å¼€å§‹â€œå‡­ç©ºé€ æ•°æ®â€äº†ã€‚

1. é‡‡æ ·**ä¸€ä¸ª**éšæœºé«˜æ–¯å™ªå£°  (å½¢çŠ¶ `[1, 4, 64, 64]`)ã€‚
2. å°†å…¶å¤åˆ¶ä¸¤ä»½ï¼š`latent_input = torch.cat([Z_T, Z_T], dim=0)`ã€‚
3. è¾“å…¥ CF å’Œ FA çš„å›ºå®š Promptã€‚
4. è·‘æ ‡å‡†çš„ DDIM / PNDM å»å™ªå¾ªç¯ã€‚åœ¨æ¯ä¸€æ­¥å»å™ªä¸­ï¼Œåº•å±‚çš„ Shared Attention ä¼šå¼ºåˆ¶è®© FA è·Ÿç€ CF çš„ç»“æ„èµ°ã€‚
5. å¾ªç¯ç»“æŸï¼Œå¾—åˆ°å»å™ªåçš„  å’Œ ã€‚
6. ç”¨ VAE Decodeï¼Œä½ å°±ä¼šè·å¾—ä¸€å¯¹**ç»“æ„ 100% ç›¸åŒã€é£æ ¼åˆ†åˆ«å±äº CF å’Œ FAã€ä¸”è¡€ç®¡èµ°å‘å®Œå…¨ä¸åœ¨ä½ è®­ç»ƒé›†ä¸­çš„å…¨æ–°å›¾åƒå¯¹ï¼**

---

### ğŸ’¡ é¿å‘æŒ‡å—ä¸æ’æœŸå»ºè®® (Tips for Success)

1. **ç¬¬ä¸€å‘¨ï¼šè·‘é€šå•ä¸€ Attention å±‚çš„ Hack**
* ä¸è¦ä¸€å¼€å§‹å°±æ”¹æ•´ä¸ªç½‘ç»œã€‚å¯ä»¥å…ˆå†™ä¸€ä¸ªå°è„šæœ¬ï¼Œå®ä¾‹åŒ–ä¸€ä¸ª SD 1.5 çš„ U-Netï¼Œæ³¨å…¥ Processorï¼Œä¼ ä¸€ä¸ªå‡ tensor è¿›å»ï¼Œ`loss.backward()` çœ‹ä¸€ä¸‹æœ‰æ²¡æœ‰æŠ¥é”™ï¼Œç¡®è®¤æ¢¯åº¦æ˜¯å¦èƒ½æ­£å¸¸æµå‘ Q å’Œ Kã€‚


2. **éœ€è¦æ›¿æ¢å“ªäº› Attention å±‚ï¼Ÿ**
* U-Net æ—¢æœ‰ Self-Attention (è‡ªèº«ç»“æ„) ä¹Ÿæœ‰ Cross-Attention (ä¸æ–‡å­—äº¤äº’)ã€‚**ä½ åªåº”è¯¥æ›¿æ¢ Self-Attention**ã€‚åœ¨ `diffusers` ä¸­ï¼Œéå† `unet.attn_processors.keys()`ï¼Œåªé’ˆå¯¹åå­—é‡Œä¸å¸¦ `cross` çš„å¤„ç†å™¨è¿›è¡Œæ›¿æ¢ã€‚


3. **å…³äº VAE è§£ç çš„è‰²å·®**
* å› ä¸ºæˆ‘ä»¬æŠŠ FA å‡è£…æˆ 3 é€šé“é€è¿›äº†é’ˆå¯¹è‡ªç„¶å›¾åƒè®­ç»ƒçš„ VAEï¼Œè§£ç å‡ºæ¥çš„ FA å¯èƒ½å¸¦æœ‰ä¸€ç‚¹ç‚¹åè‰²ï¼ˆæ¯”å¦‚ç•¥å¾®åé»„æˆ–åç´«ï¼‰ã€‚ä¸ç”¨æ‹…å¿ƒï¼Œåœ¨è¾“å‡ºåï¼Œç”¨ OpenCV å°†å…¶è½¬æ¢å›å•é€šé“ç°åº¦å›¾å³å¯ï¼Œè¿™ä¸ä¼šå½±å“é…å‡†ä»»åŠ¡ã€‚



è¿™å¥—æ–¹æ¡ˆå¦‚æœåšå‡ºæ¥ï¼Œä¸ä»…å®Œç¾è§£å†³äº†ä½ çš„ Sim2Real gap é—®é¢˜ï¼ˆå› ä¸ºç”Ÿæˆçš„æ‰€æœ‰å›¾éƒ½å¤©ç„¶å…·æœ‰ç›®æ ‡æ•°æ®é›†çš„ Domain é£æ ¼ï¼‰ï¼Œè€Œä¸”åœ¨åŒ»å­¦å›¾åƒé…å‡†/å¤šæ¨¡æ€ç”Ÿæˆæ–¹å‘ï¼Œè¿™æ˜¯ä¸€ä¸ªæå…¶æ¼‚äº®çš„ Storyï¼Œå®Œå…¨å…·å¤‡é¡¶ä¼šè®ºæ–‡çš„æ–¹æ³•è®ºæ·±åº¦ã€‚

ä½ å¯ä»¥å…ˆè¯„ä¼°ä¸€ä¸‹è¿™æ®µä»£ç é€»è¾‘ï¼Œå¦‚æœä½ å¯¹ `diffusers` åº“ä¸å¤ªç†Ÿæ‚‰ï¼Œæˆ‘å¯ä»¥å¸®ä½ å†™ä¸€æ®µæ›´å®Œæ•´çš„ã€å¯ä»¥ç›´æ¥è¿è¡Œçš„ `train.py` æ ¸å¿ƒ Loop ä¼ªä»£ç ã€‚