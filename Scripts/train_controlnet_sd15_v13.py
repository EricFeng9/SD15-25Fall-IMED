# -*- coding: utf-8 -*-
'''
è®­ç»ƒè„šæœ¬ - SD 1.5 + Dual ControlNet ç‰ˆæœ¬ v11

ã€åŸºäºã€‘train_controlnet_sd15_v10-3.py
ã€æ¨¡å‹ã€‘Stable Diffusion 1.5 (512Ã—512) + åŒè·¯ ControlNet (Scribble + Tile)
ã€æ•°æ®é›†ã€‘æ”¯æŒä¸‰ç§æ•°æ®é›†
  - CF-OCTA: é…å‡†æ•°æ®é›† (ç»¿è‰²é€šé“ + Tile)
  - CF-FA: CFFA æ•°æ®é›† (ç»¿è‰²é€šé“ + Tile)
  - CF-OCT: CF_OCT æ•°æ®é›† (ç»¿è‰²é€šé“ + Tile)

ã€v11 æ›´æ–°ã€‘âœ¨ ğŸ¯
1. **Scribble ControlNet è¾“å…¥æ”¹ç”¨ç»¿è‰²é€šé“ï¼ˆä¸å†ä½¿ç”¨Frangiæ»¤æ³¢ï¼‰**
   - å®Œå…¨é¿å…Frangiæ»¤æ³¢äº§ç”Ÿçš„è¾¹ç•Œä¼ªå½±é—®é¢˜
   - ä¿ç•™æ‰€æœ‰è¡€ç®¡ç»†èŠ‚ï¼Œè®©ControlNetè‡ªå·±å­¦ä¹ æå–ç‰¹å¾
   - æ ¹æ®æ¨¡å¼è‡ªåŠ¨å†³å®šæ˜¯å¦å–åï¼š
     * éœ€è¦å–åï¼šcf2fa, cf2octa, oct2cfï¼ˆè®©æš—è¡€ç®¡å˜äº®ï¼‰
     * ä¸å–åï¼šcf2oct, fa2cf, octa2cfï¼ˆä¿æŒåŸæ ·ï¼‰
   - åº”ç”¨CLAHEå¯¹æ¯”åº¦å¢å¼ºï¼Œæå‡è¡€ç®¡å¯è§åº¦
   
2. **Vessel Loss ä¿æŒä½¿ç”¨ Frangi æ»¤æ³¢ + Dice Loss**
   - Scribbleè¾“å…¥ç®€åŒ–ï¼Œä½†Vessel Lossä»ç”¨Frangiæä¾›æ˜¾å¼ç›‘ç£
   - ç¡®ä¿æ¨¡å‹å­¦ä¹ æ­£ç¡®çš„è¡€ç®¡ç»“æ„
   - ç»§ç»­ä½¿ç”¨FOVæ©ç å’Œä¾µèš€å¤„ç†ï¼ˆä»…ç”¨äºVessel Lossè®¡ç®—ï¼‰

ã€v10-3 æ›´æ–°ã€‘âœ¨ ğŸ¯
1. **Vessel Loss æ”¹ç”¨ Dice Loss è®¡ç®—ï¼ˆé’ˆå¯¹ç¨€ç–è¡€ç®¡å›¾ä¼˜åŒ–ï¼‰**
   - ä» MS-SSIM æ”¹ä¸º Dice Lossï¼ˆä¸“ä¸ºç¨€ç–äºŒå€¼ç»“æ„è®¾è®¡ï¼‰
   - è§£å†³èƒŒæ™¯ä¸»å¯¼æ•ˆåº”ï¼ˆ90%é»‘è‰²èƒŒæ™¯æ·¹æ²¡10%è¡€ç®¡ä¿¡å·ï¼‰
   - ä¸å—ä½ç½®åç§»å½±å“ï¼ˆå…³æ³¨é‡å åº¦è€Œéé€åƒç´ å¯¹é½ï¼‰
   - Diceç³»æ•°ï¼š2Ã—|Aâˆ©B| / (|A|+|B|)ï¼Œä¸“æ³¨è¡€ç®¡åŒºåŸŸé‡å 
   - è®­ç»ƒæ›´ç¨³å®šï¼ŒLossä¿¡å·æ›´æ˜ç¡®
   - ç§»é™¤ä¸å¿…è¦çš„3é€šé“æ‰©å±•

ã€v10-3 æ›´æ–°ã€‘âœ¨ ğŸ¯ï¼ˆå·²åºŸå¼ƒï¼Œæ”¹ç”¨Diceï¼‰
1. **Vessel Loss æ”¹ç”¨ MS-SSIM è®¡ç®—**
   - å‘ç°é—®é¢˜ï¼šç¨€ç–è¡€ç®¡å›¾ä¸é€‚åˆSSIMï¼ˆèƒŒæ™¯ä¸»å¯¼æ•ˆåº”ï¼‰
   - å·²åœ¨v10-3ä¸­æ”¹ä¸ºDice Loss

ã€v10-2 æ›´æ–°ã€‘âœ¨
1. **é‡æ„è¡€ç®¡æå–é€»è¾‘ï¼ˆSingle Source of Truthï¼‰**
   - å°†è¡€ç®¡æå–é€»è¾‘ç§»è‡³ `data_loader_all.py` æ¨¡å—
   - æ ¸å¿ƒå‡½æ•°ï¼š`extract_vessel_map_torch` + `frangi_filter_torch`
   - è®­ç»ƒã€éªŒè¯ã€æ¨ç†æµ‹è¯•ã€æ•°æ®åŠ è½½éƒ½ä½¿ç”¨åŒä¸€å¥—å®ç°
   - ä¿®æ”¹ä¸€å¤„ï¼Œæ‰€æœ‰åœ°æ–¹è‡ªåŠ¨åŒæ­¥ï¼ˆé¿å…ä¸ä¸€è‡´é—®é¢˜ï¼‰
   - æ¶ˆé™¤äº† scikit-image å’Œ PyTorch ä¸¤å¥— Frangi å¹¶å­˜çš„é—®é¢˜
   
2. **æ¨ç†æµ‹è¯•è¾“å‡ºè¡€ç®¡å“åº”å›¾**
   - é¢å¤–ä¿å­˜é¢„æµ‹å›¾çš„è¡€ç®¡æå–ç»“æœï¼š`{idx}_pred_vessel_step{step_num}.png`
   - é¢å¤–ä¿å­˜ç›®æ ‡å›¾çš„è¡€ç®¡æå–ç»“æœï¼š`{idx}_target_vessel_step{step_num}.png`
   - ä¾¿äºå¯è§†åŒ–è°ƒè¯• Vessel Loss çš„è®¡ç®—è¿‡ç¨‹
   - ä¸è®­ç»ƒæ—¶ä½¿ç”¨å®Œå…¨ç›¸åŒçš„æå–é€»è¾‘

ã€v10 æ›´æ–°ã€‘âœ¨
1. **ä½¿ç”¨ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ï¼ˆdata_loader_all.pyï¼‰**
   - æ•´åˆä¸‰ä¸ªæ•°æ®é›†åŠ è½½å™¨ï¼ˆCF-OCTAã€CF-FAã€CF_OCTï¼‰
   - ç»Ÿä¸€çš„è¡€ç®¡æå–æ¥å£

2. **gen_mask + ä¾µèš€æ©ç ï¼ˆè§£å†³è¾¹ç•Œè¯¯è¯†åˆ«é—®é¢˜ï¼‰**
   - ä½¿ç”¨ gen_mask æ£€æµ‹é»‘è¾¹åŒºåŸŸï¼ˆè‡ªé€‚åº”ä»»æ„å½¢çŠ¶ï¼‰
   - å¯¹æ©ç å‘å†…ä¾µèš€æŒ‡å®šåƒç´ æ•°ï¼ˆCFå›¾10pxï¼ŒFAå›¾20pxï¼‰
   - åº”ç”¨èŒƒå›´ï¼š
     * Scribble ControlNet è¾“å…¥ï¼šFrangiæ»¤æ³¢ + FOVæ©ç 
     * Vessel Loss è®¡ç®—ï¼šFrangiæ»¤æ³¢ + FOVæ©ç ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
   - ç§»é™¤è¾¹ç•Œä¼ªå½±ï¼Œé¿å…è¯¯è®¤ä¸ºè¡€ç®¡
   - æ¯”åœ†å½¢æ©ç æ›´ç²¾ç¡®ï¼Œé€‚åº”ä¸åŒæ•°æ®é›†

ã€æ ¸å¿ƒç‰¹ç‚¹ã€‘
- åŒè·¯ ControlNet æ¶æ„ï¼ˆè¡€ç®¡ç»“æ„ + åŸå›¾ç»†èŠ‚ï¼‰
  * ControlNet-Scribble: è¡€ç®¡ç»“æ„å¼•å¯¼ï¼ˆã€v11ã€‘ä½¿ç”¨ç»¿è‰²é€šé“+å¯é€‰å–å+CLAHEï¼‰
  * ControlNet-Tile: åŸå›¾ç»†èŠ‚ä¿ç•™ï¼ˆçº¹ç†ã€å¼ºåº¦ã€é¢œè‰²ï¼‰
- SD 1.5 åŸç”Ÿæ”¯æŒ 512Ã—512 åˆ†è¾¨ç‡
- **ã€v11æ›´æ–°ã€‘Scribbleè¾“å…¥æ”¹ç”¨ç»¿è‰²é€šé“ï¼Œé¿å…Frangiè¾¹ç•Œä¼ªå½±**
- **ã€v8-3-2æ›´æ–°ã€‘CFè®­ç»ƒé›†æ”¹ç”¨å½©è‰²åŸå›¾ï¼ŒTileè¾“å…¥ç›´æ¥ä½¿ç”¨åŸå›¾**
- Vessel Lossç»§ç»­ä½¿ç”¨Frangiæ»¤æ³¢æä¾›æ˜¾å¼ç›‘ç£
- FP32 è®­ç»ƒ

ã€v13 æ›´æ–°ã€‘âœ¨ ğŸ¯
1. **CF_OCT é…å‡†æ–¹æ¡ˆå‡çº§ä¸ºé€è§†å˜æ¢**
   - ä½¿ç”¨é€è§†å˜æ¢ï¼ˆHomographyï¼‰æ›¿ä»£ä»¿å°„å˜æ¢ï¼ˆæ›´ç²¾ç¡®ï¼‰
   - ä¸ç®¡ cf2oct è¿˜æ˜¯ oct2cfï¼Œç»Ÿä¸€é…å‡†åˆ° CF åŸŸï¼ˆ1016Ã—675ï¼‰
   - é…å‡†åç›´æ¥ resize åˆ° 512Ã—512ï¼ˆä¸ä½¿ç”¨ resize_with_paddingï¼‰
   - ä½¿ç”¨ registration_cf_oct_v2.register_cfoct_pair() ç»Ÿä¸€æ¥å£
   - è®­ç»ƒå’Œæ¨ç†ä½¿ç”¨å®Œå…¨ç›¸åŒçš„é…å‡†é€»è¾‘ï¼ˆdata_loader_all_v13ï¼‰

ã€v9-2 æ›´æ–°ã€‘âœ¨ï¼ˆå·²è¢«v13æ›¿ä»£ï¼‰
1. **CF_OCT é…å‡†æ–¹æ¡ˆå‡çº§ï¼ˆæ¨ç†æµ‹è¯•éƒ¨åˆ†ï¼‰**
   - ä½¿ç”¨æ–°çš„é…å‡†æ–¹æ¡ˆï¼ˆregistration_cf_oct.py æ–¹æ¡ˆ1ï¼‰
   - ç›´æ¥åœ¨åŸå§‹åæ ‡ç³»è®¡ç®—ä»¿å°„çŸ©é˜µï¼ˆæ— éœ€é¢„å…ˆå½’ä¸€åŒ–ï¼‰
   - æ­£ç¡®çš„é…å‡†æµç¨‹ï¼šå…ˆé…å‡†åˆ°ç›®æ ‡åŸŸåŸå§‹å°ºå¯¸ï¼Œå† resize_with_padding åˆ° 512Ã—512
   - ä¾‹å¦‚ OCTâ†’CFï¼šå…ˆé…å‡†åˆ° CF åŸå§‹å°ºå¯¸(1016Ã—675)ï¼Œå† resize åˆ° 512Ã—512
   - ä½¿ç”¨ register_image_with_keypoints() ç»Ÿä¸€æ¥å£ï¼ˆè‡ªåŠ¨å¤„ç†é…å‡†+resizeï¼‰

2. **ä¿®å¤é¢„å¤„ç†é¡ºåºä¸ä¸€è‡´é—®é¢˜ï¼ˆæ¨ç†æµ‹è¯•éƒ¨åˆ†ï¼‰**
   - CF-FA å’Œ CF-OCTAï¼šä¿æŒä¸è®­ç»ƒä¸€è‡´çš„é¡ºåºï¼ˆå…ˆä»åŸå›¾æå–è¡€ç®¡ï¼Œå† resizeï¼‰
   - CF_OCTï¼šä½¿ç”¨æ–°é…å‡†æ–¹æ¡ˆï¼ˆå…ˆ resize_with_paddingï¼Œå†æå–è¡€ç®¡ï¼‰
   - ç¡®ä¿æ¨ç†æ—¶çš„æ•°æ®å¤„ç†ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼Œé¿å…è¡€ç®¡åç§»é—®é¢˜

ã€v9-1 æ›´æ–°ã€‘âœ¨
1. **MSE Loss åœ¨å™ªå£°ç©ºé—´åº”ç”¨è’™ç‰ˆæ¶ˆé™¤é»‘è¾¹å½±å“**
   - åœ¨åƒç´ ç©ºé—´æ£€æµ‹GTçš„é»‘è¾¹åŒºåŸŸ
   - å°†è’™ç‰ˆdownsampleåˆ°latentç©ºé—´ï¼ˆå™ªå£°ç©ºé—´ï¼‰
   - åœ¨å™ªå£°ç©ºé—´åº”ç”¨è’™ç‰ˆè®¡ç®—MSEï¼ˆä¿æŒæ‰©æ•£æ¨¡å‹æ ‡å‡†è®­ç»ƒèŒƒå¼ï¼‰
   - MS-SSIMå’ŒVessel Lossåœ¨åƒç´ ç©ºé—´åº”ç”¨è’™ç‰ˆ
   - ç¡®ä¿ä¸‰ä¸ªæŸå¤±å‡½æ•°éƒ½ä¸å—é…å‡†é»‘è¾¹å½±å“

ã€v8-3-3 æ›´æ–°ã€‘âœ¨
1. **ä¿®å¤ Vessel Loss é€»è¾‘**
   - octa2cf æ¨¡å¼ï¼šCFå›¾ï¼ˆé¢„æµ‹+GTï¼‰åœ¨æå–ç»¿è‰²é€šé“åéœ€è¦å–å
   - åŸå› ï¼šCFå›¾è¡€ç®¡æ˜¯æš—è‰²ï¼Œéœ€è¦è½¬ä¸ºäº®è¡€ç®¡åæ‰èƒ½æ­£ç¡®åº”ç”¨Frangiæ»¤æ³¢
   - ä¸ CF-FA æ¨¡å¼çš„ fa2cf é€»è¾‘ä¿æŒä¸€è‡´
   
2. **ä¿®å¤é…å‡†é»‘è¾¹å¹²æ‰°é—®é¢˜**
   - CFå›¾å–åå‰å…ˆå°†å…¨é»‘åƒç´ ï¼ˆé…å‡†é»‘è¾¹ï¼‰æ›¿æ¢æˆçº¯ç™½
   - åŸå› ï¼šé»‘è¾¹(0)å–ååå˜ç™½(255)ä¼šè¢«Frangiè¯¯è®¤ä¸ºè¡€ç®¡
   - è§£å†³ï¼šé»‘è¾¹å…ˆè®¾ä¸ºç™½(1.0) â†’ å–ååå˜é»‘(0) â†’ ä¸å¹²æ‰°è¡€ç®¡æ£€æµ‹

ã€v8-3-2 æ›´æ–°ã€‘âœ¨
1. **CF-OCTA æ•°æ®é›†æ›´æ–°**
   - CF è®­ç»ƒé›†å›¾åƒå·²æ”¹ä¸ºå½©è‰²åŸå›¾
   - cf2octa æ¨¡å¼ï¼šTile è¾“å…¥ç›´æ¥ä½¿ç”¨ CF å½©è‰²åŸå›¾ï¼ˆä¸åšé¢„å¤„ç†ï¼‰
   - octa2cf æ¨¡å¼ï¼šç›®æ ‡å›¾ç›´æ¥ä½¿ç”¨ CF å½©è‰²åŸå›¾ï¼ˆä¸åšé¢„å¤„ç†ï¼‰
   - Scribbleï¼ˆè¡€ç®¡å›¾ï¼‰ï¼šç›´æ¥ä¼ å…¥åŸå›¾åˆ° Frangi æ»¤æ³¢å‡½æ•°
     * CFå›¾ï¼šå‡½æ•°å†…éƒ¨è‡ªåŠ¨æå–ç»¿è‰²é€šé“ + å–åï¼ˆæš—è¡€ç®¡â†’äº®è¡€ç®¡ï¼‰
     * OCTAå›¾ï¼šå‡½æ•°å†…éƒ¨è‡ªåŠ¨æå–ç»¿è‰²é€šé“ï¼ˆè¡€ç®¡å·²æ˜¯äº®è‰²ï¼‰

2. **è¡€ç®¡ç»“æ„æŸå¤± (Vessel Loss) - æ‰€æœ‰æ¨¡å¼å¯ç”¨**
   - ã€v10-3ã€‘ä½¿ç”¨ Frangi è¡€ç®¡æ»¤æ³¢ + Dice Lossï¼ˆä¸“ä¸ºç¨€ç–è¡€ç®¡å›¾è®¾è®¡ï¼‰
   - CF-FAæ•°æ®é›†ï¼šsigmas=FRANGI_SIGMAS, gamma=GAMMA_CFFA
     * CFå›¾åƒï¼šæå–ç»¿è‰²é€šé“ + å–åï¼ˆæš—è¡€ç®¡â†’äº®è¡€ç®¡ï¼‰
     * FAå›¾åƒï¼šæå–ç»¿è‰²é€šé“ï¼ˆäº®è¡€ç®¡ï¼‰
   - CF-OCTAæ•°æ®é›†ï¼šsigmas=FRANGI_SIGMAS
     * CFå›¾åƒï¼šgamma=GAMMA_CFOCTA_CFï¼ˆScribbleç”¨ç»¿è‰²é€šé“+å–åæå–è¡€ç®¡ï¼‰
     * OCTAå›¾åƒï¼šgamma=GAMMA_CFOCTA_OCTAï¼ˆç›´æ¥è½¬ç°åº¦ï¼‰
   - å›ºå®šæƒé‡ï¼ˆå¯é€šè¿‡ --vessel_lambda è°ƒèŠ‚ï¼Œé»˜è®¤0.05ï¼‰

3. **å¤šæŸå¤±å‡½æ•°è®­ç»ƒ**
   - MSE Loss (å™ªå£°é¢„æµ‹) - æƒé‡å›ºå®š 1.0
   - MS-SSIM Loss (æ„ŸçŸ¥è´¨é‡) - æƒé‡å›ºå®š 0.1 (å¯è°ƒ)
   - Vessel Loss (Frangi + Dice) - æƒé‡å›ºå®š 0.05 (æ‰€æœ‰æ¨¡å¼) ã€v10-3æ”¹è¿›ã€‘
   - æ‰€æœ‰æƒé‡ä»å¤´åˆ°å°¾ä¿æŒä¸å˜ï¼Œé¿å…åæœŸå˜å½¢

4. **å­¦ä¹ ç‡å¹³æ»‘è¡°å‡**
   - step<4000: lr=5e-5
   - stepâ‰¥4000: Cosine è¡°å‡ 5e-5 â†’ 1e-5
   - é˜²æ­¢ç ´åå·²å­¦åˆ°çš„å…¨å±€ç»“æ„

5. **æ›´é¢‘ç¹çš„æ£€æŸ¥ç‚¹ä¿å­˜**
   - æ¯ 500 æ­¥ä¿å­˜æƒé‡å¹¶è¿è¡Œæ¨ç†æµ‹è¯•ï¼ˆåŸä¸º1000æ­¥ï¼‰
   - ä¾¿äºç²¾ç»†é€‰æ‹©æœ€ä½³ checkpoint

ã€ä½¿ç”¨æ–¹æ³•ã€‘
# CF-FA è®­ç»ƒï¼ˆåŒè·¯Vessel+Tileæ¨¡å¼ï¼Œgamma=0.015ï¼‰
python train_controlnet_sd15_v9.py --mode cf2fa --name sd15_v9-1_cffa --max_steps 8000 --scribble_scale 0.8 --vessel_lambda 0.05

# CF-OCTA è®­ç»ƒï¼ˆåŒè·¯Vessel+Tileæ¨¡å¼ï¼Œgamma_cf=0.008, gamma_octa=0.1ï¼‰
python train_controlnet_sd15_v9.py --mode cf2octa --name sd15_v9-1_cfocta --max_steps 8000 --scribble_scale 0.8 --vessel_lambda 0.05

# CF_OCT è®­ç»ƒï¼ˆåŒè·¯Vessel+Tileæ¨¡å¼ï¼Œgamma_cf=0.015, gamma_oct=0.02ï¼‰
python train_controlnet_sd15_v9.py --mode cf2oct --name sd15_v9-1_cfoct --max_steps 8000 --scribble_scale 0.8 --vessel_lambda 0.05

å‚æ•°è°ƒèŠ‚:
  --scribble_scale: Scribble ControlNet å¼ºåº¦ (é»˜è®¤ 0.8ï¼Œæ‰€æœ‰æ¨¡å¼)
  --tile_scale: Tile ControlNet å¼ºåº¦ (é»˜è®¤ 1.0)
  --msssim_lambda: MS-SSIM æŸå¤±æƒé‡ (é»˜è®¤ 0.1ï¼Œå›ºå®šä¸å˜ï¼Œåº”ç”¨è’™ç‰ˆ)
  --vessel_lambda: Vessel Loss æƒé‡ (é»˜è®¤ 0.05ï¼Œæ‰€æœ‰æ¨¡å¼ç”Ÿæ•ˆï¼Œåº”ç”¨è’™ç‰ˆ)

ã€v9-1 é‡è¦æ”¹è¿›ã€‘
  MSE Lossåœ¨å™ªå£°ç©ºé—´åº”ç”¨è’™ç‰ˆï¼ˆä¿æŒæ‰©æ•£æ¨¡å‹æ ‡å‡†è®­ç»ƒèŒƒå¼ï¼‰
  MS-SSIMå’ŒVessel Lossåœ¨åƒç´ ç©ºé—´åº”ç”¨è’™ç‰ˆ
  è‡ªåŠ¨æ£€æµ‹å¹¶æ’é™¤GTä¸­çš„é»‘è¾¹åŒºåŸŸï¼ˆé…å‡†è¾¹ç¼˜ï¼‰
  æ—¢æ¶ˆé™¤é»‘è¾¹å½±å“ï¼Œåˆé¿å…æƒé‡å¤±è¡¡å’Œæ¢¯åº¦ä¼ æ’­é—®é¢˜
  è®­ç»ƒè´¨é‡ä¸åŸç‰ˆç›¸å½“æˆ–æ›´å¥½ï¼ŒåŒæ—¶æ­£ç¡®å¤„ç†é…å‡†é»‘è¾¹
'''

import os
# ============ è®¾ç½®ç¦»çº¿æ¨¡å¼ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ HF åº“ä¹‹å‰ï¼‰============
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"
os.environ["HF_HUB_DISABLE_TELEMETRY"] = "1"
os.environ["DISABLE_TELEMETRY"] = "1"

import csv, math, itertools
import torch, numpy as np
import cv2
from PIL import Image
from torch import nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from diffusers import (DDPMScheduler, StableDiffusionControlNetPipeline,
                       ControlNetModel, 
                       AutoencoderKL, UNet2DConditionModel)
from transformers import CLIPTextModel, CLIPTokenizer
from pytorch_msssim import MS_SSIM  # ä»…ç”¨äºåƒç´ ç©ºé—´çš„MS-SSIM Lossï¼ŒVessel Losså·²æ”¹ç”¨Dice
import time
import argparse

# å¯¼å…¥ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ï¼ˆv13ï¼šä½¿ç”¨æ–°çš„CF-OCTé…å‡†é€»è¾‘ï¼‰
from data_loader_all_v13 import (
    UnifiedDataset, SIZE, preprocess_for_vessel_extraction,
    GAMMA_CFFA, GAMMA_CFOCTA_CF, GAMMA_CFOCTA_OCTA,  # v10: Frangiå‚æ•°ï¼ˆä»…ç”¨äºVessel Lossï¼‰
    GAMMA_CFOCT_CF, GAMMA_CFOCT_OCT, FRANGI_SIGMAS, FRANGI_ALPHA, FRANGI_BETA,
    create_eroded_mask,  # v10: FOVæ©ç ç”Ÿæˆï¼ˆç”¨äºVessel Lossï¼‰
    get_image_params,    # v10: ç»Ÿä¸€å›¾åƒå¤„ç†å‚æ•°é…ç½®ï¼ˆè®­ç»ƒå’Œæ¨ç†å…±ç”¨ï¼‰
    frangi_filter_torch, extract_vessel_map_torch  # v10-2: PyTorchå¯å¾®è¡€ç®¡æå–ï¼ˆè®­ç»ƒ/éªŒè¯/æ¨ç†å…±ç”¨ï¼‰
)
from registration_cf_octa import load_affine_matrix, apply_affine_registration

# ============ SD 1.5 + Dual ControlNet æ¨¡å‹è·¯å¾„é…ç½® ============
base_dir = "/data/student/Fengjunming/SDXL_ControlNet/models/sd15-diffusers"
ctrl_scribble_dir = "/data/student/Fengjunming/SDXL_ControlNet/models/controlnet-sd15-scribble"
ctrl_tile_dir = "/data/student/Fengjunming/SDXL_ControlNet/models/controlnet-sd15-tile"

# CSV æ•°æ®è·¯å¾„é…ç½®ï¼ˆæ ¹æ®æ¨¡å¼é€‰æ‹©ï¼‰
CFOCTA_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_v2-2_repaired.csv"
CFOCTA_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_v2-2_repaired.csv"
CFFA_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_cffa.csv"
CFFA_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_cffa.csv"
CFOCT_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_cfoct.csv"
CFOCT_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_cfoct.csv"

# è¾“å‡ºç›®å½•
out_root  = "/data/student/Fengjunming/SDXL_ControlNet/results/out_ctrl_sd15_dual"
device    = torch.device("cuda")

# CF-FA åŸå§‹å›¾åƒå°ºå¯¸
CFFA_ORIGINAL_SIZE = (720, 576)  # width, height

# æ³¨æ„ï¼šå›¾åƒå¤„ç†å‚æ•°é…ç½®å·²ç§»è‡³ data_loader_all.py
# ä½¿ç”¨ get_image_params(mode, param_type) è·å–ç»Ÿä¸€é…ç½®
# ç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°

# ============ ç¼–ç å·¥å…·å‡½æ•° ============
def get_prompt_embeds(bs):
    """
    SD 1.5 æ–‡æœ¬ç¼–ç ï¼ˆç®€åŒ–ç‰ˆï¼Œåªè¿”å› prompt_embedsï¼‰
    """
    prompts = [""] * bs
    text_inputs = tokenizer(
        prompts,
        padding="max_length",
        max_length=tokenizer.model_max_length,
        truncation=True,
        return_tensors="pt",
    )
    text_input_ids = text_inputs.input_ids.to(device)
    prompt_embeds = text_encoder(text_input_ids)[0]
    return prompt_embeds

def encode_vae(img):
    """VAE ç¼–ç ï¼šimg [-1,1] â†’ latents"""
    latents = vae.encode(img).latent_dist.sample() * vae_sf
    return latents

def decode_vae(latents):
    """VAE è§£ç ï¼šlatents â†’ img [-1,1]"""
    img = vae.decode(latents / vae_sf).sample
    return img


# ============ æ¢¯åº¦åŒ¹é…å·¥å…·å‡½æ•° ============
def _get_sobel_kernels(device, dtype):
    base_kernel = torch.tensor(
        [[1., 0., -1.],
         [2., 0., -2.],
         [1., 0., -1.]],
        device=device,
        dtype=dtype
    )
    kernel_x = base_kernel.view(1, 1, 3, 3)
    kernel_y = base_kernel.t().view(1, 1, 3, 3)
    return kernel_x, kernel_y


def compute_image_gradients(image):
    """
    è®¡ç®—å›¾åƒçš„ Sobel æ¢¯åº¦ã€‚

    Args:
        image: (B, C, H, W) tensorï¼ŒèŒƒå›´ [0, 1]

    Returns:
        grad_x, grad_y: ä¸è¾“å…¥åŒå½¢çŠ¶çš„æ¢¯åº¦å¼ é‡
    """
    kernel_x, kernel_y = _get_sobel_kernels(image.device, image.dtype)
    kernel_x = kernel_x.expand(image.shape[1], 1, 3, 3)
    kernel_y = kernel_y.expand(image.shape[1], 1, 3, 3)
    grad_x = F.conv2d(image, kernel_x, padding=1, groups=image.shape[1])
    grad_y = F.conv2d(image, kernel_y, padding=1, groups=image.shape[1])
    return grad_x, grad_y


def compute_gradient_match_loss(pred_imgs_01, gt_imgs_01, mask=None, reduction="l1"):
    """
    æ¢¯åº¦åŒ¹é…æŸå¤±ï¼šçº¦æŸé¢„æµ‹å›¾ä¸ç›®æ ‡å›¾åœ¨æ¢¯åº¦ç©ºé—´ä¿æŒä¸€è‡´ã€‚

    Args:
        pred_imgs_01: (B, 3, H, W) é¢„æµ‹å›¾åƒï¼ŒèŒƒå›´ [0, 1]
        gt_imgs_01: (B, 3, H, W) ç›®æ ‡å›¾åƒï¼ŒèŒƒå›´ [0, 1]
        mask: (B, 1, H, W) å¯é€‰ï¼Œ0 è¡¨ç¤ºå¿½ç•¥åŒºåŸŸ
        reduction: 'l1' æˆ– 'l2'

    Returns:
        æ ‡é‡æŸå¤±å€¼
    """
    # ä½¿ç”¨ç»¿è‰²é€šé“ä½œä¸ºç°åº¦åŸºç¡€ï¼ˆOCT å¯¹æ¯”åº¦æœ€ä½³ï¼‰
    pred_gray = pred_imgs_01[:, 1:2, :, :]
    gt_gray = gt_imgs_01[:, 1:2, :, :]

    pred_grad_x, pred_grad_y = compute_image_gradients(pred_gray)
    gt_grad_x, gt_grad_y = compute_image_gradients(gt_gray)

    if reduction == "l2":
        diff = (pred_grad_x - gt_grad_x) ** 2 + (pred_grad_y - gt_grad_y) ** 2
    else:
        diff = (pred_grad_x - gt_grad_x).abs() + (pred_grad_y - gt_grad_y).abs()

    if mask is not None:
        diff = diff * mask

    return diff.mean()


# ============ v8-3 æ–°å¢ï¼šFrangi è¡€ç®¡æ»¤æ³¢æŸå¤± ============
# ============ v10-2 é‡æ„ï¼šè¡€ç®¡æå–é€»è¾‘å·²ç§»è‡³ data_loader_all.py ============
# ============ v10-3 æ”¹è¿›ï¼šä» MS-SSIM æ”¹ä¸º Dice Lossï¼ˆè§£å†³ç¨€ç–è¡€ç®¡å›¾é—®é¢˜ï¼‰============
# ä» data_loader_all å¯¼å…¥ï¼šfrangi_filter_torch, extract_vessel_map_torch

def compute_vessel_loss_frangi(pred_imgs, gt_imgs, mode='cf2fa', sigmas=FRANGI_SIGMAS, 
                                alpha=FRANGI_ALPHA, beta=FRANGI_BETA, 
                                gamma_cffa=GAMMA_CFFA, 
                                gamma_cfocta_cf=GAMMA_CFOCTA_CF, 
                                gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                                gamma_cfoct_cf=GAMMA_CFOCT_CF, 
                                gamma_oct=GAMMA_CFOCT_OCT,
                                fov_threshold=10,
                                erode_pixels=10,
                                image_border_margin=5,
                                debug_dir=None):
    """
    è¡€ç®¡ç»“æ„æŸå¤± - ä½¿ç”¨ Frangi æ»¤æ³¢ + Dice Loss
    
    ã€v10-3 æ›´æ–°ã€‘ğŸ¯
    - æ”¹ç”¨ Dice Loss è®¡ç®—è¡€ç®¡ç»“æ„ç›¸ä¼¼æ€§ï¼ˆæ›¿ä»£ MS-SSIMï¼‰
    - è§£å†³ç¨€ç–è¡€ç®¡å›¾çš„èƒŒæ™¯ä¸»å¯¼æ•ˆåº”ï¼ˆ90%é»‘è‰²èƒŒæ™¯æ·¹æ²¡10%è¡€ç®¡ä¿¡å·ï¼‰
    - Diceç³»æ•°ä¸“æ³¨äºè¡€ç®¡åŒºåŸŸçš„é‡å åº¦ï¼š2Ã—|Aâˆ©B| / (|A|+|B|)
    - ä¸å—1-2åƒç´ ä½ç½®åç§»å½±å“ï¼ˆå…³æ³¨æ•´ä½“é‡å è€Œéé€åƒç´ å¯¹é½ï¼‰
    - è®­ç»ƒæ›´ç¨³å®šï¼ŒLossä¿¡å·æ›´æ˜ç¡®ï¼Œæ”¶æ•›æ›´å¿«
    - **ã€æ©ç ç­–ç•¥ä¿®å¤ã€‘** ä½¿ç”¨predå’ŒGTä¸¤ä¸ªFOVæ©ç çš„äº¤é›†ï¼ˆåªåœ¨ä¸¤è€…éƒ½è®¤ä¸ºæœ‰æ•ˆçš„åŒºåŸŸè®¡ç®—lossï¼‰
    
    ã€v10 æ›´æ–°ã€‘âœ¨
    - ä½¿ç”¨ FOV æ©ç  + ä¾µèš€æ–¹æ³•ç§»é™¤è¾¹ç•Œä¼ªå½±
    - ã€æ–°å¢ã€‘å›¾åƒè¾¹ç•Œä¿æŠ¤ï¼šé¢å¤–ç§»é™¤å›¾åƒå¤–å›´åŒºåŸŸï¼Œé˜²æ­¢è´´è¾¹ FOV çš„ä¼ªå½±
    - ä¸æ•°æ®åŠ è½½å™¨çš„é¢„å¤„ç†é€»è¾‘ä¿æŒä¸€è‡´
    
    ã€å¤„ç†é€»è¾‘ã€‘v9 æ›´æ–° - æ”¯æŒ CF_OCT æ•°æ®é›†
    - CF-FA æ•°æ®é›†:
      * CFå›¾: ç»¿è‰²é€šé“ â†’ é»‘è¾¹æ›¿æ¢æˆç™½è‰² â†’ å–åï¼ˆè¡€ç®¡æ˜¯æš—è‰²ï¼‰
      * FAå›¾: ç»¿è‰²é€šé“ + ä¸å–åï¼ˆè¡€ç®¡æ˜¯äº®è‰²ï¼‰
    - CF-OCTA æ•°æ®é›†:
      * CFå›¾: ç»¿è‰²é€šé“ â†’ é»‘è¾¹æ›¿æ¢æˆç™½è‰² â†’ å–åï¼ˆè¡€ç®¡æ˜¯æš—è‰²ï¼‰
      * OCTAå›¾: ç»¿è‰²é€šé“ + ä¸å–åï¼ˆè¡€ç®¡æ˜¯äº®è‰²ï¼‰
    - CF_OCT æ•°æ®é›† (æ–°å¢):
      * CFå›¾: ç»¿è‰²é€šé“ â†’ é»‘è¾¹æ›¿æ¢æˆç™½è‰² â†’ å–åï¼ˆè¡€ç®¡æ˜¯æš—è‰²ï¼‰
      * OCTå›¾: ç»¿è‰²é€šé“ â†’ é»‘è¾¹æ›¿æ¢æˆç™½è‰² â†’ å–åï¼ˆè¡€ç®¡æ˜¯æš—è‰²ï¼‰
    
    æ³¨æ„ï¼šCF/OCTå›¾å–åå‰å…ˆå°†å…¨é»‘åƒç´ ï¼ˆé…å‡†é»‘è¾¹ï¼‰æ›¿æ¢æˆçº¯ç™½ï¼Œ
         é¿å…é»‘è¾¹å–ååå˜ç™½è¢«Frangiè¯¯è®¤ä¸ºè¡€ç®¡
    
    å‚æ•°:
        pred_imgs: é¢„æµ‹å›¾åƒ (B, 3, H, W)ï¼ŒèŒƒå›´ [-1, 1]
        gt_imgs: ç›®æ ‡å›¾åƒ (B, 3, H, W)ï¼ŒèŒƒå›´ [-1, 1]
        mode: è®­ç»ƒæ¨¡å¼ ('cf2fa', 'fa2cf', 'cf2octa', 'octa2cf', 'cf2oct', 'oct2cf')
        sigmas: Frangi å¤šå°ºåº¦å‚æ•°ï¼ˆé»˜è®¤ FRANGI_SIGMASï¼‰
        alpha: Frangi æ¿çŠ¶ç»“æ„æ•æ„Ÿåº¦ï¼ˆé»˜è®¤ FRANGI_ALPHAï¼‰
        beta: Frangi çƒçŠ¶ç»“æ„æ•æ„Ÿåº¦ï¼ˆé»˜è®¤ FRANGI_BETAï¼‰
        gamma_cffa: CF-FAæ¨¡å¼çš„gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFFAï¼‰
        gamma_cfocta_cf: CF-OCTAæ¨¡å¼çš„CFå›¾gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFOCTA_CFï¼‰
        gamma_cfocta_octa: CF-OCTAæ¨¡å¼çš„OCTAå›¾gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFOCTA_OCTAï¼‰
        gamma_cfoct_cf: CF_OCTæ¨¡å¼çš„CFå›¾gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFOCT_CFï¼‰
        gamma_oct: CF_OCTæ¨¡å¼çš„OCTå›¾gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFOCT_OCTï¼‰
        fov_threshold: FOVæ©ç æ£€æµ‹é˜ˆå€¼ï¼ˆé»˜è®¤ 10ï¼‰
        erode_pixels: æ©ç å‘å†…ä¾µèš€åƒç´ æ•°ï¼ˆé»˜è®¤ 10ï¼‰
        image_border_margin: å›¾åƒè¾¹ç•Œé¢å¤–ç§»é™¤åƒç´ æ•°ï¼ˆé»˜è®¤ 5ï¼ŒFAå›¾å»ºè®® 10ï¼‰
        debug_dir: è°ƒè¯•å›¾åƒä¿å­˜ç›®å½•ï¼ˆä»…ç¬¬ä¸€æ­¥ä½¿ç”¨ï¼‰
    
    è¿”å›:
        loss: MS-SSIM æŸå¤±ï¼ˆæ ‡é‡ï¼Œ1 - MS-SSIM å€¼ï¼‰
    """
    # 1. è½¬æ¢åˆ° [0, 1] èŒƒå›´
    pred_01 = (pred_imgs.clamp(-1, 1) + 1) / 2  # (B, 3, H, W)
    gt_01 = (gt_imgs.clamp(-1, 1) + 1) / 2
    
    # 2. åˆ›å»ºæœ‰æ•ˆåƒç´ æ©ç ï¼ˆæ’é™¤é»‘è‰²é…å‡†è¾¹ç¼˜åŒºåŸŸï¼‰
    threshold = 0.01
    black_mask_pred = (pred_01 <= threshold).all(dim=1, keepdim=True)  # (B,1,H,W)
    black_mask_gt = (gt_01 <= threshold).all(dim=1, keepdim=True)
    valid_mask = ~(black_mask_pred | black_mask_gt)  # (B,1,H,W)
    
    # 3. ã€v10-2 é‡æ„ã€‘è°ƒç”¨ data_loader_all ä¸­çš„ç»Ÿä¸€è¡€ç®¡æå–å‡½æ•°
    # é¢„æµ‹å›¾çš„è¡€ç®¡æå–ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
    pred_vessel, fov_mask_batch = extract_vessel_map_torch(
        pred_01, mode,
        gamma_cffa=gamma_cffa,
        gamma_cfocta_cf=gamma_cfocta_cf,
        gamma_cfocta_octa=gamma_cfocta_octa,
        gamma_cfoct_cf=gamma_cfoct_cf,
        gamma_oct=gamma_oct,
        sigmas=sigmas,
        alpha=alpha,
        beta=beta,
        fov_threshold=fov_threshold,
        erode_pixels=erode_pixels,
        image_border_margin=image_border_margin,
        apply_fov_mask=True
    )
    
    # GT å›¾çš„è¡€ç®¡æå–ï¼ˆä¸éœ€è¦æ¢¯åº¦ï¼‰
    with torch.no_grad():
        gt_vessel, gt_fov_mask_batch = extract_vessel_map_torch(
            gt_01, mode,
            gamma_cffa=gamma_cffa,
            gamma_cfocta_cf=gamma_cfocta_cf,
            gamma_cfocta_octa=gamma_cfocta_octa,
            gamma_cfoct_cf=gamma_cfoct_cf,
            gamma_oct=gamma_oct,
            sigmas=sigmas,
            alpha=alpha,
            beta=beta,
            fov_threshold=fov_threshold,
            erode_pixels=erode_pixels,
            image_border_margin=image_border_margin,
            apply_fov_mask=True
        )
    
    # 4. ã€v10-3 æ”¹è¿›ã€‘è®¡ç®— Dice Lossï¼ˆä¸“ä¸ºç¨€ç–è¡€ç®¡å›¾è®¾è®¡ï¼‰
    # ç»“åˆ FOV æ©ç å’Œé…å‡†é»‘è¾¹æ©ç 
    # å–predå’ŒGTä¸¤ä¸ªFOVæ©ç çš„äº¤é›†ï¼ˆåªåœ¨ä¸¤è€…éƒ½è®¤ä¸ºæœ‰æ•ˆçš„åŒºåŸŸè®¡ç®—lossï¼‰
    combined_mask = valid_mask * fov_mask_batch * gt_fov_mask_batch  # (B, 1, H, W)
    
    # 5. ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆä»…ç¬¬ä¸€æ­¥ï¼‰
    if debug_dir is not None:
        os.makedirs(debug_dir, exist_ok=True)
        # ä¿å­˜åŸå§‹è¾“å…¥å›¾åƒï¼ˆéœ€è¦ detach æ–­å¼€æ¢¯åº¦ï¼‰
        pred_save = (pred_01[0].detach().cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
        gt_save = (gt_01[0].detach().cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(pred_save).save(os.path.join(debug_dir, "vessel_loss_pred_input.png"))
        Image.fromarray(gt_save).save(os.path.join(debug_dir, "vessel_loss_gt_input.png"))
        
        # ä¿å­˜ Frangi æ»¤æ³¢ç»“æœï¼ˆéœ€è¦ detach æ–­å¼€æ¢¯åº¦ï¼‰
        pred_vessel_save = (pred_vessel[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        gt_vessel_save = (gt_vessel[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(pred_vessel_save).save(os.path.join(debug_dir, "vessel_loss_pred_frangi.png"))
        Image.fromarray(gt_vessel_save).save(os.path.join(debug_dir, "vessel_loss_gt_frangi.png"))
        
        # ã€v10 æ–°å¢ã€‘ä¿å­˜ FOV æ©ç 
        pred_fov_mask_save = (fov_mask_batch[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        gt_fov_mask_save = (gt_fov_mask_batch[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(pred_fov_mask_save).save(os.path.join(debug_dir, "vessel_loss_pred_fov_mask.png"))
        Image.fromarray(gt_fov_mask_save).save(os.path.join(debug_dir, "vessel_loss_gt_fov_mask.png"))
        
        # ä¿å­˜ç»„åˆæ©ç ï¼ˆäº¤é›†ï¼‰
        combined_mask_save = (combined_mask[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(combined_mask_save).save(os.path.join(debug_dir, "vessel_loss_combined_mask.png"))
        
        print(f"\nâœ“ Vessel Loss è°ƒè¯•å›¾åƒå·²ä¿å­˜åˆ°: {debug_dir}")
        print(f"  - vessel_loss_pred_input.png: é¢„æµ‹å›¾åŸå§‹è¾“å…¥")
        print(f"  - vessel_loss_gt_input.png: GTå›¾åŸå§‹è¾“å…¥")
        print(f"  - vessel_loss_pred_frangi.png: é¢„æµ‹å›¾Frangiå“åº”ï¼ˆå·²åº”ç”¨FOVæ©ç ï¼‰")
        print(f"  - vessel_loss_gt_frangi.png: GTå›¾Frangiå“åº”ï¼ˆå·²åº”ç”¨FOVæ©ç ï¼‰")
        print(f"  - vessel_loss_pred_fov_mask.png: é¢„æµ‹å›¾FOVä¾µèš€æ©ç ï¼ˆerode={erode_pixels}pxï¼‰")
        print(f"  - vessel_loss_gt_fov_mask.png: GTå›¾FOVä¾µèš€æ©ç ï¼ˆerode={erode_pixels}pxï¼‰")
        print(f"  - vessel_loss_combined_mask.png: ç»„åˆæ©ç ï¼ˆpredâˆ©gtâˆ©validçš„äº¤é›†ï¼‰\n")
    
    # 6. åº”ç”¨æ©ç åˆ°è¡€ç®¡å›¾ï¼ˆåªåœ¨æœ‰æ•ˆåŒºåŸŸå†…è®¡ç®—ï¼‰
    pred_vessel_masked = pred_vessel * combined_mask.float()  # (B, 1, H, W)
    gt_vessel_masked = gt_vessel * combined_mask.float()      # (B, 1, H, W)
    
    # 7. è®¡ç®— Dice Loss
    # Dice ç³»æ•° = 2 Ã— |A âˆ© B| / (|A| + |B|)
    smooth = 1e-5  # å¹³æ»‘é¡¹ï¼Œé¿å…é™¤é›¶
    
    # äº¤é›†ï¼šé¢„æµ‹è¡€ç®¡ä¸GTè¡€ç®¡çš„é‡å åŒºåŸŸ
    intersection = (pred_vessel_masked * gt_vessel_masked).sum()
    
    # å¹¶é›†ï¼šé¢„æµ‹è¡€ç®¡ + GTè¡€ç®¡çš„æ€»å’Œ
    pred_sum = pred_vessel_masked.sum()
    gt_sum = gt_vessel_masked.sum()
    
    # Dice ç³»æ•°ï¼ˆèŒƒå›´ [0, 1]ï¼Œ1è¡¨ç¤ºå®Œå…¨é‡å ï¼‰
    dice_coeff = (2.0 * intersection + smooth) / (pred_sum + gt_sum + smooth)
    
    # Dice Loss = 1 - Diceç³»æ•°ï¼ˆèŒƒå›´ [0, 1]ï¼Œ0è¡¨ç¤ºå®Œç¾ï¼‰
    loss = 1.0 - dice_coeff
    
    return loss


def get_dynamic_learning_rate(global_step, max_steps, base_lr=5e-5, min_lr=1e-5):
    """
    å­¦ä¹ ç‡å¹³æ»‘è¡°å‡ï¼ˆCosine Annealingï¼‰
    
    step < 4000: lr = 5e-5
    step >= 4000: Cosine è¡°å‡ 5e-5 â†’ 1e-5
    
    è¿”å›: å½“å‰å­¦ä¹ ç‡
    """
    if global_step < 4000:
        return base_lr
    else:
        # Cosine è¡°å‡
        progress = min((global_step - 4000) / (max_steps - 4000), 1.0)
        lr = min_lr + (base_lr - min_lr) * (1 + math.cos(progress * math.pi)) / 2
        return lr


def compute_total_loss(noise_pred, noise, noisy_latents, latents, timesteps, 
                       args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                       return_components=False, vessel_debug_dir=None):
    """
    è®¡ç®—æ€»æŸå¤±ï¼ˆè®­ç»ƒå’ŒéªŒè¯å…±ç”¨ï¼‰
    
    ã€v10-2 æ–°å¢ã€‘å°è£…æŸå¤±è®¡ç®—é€»è¾‘ï¼Œç¡®ä¿è®­ç»ƒå’ŒéªŒè¯ä½¿ç”¨å®Œå…¨ç›¸åŒçš„è®¡ç®—æ–¹å¼
    
    å‚æ•°:
        noise_pred: UNet é¢„æµ‹çš„å™ªå£° (B, 4, H/8, W/8)
        noise: çœŸå®å™ªå£° (B, 4, H/8, W/8)
        noisy_latents: åŠ å™ªåçš„ latents (B, 4, H/8, W/8)
        latents: åŸå§‹ latents (B, 4, H/8, W/8)
        timesteps: æ—¶é—´æ­¥ (B,)
        args: å‘½ä»¤è¡Œå‚æ•°ï¼ˆåŒ…å«å„æŸå¤±æƒé‡ï¼‰
        noise_scheduler: DDPM è°ƒåº¦å™¨
        vae_sf: VAE ç¼©æ”¾å› å­
        msssim_loss_fn: MS-SSIM æŸå¤±å‡½æ•°
        device: è®¾å¤‡
        return_components: æ˜¯å¦è¿”å›å„æŸå¤±åˆ†é‡ï¼ˆé»˜è®¤Falseï¼Œåªè¿”å›æ€»æŸå¤±ï¼‰
        vessel_debug_dir: Vessel Loss è°ƒè¯•å›¾åƒä¿å­˜ç›®å½•ï¼ˆé»˜è®¤Noneï¼Œä¸ä¿å­˜ï¼‰
    
    è¿”å›:
        å¦‚æœ return_components=False: total_loss (æ ‡é‡)
        å¦‚æœ return_components=True: (total_loss, loss_mse, loss_msssim, loss_vessel, loss_grad)
    """
    # ============ 1. MSE æŸå¤±ï¼ˆå™ªå£°ç©ºé—´ï¼Œåº”ç”¨è’™ç‰ˆï¼‰============
    with torch.no_grad():
        # è§£ç GTå›¾åƒåˆ°åƒç´ ç©ºé—´ï¼ˆä»…ç”¨äºæ£€æµ‹é»‘è¾¹ï¼‰
        tgt_imgs_for_mask = vae.decode(latents / vae_sf).sample
        tgt_imgs_0_1 = (tgt_imgs_for_mask.clamp(-1, 1) + 1) / 2
        
        # æ£€æµ‹é»‘è¾¹ï¼šGTçš„é»‘è‰²åƒç´ ï¼ˆé…å‡†è¾¹ç¼˜ï¼‰
        threshold = 0.01
        black_mask_pixel = torch.all(tgt_imgs_0_1 <= threshold, dim=1, keepdim=True)  # (B, 1, H, W)
        valid_mask_pixel = ~black_mask_pixel  # (B, 1, H, W)
        
        # å°†åƒç´ ç©ºé—´è’™ç‰ˆ downsample åˆ° latent ç©ºé—´
        valid_mask_latent = F.interpolate(
            valid_mask_pixel.float(), 
            size=(latents.shape[2], latents.shape[3]),
            mode='nearest'
        )  # (B, 1, H/8, W/8)
        
        # æ‰©å±•åˆ°latentçš„é€šé“æ•°ï¼ˆé€šå¸¸æ˜¯4ï¼‰
        valid_mask_latent = valid_mask_latent.expand(-1, latents.shape[1], -1, -1)  # (B, 4, H/8, W/8)
    
    # åœ¨å™ªå£°ç©ºé—´è®¡ç®—MSEï¼ˆä¿æŒæ‰©æ•£æ¨¡å‹æ ‡å‡†è®­ç»ƒèŒƒå¼ï¼‰
    noise_diff = (noise_pred - noise) ** 2  # (B, 4, H/8, W/8)
    loss_mse = (noise_diff * valid_mask_latent).sum() / (valid_mask_latent.sum() + 1e-10)
    
    # ============ 2. åƒç´ ç©ºé—´æŸå¤±ï¼ˆMS-SSIMã€Vesselã€Gradientï¼‰============
    with torch.no_grad():
        # scheduler.alphas_cumprod is on CPU, need to move to device
        alphas_cumprod = noise_scheduler.alphas_cumprod.to(device)
        alphas_cumprod_t = alphas_cumprod[timesteps].view(-1, 1, 1, 1)
    
    # ä»å™ªå£°é¢„æµ‹ä¸­æ¢å¤ x0 (åŸå§‹å›¾åƒçš„ latent)
    pred_x0_latents = (noisy_latents - (1 - alphas_cumprod_t).sqrt() * noise_pred) / alphas_cumprod_t.sqrt()
    
    # VAE è§£ç åˆ°åƒç´ ç©ºé—´
    with torch.no_grad():
        tgt_imgs = vae.decode(latents / vae_sf).sample  # GTå›¾ï¼ˆä¸éœ€è¦æ¢¯åº¦ï¼‰
    pred_imgs = vae.decode(pred_x0_latents / vae_sf).sample  # é¢„æµ‹å›¾ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
    
    # è½¬æ¢åˆ° [0, 1] èŒƒå›´
    tgt_imgs_0_1 = (tgt_imgs.clamp(-1, 1) + 1) / 2
    pred_imgs_0_1 = (pred_imgs.clamp(-1, 1) + 1) / 2
    
    # åˆ›å»ºåƒç´ ç©ºé—´è’™ç‰ˆï¼ˆç”¨äºSSIMã€Vesselã€Gradientï¼‰
    threshold = 0.01
    black_mask_tgt = torch.all(tgt_imgs_0_1 <= threshold, dim=1, keepdim=True)
    black_mask_pred = torch.all(pred_imgs_0_1 <= threshold, dim=1, keepdim=True)
    valid_mask_pixel_3ch = ~(black_mask_tgt | black_mask_pred)  # (B, 1, H, W)
    valid_mask_pixel_3ch = valid_mask_pixel_3ch.expand(-1, 3, -1, -1).float()  # (B, 3, H, W)
    
    # 3. MS-SSIM æŸå¤±ï¼ˆåƒç´ ç©ºé—´åº”ç”¨è’™ç‰ˆï¼‰
    if args.msssim_lambda > 0:
        # å°†é»‘è¾¹åŒºåŸŸåœ¨ä¸¤å¼ å›¾ä¸Šéƒ½ç½®é›¶ï¼ˆ[0, 1] èŒƒå›´ï¼‰
        tgt_imgs_0_1_masked = tgt_imgs_0_1 * valid_mask_pixel_3ch
        pred_imgs_0_1_masked = pred_imgs_0_1 * valid_mask_pixel_3ch
        
        # è®¡ç®— MS-SSIM æŸå¤±
        loss_msssim = 1 - msssim_loss_fn(pred_imgs_0_1_masked, tgt_imgs_0_1_masked)
    else:
        loss_msssim = torch.tensor(0.0, device=device)
    
    # 4. Vessel æŸå¤±ï¼ˆFrangi + L1 + FOVæ©ç  + å›¾åƒè¾¹ç•Œä¿æŠ¤ï¼‰
    tgt_params = get_image_params(args.mode, param_type='target')
    
    loss_vessel = compute_vessel_loss_frangi(
        pred_imgs, tgt_imgs, 
        mode=args.mode,
        sigmas=FRANGI_SIGMAS,
        alpha=FRANGI_ALPHA, 
        beta=FRANGI_BETA, 
        gamma_cffa=GAMMA_CFFA,
        gamma_cfocta_cf=GAMMA_CFOCTA_CF,
        gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
        gamma_cfoct_cf=GAMMA_CFOCT_CF,
        gamma_oct=GAMMA_CFOCT_OCT,
        fov_threshold=tgt_params['fov_threshold'],
        erode_pixels=tgt_params['erode_pixels'],
        image_border_margin=tgt_params['image_border_margin'],
        debug_dir=vessel_debug_dir  # ä½¿ç”¨ä¼ å…¥çš„è°ƒè¯•ç›®å½•å‚æ•°
    )
    
    # 5. æ¢¯åº¦åŒ¹é…æŸå¤±
    grad_mask = valid_mask_pixel_3ch[:, :1, :, :]
    loss_grad = compute_gradient_match_loss(
        pred_imgs_0_1,
        tgt_imgs_0_1,
        mask=grad_mask,
        reduction='l1'
    )
    
    # 6. ç»„åˆæ€»æŸå¤±
    total_loss = (loss_mse + 
                  args.msssim_lambda * loss_msssim + 
                  args.vessel_lambda * loss_vessel +
                  args.grad_lambda * loss_grad)
    
    if return_components:
        return total_loss, loss_mse, loss_msssim, loss_vessel, loss_grad
    else:
        return total_loss


def run_inference_test(row_data, step_dir, step_num, mode, fixed_seed=42):
    """
    è¿è¡Œæ¨ç†æµ‹è¯•ï¼ˆæ¯500æ­¥ï¼‰- Dual ControlNet ç‰ˆæœ¬ v9 (Scribble + Tile)
    æ”¯æŒ CF-OCTAã€CF-FA å’Œ CF_OCT ä¸‰ç§æ•°æ®é›†
    
    å‚æ•°:
        row_data: CSV è¡Œæ•°æ®å­—å…¸
        step_dir: checkpoint ä¿å­˜ç›®å½•
        step_num: å½“å‰æ­¥æ•°
        mode: è®­ç»ƒæ¨¡å¼ (cf2octa/octa2cf/cf2fa/fa2cf/cf2oct/oct2cf)
        fixed_seed: å›ºå®šçš„éšæœºç§å­
    """
    print(f"\n{'='*70}")
    print(f"è¿è¡Œæ¨ç†æµ‹è¯• (step {step_num}) - Dual ControlNet (Scribble+Tile) [{mode}]")
    print(f"{'='*70}")
    
    # åˆ›å»ºæ¨ç†æµ‹è¯•ç›®å½•
    infer_dir = os.path.join(step_dir, "inference_test")
    os.makedirs(infer_dir, exist_ok=True)
    
    # åˆ¤æ–­æ•°æ®é›†ç±»å‹
    is_cffa = mode in ["cf2fa", "fa2cf"]
    is_cfoct = mode in ["cf2oct", "oct2cf"]
    
    # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©è·¯å¾„
    if is_cffa:
        # CF-FA æ•°æ®é›†
        cf_path = row_data.get("cf_path")
        fa_path = row_data.get("fa_path")
        
        if mode == "cf2fa":
            src_path = cf_path
            target_path = fa_path
        else:  # fa2cf
            src_path = fa_path
            target_path = cf_path
    elif is_cfoct:
        # CF_OCT æ•°æ®é›†
        cf_path = row_data.get("cf_path")
        oct_path = row_data.get("oct_path")
        
        if mode == "cf2oct":
            src_path = cf_path
            target_path = oct_path
        else:  # oct2cf
            src_path = oct_path
            target_path = cf_path
    else:
        # CF-OCTA æ•°æ®é›†
        cf = row_data.get("cf_path")
        octa = row_data.get("octa_path")
        cond = row_data.get("cond_path")
        tgt = row_data.get("target_path")
        affine_cf_to_octa = row_data.get("affine_cf_to_octa_path", "")
        affine_octa_to_cf = row_data.get("affine_octa_to_cf_path", "")
        
        if mode == "cf2octa":
            src_path = cf or cond
            target_path = octa or tgt
            affine_path = affine_octa_to_cf
        else:  # octa2cf
            src_path = octa or cond
            # éœ€è¦å¯¼å…¥ _strip_seg_prefix_in_path
            from data_loader_cfocta import _strip_seg_prefix_in_path
            target_path = cf or _strip_seg_prefix_in_path(cond or tgt) if (cf or cond or tgt) else None
            affine_path = affine_cf_to_octa
    
    if not src_path or not target_path:
        print("  âš  è·³è¿‡æ¨ç†æµ‹è¯•ï¼šè·¯å¾„ä¸å®Œæ•´")
        return
    
    print(f"  æºå›¾è·¯å¾„: {src_path}")
    print(f"  ç›®æ ‡å›¾è·¯å¾„: {target_path}")
    print(f"  æ¨¡å¼: {mode}")
    dataset_type = 'CF-FA' if is_cffa else ('CF_OCT' if is_cfoct else 'CF-OCTA')
    print(f"  æ•°æ®é›†ç±»å‹: {dataset_type}")
    
    # 1. åŠ è½½åŸå§‹å›¾åƒï¼ˆä¸ resizeï¼Œä¿æŒåŸå§‹åˆ†è¾¨ç‡ï¼‰
    src_img_original = Image.open(src_path).convert("RGB")
    
    # ä¿å­˜åŸå§‹å›¾åƒå°ºå¯¸ï¼ˆç”¨äº CF-FA æ¨¡å¼ resize å›åŸå°ºå¯¸ï¼‰
    original_size = src_img_original.size  # (width, height)
    
    # 2. ã€v10 é‡æ„ã€‘ä½¿ç”¨ç»Ÿä¸€çš„é¢„å¤„ç†æ¥å£
    # è‡ªåŠ¨è¯†åˆ«æ•°æ®é›†ç±»å‹
    if is_cffa:
        dataset_type = 'CFFA'
    elif is_cfoct:
        dataset_type = 'CFOCT'
    else:
        dataset_type = 'CFOCTA'
    
    # ã€v10 æ”¹è¿›ã€‘ä¸€è¡Œä»£ç å®Œæˆæ‰€æœ‰é¢„å¤„ç†ï¼Œæ‰€æœ‰å‚æ•°è‡ªåŠ¨ä»é…ç½®è·å–ï¼
    cond_scribble_pil, cond_tile_pil = preprocess_for_vessel_extraction(
        src_img_original,
        mode=mode,
        dataset_type=dataset_type
    )
    
    # 4. ä¿å­˜é¢„å¤„ç†ç»“æœ
    idx = os.path.splitext(os.path.basename(src_path))[0]
    
    # ç¡®å®šScribbleæƒé‡
    scribble_scale = args.scribble_scale
    
    if is_cffa:
        # CF-FA æ¨¡å¼ï¼šä¿å­˜è°ƒè¯•å›¾åƒ
        # 1. åŸå°ºå¯¸åŸå›¾ï¼ˆ720Ã—576ï¼‰
        src_img_original.save(os.path.join(infer_dir, f"{idx}_00_input_original_{original_size[0]}x{original_size[1]}.png"))
        # 2. 512Ã—512 Scribbleè¡€ç®¡å›¾
        cond_scribble_pil.save(os.path.join(infer_dir, f"{idx}_01_scribble_vessel_512x512.png"))
        # 3. 512Ã—512 åŸå›¾ï¼ˆTileè¾“å…¥ï¼‰
        cond_tile_pil.save(os.path.join(infer_dir, f"{idx}_02_tile_512x512.png"))
    elif is_cfoct:
        # CF_OCT æ¨¡å¼ï¼šä¿å­˜è°ƒè¯•å›¾åƒ
        src_img_original.save(os.path.join(infer_dir, f"{idx}_input_original.png"))
        cond_scribble_pil.save(os.path.join(infer_dir, f"{idx}_condition_vessel.png"))
        cond_tile_pil.save(os.path.join(infer_dir, f"{idx}_condition_tile.png"))
    else:
        # CF-OCTA æ¨¡å¼ï¼šç»Ÿä¸€ä¿å­˜è¡€ç®¡å›¾å’ŒåŸå›¾
        src_img_original.save(os.path.join(infer_dir, f"{idx}_input_original.png"))
        cond_scribble_pil.save(os.path.join(infer_dir, f"{idx}_condition_vessel.png"))
        cond_tile_pil.save(os.path.join(infer_dir, f"{idx}_condition_tile.png"))
    
    # 5. æ„å»ºæ¨ç† pipelineï¼ˆDual ControlNet: Scribble + Tileï¼‰
    controlnet_scribble.eval()
    controlnet_tile.eval()
    
    from diffusers import MultiControlNetModel
    multi_controlnet = MultiControlNetModel([controlnet_scribble, controlnet_tile])
    
    pipe = StableDiffusionControlNetPipeline(
        vae=vae,
        text_encoder=text_encoder,
        tokenizer=tokenizer,
        unet=unet,
        controlnet=multi_controlnet,
        scheduler=noise_scheduler,
        safety_checker=None,
        feature_extractor=None
    )
    
    # 6. è¿è¡Œæ¨ç†ï¼ˆä½¿ç”¨å›ºå®šç§å­ï¼‰
    generator = torch.Generator(device=device).manual_seed(fixed_seed)
    
    with torch.no_grad():
        output = pipe(
            prompt="",
            negative_prompt=None,
            image=[cond_scribble_pil, cond_tile_pil],  # [Scribble, Tile] æ¡ä»¶å›¾
            num_inference_steps=30,
            guidance_scale=7.5,
            controlnet_conditioning_scale=[scribble_scale, args.tile_scale],  # [Scribbleæƒé‡, Tileæƒé‡]
            generator=generator
        )
    
    # 6. ä¿å­˜é¢„æµ‹ç»“æœ
    pred_img = output.images[0]
    
    if is_cffa:
        # CF-FA æ¨¡å¼ï¼šä¿å­˜ 512Ã—512 å’Œ resize å›åŸå°ºå¯¸çš„ç»“æœ
        # 3. 512Ã—512 æ¨ç†ç»“æœ
        pred_img.save(os.path.join(infer_dir, f"{idx}_02_pred_512x512_step{step_num}.png"))
        
        # 4. Resize å›åŸå°ºå¯¸çš„æ¨ç†ç»“æœï¼ˆ720Ã—576ï¼‰
        pred_img_resized = pred_img.resize(original_size)  # resize å›åŸå°ºå¯¸
        pred_img_resized.save(os.path.join(infer_dir, f"{idx}_03_pred_{original_size[0]}x{original_size[1]}_step{step_num}.png"))
    elif is_cfoct:
        # CF_OCT æ¨¡å¼ï¼šä¿å­˜é¢„æµ‹ç»“æœ
        suffix = "pred_oct" if mode == "cf2oct" else "pred_cf"
        pred_img.save(os.path.join(infer_dir, f"{idx}_{suffix}_step{step_num}.png"))
    else:
        # CF-OCTA æ¨¡å¼ï¼šä¿æŒåŸæœ‰é€»è¾‘
        suffix = "pred_octa" if mode == "cf2octa" else "pred_cf"
        pred_img.save(os.path.join(infer_dir, f"{idx}_{suffix}_step{step_num}.png"))
    
    # ã€æ–°å¢ã€‘ä¿å­˜é¢„æµ‹å›¾çš„è¡€ç®¡æå–ç»“æœï¼ˆç”¨äºè°ƒè¯• Vessel Lossï¼‰
    # å°†é¢„æµ‹å›¾è½¬æ¢ä¸ºtorch tensorå¹¶æå–è¡€ç®¡
    pred_img_np = np.array(pred_img).astype(np.float32) / 255.0
    pred_img_torch = torch.from_numpy(pred_img_np).permute(2, 0, 1).unsqueeze(0).to(device)  # (1, 3, H, W)
    
    # æå–é¢„æµ‹å›¾çš„è¡€ç®¡ï¼ˆè°ƒç”¨ data_loader_all ä¸­çš„ç»Ÿä¸€å‡½æ•°ï¼‰
    tgt_params = get_image_params(mode, param_type='target')
    pred_vessel_map, _ = extract_vessel_map_torch(
        pred_img_torch, mode, 
        gamma_cffa=GAMMA_CFFA,
        gamma_cfocta_cf=GAMMA_CFOCTA_CF,
        gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
        gamma_cfoct_cf=GAMMA_CFOCT_CF,
        gamma_oct=GAMMA_CFOCT_OCT,
        sigmas=FRANGI_SIGMAS,
        alpha=FRANGI_ALPHA,
        beta=FRANGI_BETA,
        fov_threshold=tgt_params['fov_threshold'],
        erode_pixels=tgt_params['erode_pixels'],
        image_border_margin=tgt_params['image_border_margin'],
        apply_fov_mask=True
    )
    
    # ä¿å­˜é¢„æµ‹å›¾çš„è¡€ç®¡å›¾
    pred_vessel_save = (pred_vessel_map[0,0].cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
    Image.fromarray(pred_vessel_save).save(os.path.join(infer_dir, f"{idx}_pred_vessel_step{step_num}.png"))
    
    # 7. åŠ è½½å¹¶å¤„ç†ç›®æ ‡å›¾ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    if is_cffa:
        # CF-FA æ¨¡å¼ï¼šç”Ÿæˆé…å‡†åçš„åŸå°ºå¯¸ç›®æ ‡å›¾
        try:
            target_img_original = Image.open(target_path).convert("RGB")
            
            # åŠ è½½å…³é”®ç‚¹å¹¶è®¡ç®—ä»¿å°„çŸ©é˜µ
            cf_pts_path = row_data.get("cf_pts_path")
            fa_pts_path = row_data.get("fa_pts_path")
            
            if cf_pts_path and fa_pts_path and os.path.exists(cf_pts_path) and os.path.exists(fa_pts_path):
                from registration_cf_fa import load_keypoints, compute_affine_from_points, apply_affine_cffa
                
                # åŠ è½½é…å¯¹ç‚¹
                if mode == "cf2fa":
                    # CFâ†’FA: å°† FA é…å‡†åˆ° CF ç©ºé—´
                    cond_points = load_keypoints(cf_pts_path)
                    tgt_points = load_keypoints(fa_pts_path)
                    affine_matrix = compute_affine_from_points(tgt_points, cond_points)
                else:  # fa2cf
                    # FAâ†’CF: å°† CF é…å‡†åˆ° FA ç©ºé—´
                    cond_points = load_keypoints(fa_pts_path)
                    tgt_points = load_keypoints(cf_pts_path)
                    affine_matrix = compute_affine_from_points(tgt_points, cond_points)
                
                # åœ¨åŸå°ºå¯¸ä¸Šåº”ç”¨é…å‡†ï¼ˆä¸resizeï¼‰
                target_np = np.array(target_img_original)
                h, w = target_np.shape[:2]
                registered_np = cv2.warpAffine(
                    target_np, affine_matrix, (w, h),
                    flags=cv2.INTER_LINEAR,
                    borderMode=cv2.BORDER_CONSTANT,
                    borderValue=(0, 0, 0)
                )
                target_img_registered = Image.fromarray(registered_np)
                
                # 5. ä¿å­˜é…å‡†åçš„åŸå°ºå¯¸ç›®æ ‡å›¾
                target_img_registered.save(os.path.join(infer_dir, f"{idx}_04_target_registered_{original_size[0]}x{original_size[1]}.png"))
                
                # ã€æ–°å¢ã€‘æå–å¹¶ä¿å­˜ç›®æ ‡å›¾çš„è¡€ç®¡
                # Resize åˆ° 512Ã—512 ç”¨äºè¡€ç®¡æå–ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
                target_img_512 = target_img_registered.resize((SIZE, SIZE))
                target_img_np = np.array(target_img_512).astype(np.float32) / 255.0
                target_img_torch = torch.from_numpy(target_img_np).permute(2, 0, 1).unsqueeze(0).to(device)
                
                target_vessel_map, _ = extract_vessel_map_torch(
                    target_img_torch, mode,
                    gamma_cffa=GAMMA_CFFA,
                    gamma_cfocta_cf=GAMMA_CFOCTA_CF,
                    gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                    gamma_cfoct_cf=GAMMA_CFOCT_CF,
                    gamma_oct=GAMMA_CFOCT_OCT,
                    sigmas=FRANGI_SIGMAS,
                    alpha=FRANGI_ALPHA,
                    beta=FRANGI_BETA,
                    fov_threshold=tgt_params['fov_threshold'],
                    erode_pixels=tgt_params['erode_pixels'],
                    image_border_margin=tgt_params['image_border_margin'],
                    apply_fov_mask=True
                )
                
                target_vessel_save = (target_vessel_map[0,0].cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(target_vessel_save).save(os.path.join(infer_dir, f"{idx}_target_vessel_step{step_num}.png"))
                
            else:
                print(f"  âš  å…³é”®ç‚¹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ç›®æ ‡å›¾é…å‡†")
                
        except Exception as e:
            print(f"  âš  CF-FA ç›®æ ‡å›¾é…å‡†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    elif is_cfoct:
        # CF_OCT æ¨¡å¼ï¼šã€v13 æ”¹è¿›ã€‘å¤ç”¨ data_loader çš„é…å‡†é€»è¾‘ï¼Œä¿æŒä¸€è‡´æ€§
        try:
            target_img_original = Image.open(target_path).convert("RGB")
            
            # ã€å…³é”®ã€‘ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„é…å‡†é€»è¾‘
            # æ¨¡æ‹Ÿ data_loader çš„è¡Œä¸ºï¼šåˆ›å»ºä¸´æ—¶ row æ•°æ®
            temp_row = {
                'cf_path': row_data.get('cf_path'),
                'oct_path': row_data.get('oct_path'),
                'cf_pts_path': row_data.get('cf_pts_path'),
                'oct_pts_path': row_data.get('oct_pts_path')
            }
            
            # ä» data_loader_all_v13 å¯¼å…¥é…å‡†é€»è¾‘
            from data_loader_all_v13 import UnifiedDataset
            
            # åˆ›å»ºä¸´æ—¶ dataset å®ä¾‹ä»¥å¤ç”¨é…å‡†æ–¹æ³•
            temp_ds = UnifiedDataset.__new__(UnifiedDataset)
            temp_ds.mode = mode
            
            # è°ƒç”¨ç»Ÿä¸€çš„é…å‡†æ–¹æ³•
            src_img_original = Image.open(src_path).convert("RGB")
            _, target_registered_pil = temp_ds._apply_registration_cfoct(
                src_img_original, 
                target_img_original,
                (temp_row['cf_pts_path'], temp_row['oct_pts_path'])
            )
            
            # ä¿å­˜é…å‡†åçš„å›¾åƒ
            target_registered_pil.save(os.path.join(infer_dir, f"{idx}_target_registered.png"))
            target_img_original.save(os.path.join(infer_dir, f"{idx}_target_original.png"))
            
            # ã€æ–°å¢ã€‘æå–å¹¶ä¿å­˜ç›®æ ‡å›¾çš„è¡€ç®¡
            target_img_np = np.array(target_registered_pil).astype(np.float32) / 255.0
            target_img_torch = torch.from_numpy(target_img_np).permute(2, 0, 1).unsqueeze(0).to(device)
            
            target_vessel_map, _ = extract_vessel_map_torch(
                target_img_torch, mode,
                gamma_cffa=GAMMA_CFFA,
                gamma_cfocta_cf=GAMMA_CFOCTA_CF,
                gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                gamma_cfoct_cf=GAMMA_CFOCT_CF,
                gamma_oct=GAMMA_CFOCT_OCT,
                sigmas=FRANGI_SIGMAS,
                alpha=FRANGI_ALPHA,
                beta=FRANGI_BETA,
                fov_threshold=tgt_params['fov_threshold'],
                erode_pixels=tgt_params['erode_pixels'],
                image_border_margin=tgt_params['image_border_margin'],
                apply_fov_mask=True
            )
            
            target_vessel_save = (target_vessel_map[0,0].cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
            Image.fromarray(target_vessel_save).save(os.path.join(infer_dir, f"{idx}_target_vessel_step{step_num}.png"))
                
        except Exception as e:
            print(f"  âš  CF_OCT ç›®æ ‡å›¾é…å‡†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    else:
        # CF-OCTA æ¨¡å¼ï¼ˆv8-3-2ï¼‰ï¼šç›®æ ‡å›¾ç›´æ¥ä½¿ç”¨åŸå›¾ï¼Œä¸åšé¢„å¤„ç†
        try:
            target_img_original = Image.open(target_path).convert("RGB")
            
            # v8-3-2: CFè®­ç»ƒé›†å·²æ”¹ä¸ºå½©è‰²åŸå›¾ï¼Œç›®æ ‡å›¾ä¸éœ€è¦é¢„å¤„ç†
            # cf2octa: ç›®æ ‡æ˜¯OCTAï¼Œç›´æ¥ä½¿ç”¨åŸå›¾
            # octa2cf: ç›®æ ‡æ˜¯CFï¼Œç›´æ¥ä½¿ç”¨å½©è‰²åŸå›¾ï¼ˆä¸åšç»¿è‰²é€šé“+å–åï¼‰
            target_img_preprocessed = target_img_original
            
            # åº”ç”¨é…å‡†å˜æ¢
            if affine_path and os.path.exists(affine_path):
                affine_matrix = load_affine_matrix(affine_path)
                
                # ç›´æ¥åœ¨å½“å‰å°ºå¯¸ä¸Šåº”ç”¨é…å‡†
                target_np = np.array(target_img_preprocessed)
                registered_np = apply_affine_registration(target_np, affine_matrix)
                target_img_registered = Image.fromarray(registered_np)
            else:
                target_img_registered = target_img_preprocessed
            
            # Resizeåˆ°512Ã—512å¹¶ä¿å­˜
            target_img_512 = target_img_registered.resize((SIZE, SIZE))
            target_img_512.save(os.path.join(infer_dir, f"{idx}_target_registered.png"))
            target_img_original.save(os.path.join(infer_dir, f"{idx}_target_original.png"))
            
            # ã€æ–°å¢ã€‘æå–å¹¶ä¿å­˜ç›®æ ‡å›¾çš„è¡€ç®¡
            target_img_np = np.array(target_img_512).astype(np.float32) / 255.0
            target_img_torch = torch.from_numpy(target_img_np).permute(2, 0, 1).unsqueeze(0).to(device)
            
            target_vessel_map, _ = extract_vessel_map_torch(
                target_img_torch, mode,
                gamma_cffa=GAMMA_CFFA,
                gamma_cfocta_cf=GAMMA_CFOCTA_CF,
                gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                gamma_cfoct_cf=GAMMA_CFOCT_CF,
                gamma_oct=GAMMA_CFOCT_OCT,
                sigmas=FRANGI_SIGMAS,
                alpha=FRANGI_ALPHA,
                beta=FRANGI_BETA,
                fov_threshold=tgt_params['fov_threshold'],
                erode_pixels=tgt_params['erode_pixels'],
                image_border_margin=tgt_params['image_border_margin'],
                apply_fov_mask=True
            )
            
            target_vessel_save = (target_vessel_map[0,0].cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
            Image.fromarray(target_vessel_save).save(os.path.join(infer_dir, f"{idx}_target_vessel_step{step_num}.png"))
            
        except Exception as e:
            print(f"  âš  ç›®æ ‡å›¾å¤„ç†å¤±è´¥: {e}")
    
    print(f"âœ“ æ¨ç†æµ‹è¯•å®Œæˆï¼Œç»“æœä¿å­˜è‡³: {infer_dir}")
    print(f"  Scribble ControlNet å¼ºåº¦: {scribble_scale}")
    print(f"  Tile ControlNet å¼ºåº¦: {args.tile_scale}")
    print(f"  æ¨ç†ç§å­: {fixed_seed} (å›ºå®š)")
    print(f"\n  ã€æ–°å¢è¾“å‡ºã€‘è¡€ç®¡æå–ç»“æœï¼ˆç”¨äº Vessel Loss è°ƒè¯•ï¼‰:")
    print(f"    - {idx}_pred_vessel_step{step_num}.png: é¢„æµ‹å›¾çš„è¡€ç®¡å“åº”å›¾")
    print(f"    - {idx}_target_vessel_step{step_num}.png: ç›®æ ‡å›¾çš„è¡€ç®¡å“åº”å›¾")
    print(f"{'='*70}\n")
    
    # æ¢å¤è®­ç»ƒæ¨¡å¼
    controlnet_scribble.train()
    controlnet_tile.train()


def main():
    # ============ å‚æ•°è§£æ ============
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", 
                        choices=["cf2octa", "octa2cf", "cf2fa", "fa2cf", "cf2oct", "oct2cf"], 
                        default="cf2octa",
                        help="è®­ç»ƒæ¨¡å¼ï¼šcf2octa(CFâ†’OCTA), octa2cf(OCTAâ†’CF), cf2fa(CFâ†’FA), fa2cf(FAâ†’CF), cf2oct(CFâ†’OCT), oct2cf(OCTâ†’CF)")
    parser.add_argument("-n", "--name", dest="name", default='sd15_v6',
                        help="å®éªŒåç§°ï¼ˆç”¨äºç»„ç»‡è¾“å‡ºç›®å½•ï¼‰")
    parser.add_argument("--train_csv", default=None,
                        help="è®­ç»ƒé›†CSVè·¯å¾„ï¼ˆä¸æŒ‡å®šåˆ™æ ¹æ®modeè‡ªåŠ¨é€‰æ‹©ï¼‰")
    parser.add_argument("--val_csv", default=None,
                        help="æµ‹è¯•é›†CSVè·¯å¾„ï¼ˆä¸æŒ‡å®šåˆ™æ ¹æ®modeè‡ªåŠ¨é€‰æ‹©ï¼‰")
    parser.add_argument("--resume_from", type=str, default=None,
                        help="ä»æŒ‡å®šcheckpointæ¢å¤è®­ç»ƒï¼Œä¾‹å¦‚: /path/to/step_6000")
    parser.add_argument("--max_steps", type=int, default=15000,
                        help="æ€»è®­ç»ƒæ­¥æ•°")
    
    # Dual ControlNet å¼ºåº¦å‚æ•°
    parser.add_argument("--scribble_scale", type=float, default=0.8,
                        help="Scribble ControlNet å¼ºåº¦ï¼ˆæ¨è 0.6-1.0ï¼‰")
    parser.add_argument("--tile_scale", type=float, default=1.0,
                        help="Tile ControlNet å¼ºåº¦ï¼ˆæ¨è 0.8-1.2ï¼‰")
    parser.add_argument("--msssim_lambda", type=float, default=0.1,
                        help="MS-SSIM æ„ŸçŸ¥æŸå¤±çš„æƒé‡ (è®¾ä¸º0åˆ™ç¦ç”¨)")
    parser.add_argument("--vessel_lambda", type=float, default=0.05,
                        help="Vessel Loss è¡€ç®¡ç»“æ„æŸå¤±çš„æƒé‡ (é»˜è®¤0.05)")
    parser.add_argument("--grad_lambda", type=float, default=0.1,
                        help="æ¢¯åº¦åŒ¹é…æŸå¤±çš„æƒé‡ (é»˜è®¤0.1)")
    parser.add_argument("--dynamiclr", "-dlr", action="store_true",
                        help="å¯ç”¨å­¦ä¹ ç‡è¡°å‡ (step<4000: 5e-5, step>=4000: Cosineè¡°å‡ 5e-5â†’1e-5)")
    
    global args
    args, _ = parser.parse_known_args()

    print("âœ“ ç¦»çº¿ç¯å¢ƒå˜é‡å·²åœ¨è„šæœ¬å¼€å§‹æ—¶è®¾ç½® (HF_HUB_OFFLINE=1)")
    
    # åˆ¤æ–­æ•°æ®é›†ç±»å‹
    is_cffa = args.mode in ["cf2fa", "fa2cf"]
    is_cfoct = args.mode in ["cf2oct", "oct2cf"]
    is_cfocta = args.mode in ["cf2octa", "octa2cf"]
    
    # æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©CSVæ–‡ä»¶
    if args.train_csv is None:
        if is_cffa:
            args.train_csv = CFFA_TRAIN_CSV
            args.val_csv = CFFA_VAL_CSV
        elif is_cfoct:
            args.train_csv = CFOCT_TRAIN_CSV
            args.val_csv = CFOCT_VAL_CSV
        else:  # is_cfocta
            args.train_csv = CFOCTA_TRAIN_CSV
            args.val_csv = CFOCTA_VAL_CSV
    elif args.val_csv is None:
        # å¦‚æœæŒ‡å®šäº†train_csvä½†æ²¡æœ‰val_csvï¼Œè‡ªåŠ¨é€‰æ‹©val_csv
        if is_cffa:
            args.val_csv = CFFA_VAL_CSV
        elif is_cfoct:
            args.val_csv = CFOCT_VAL_CSV
        else:
            args.val_csv = CFOCTA_VAL_CSV
    
    # ç¡®å®šæ•°æ®é›†ç±»å‹åç§°
    if is_cffa:
        dataset_type_name = "CF-FA"
    elif is_cfoct:
        dataset_type_name = "CF_OCT"
    else:
        dataset_type_name = "CF-OCTA"
    
    print(f"\næ•°æ®é›†é…ç½®:")
    print(f"  æ•°æ®é›†ç±»å‹: {dataset_type_name}")
    print(f"  è®­ç»ƒé›†CSV: {args.train_csv}")
    print(f"  æµ‹è¯•é›†CSV: {args.val_csv}")

    # è¾“å‡ºç›®å½•
    out_dir = os.path.join(out_root, args.mode, args.name)
    os.makedirs(out_dir, exist_ok=True)

    # ============ æ•°æ®åŠ è½½ï¼ˆv10ï¼šä½¿ç”¨ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ + ç»Ÿä¸€é…ç½®ï¼‰============
    # ã€v10 æ”¹è¿›ã€‘æ‰€æœ‰å¤„ç†å‚æ•°è‡ªåŠ¨ä» data_loader_all.py è·å–ï¼Œä¸éœ€è¦å¤–éƒ¨ä¼ å…¥
    # Single Source of Truthï¼šè®­ç»ƒå’Œæ¨ç†ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°
    train_ds = UnifiedDataset(args.train_csv, args.mode)
    val_ds = UnifiedDataset(args.val_csv, args.mode)
    
    train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, 
                             num_workers=4, drop_last=True)
    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, 
                           num_workers=2, drop_last=False)
    
    print(f"  è®­ç»ƒæ ·æœ¬æ•°: {len(train_ds)}")
    print(f"  æµ‹è¯•æ ·æœ¬æ•°: {len(val_ds)}")

    # ============ å‡†å¤‡å›ºå®šçš„æ¨ç†æµ‹è¯•æ ·æœ¬ï¼ˆä»æµ‹è¯•é›†éšæœºæŠ½å–ï¼‰============
    import random
    random.seed(42)  # å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œé€‰åŒä¸€ä¸ªæ ·æœ¬
    
    # ä»æµ‹è¯•é›†CSVä¸­è¯»å–å¹¶éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬
    with open(args.val_csv) as f:
        val_rows = list(csv.DictReader(f))
    
    if len(val_rows) == 0:
        raise ValueError(f"æµ‹è¯•é›†ä¸ºç©º: {args.val_csv}")
    
    fixed_sample_idx = random.randint(0, len(val_rows) - 1)
    fixed_sample_row = val_rows[fixed_sample_idx]
    
    # æ ¹æ®æ¨¡å¼å’Œæ•°æ®é›†ç±»å‹è·å–è·¯å¾„
    if is_cffa:
        # CF-FA æ•°æ®é›†
        if args.mode == "cf2fa":
            src_path = fixed_sample_row.get("cf_path")
            tgt_path = fixed_sample_row.get("fa_path")
        else:  # fa2cf
            src_path = fixed_sample_row.get("fa_path")
            tgt_path = fixed_sample_row.get("cf_path")
    else:
        # CF-OCTA æ•°æ®é›†
        if args.mode == "cf2octa":
            src_path = fixed_sample_row.get("cf_path") or fixed_sample_row.get("cond_path")
            tgt_path = fixed_sample_row.get("octa_path") or fixed_sample_row.get("target_path")
        else:  # octa2cf
            src_path = fixed_sample_row.get("octa_path") or fixed_sample_row.get("cond_path")
            from data_loader_cfocta import _strip_seg_prefix_in_path
            tgt_path = fixed_sample_row.get("cf_path") or _strip_seg_prefix_in_path(
                fixed_sample_row.get("cond_path") or fixed_sample_row.get("target_path")
            )
    
    print(f"\nå›ºå®šæ¨ç†æµ‹è¯•æ ·æœ¬ (æµ‹è¯•é›†ç´¢å¼• {fixed_sample_idx}):")
    print(f"  æºå›¾: {src_path}")
    print(f"  ç›®æ ‡å›¾: {tgt_path}")
    print(f"  æ¨¡å¼: {args.mode}\n")

    # ============ SD 1.5 + Dual ControlNet æ¨¡å‹åŠ è½½ ============
    global vae, unet, text_encoder, tokenizer, controlnet_scribble, controlnet_tile, vae_sf, noise_scheduler
    
    print("\n" + "="*70)
    print("æ­£åœ¨åŠ è½½ Stable Diffusion 1.5 + Dual ControlNet (Scribble + Tile) æ¨¡å‹...")
    print("="*70)
    
    resume_step = 0
    
    if args.resume_from:
        # ä» checkpoint æ¢å¤
        print(f"ä» checkpoint æ¢å¤: {args.resume_from}")
        
        # æ¸…ç†è·¯å¾„ï¼ˆå»é™¤å¤šä½™ç©ºæ ¼å’Œæ–œæ ï¼‰
        resume_dir = args.resume_from.strip()
        if not os.path.isabs(resume_dir):
            # åªæœ‰ç›¸å¯¹è·¯å¾„æ‰éœ€è¦è½¬æ¢
            resume_dir = os.path.abspath(resume_dir)
        
        print(f"  æ¸…ç†åè·¯å¾„: {resume_dir}")
        print(f"  è·¯å¾„å­˜åœ¨: {os.path.exists(resume_dir)}")
        
        if not os.path.exists(resume_dir):
            raise FileNotFoundError(f"Checkpoint ç›®å½•ä¸å­˜åœ¨: {resume_dir}")
        
        import re
        match = re.search(r'step_(\d+)', resume_dir)
        if match:
            resume_step = int(match.group(1))
            print(f"âœ“ æ£€æµ‹åˆ° step: {resume_step}")
        
        # åŠ è½½æ¨¡å‹ç»„ä»¶ï¼ˆFP32ï¼‰
        # Scribble ControlNet æ¢å¤
        scribble_path = os.path.join(resume_dir, "controlnet_scribble")
        tile_path = os.path.join(resume_dir, "controlnet_tile")
        
        print(f"  Scribble è·¯å¾„: {scribble_path}")
        print(f"    - è·¯å¾„å­˜åœ¨: {os.path.exists(scribble_path)}")
        print(f"  Tile è·¯å¾„: {tile_path}")
        print(f"    - è·¯å¾„å­˜åœ¨: {os.path.exists(tile_path)}")
        
        print(f"\n  æ­£åœ¨åŠ è½½ Scribble ControlNet...")
        controlnet_scribble = ControlNetModel.from_pretrained(
            scribble_path, 
            torch_dtype=torch.float32,
            local_files_only=True
        ).to(device)
        print(f"  âœ“ Scribble ControlNet åŠ è½½æˆåŠŸ")
        
        print(f"  æ­£åœ¨åŠ è½½ Tile ControlNet...")
        controlnet_tile = ControlNetModel.from_pretrained(
            tile_path, 
            torch_dtype=torch.float32,
            local_files_only=True
        ).to(device)
        print(f"  âœ“ Tile ControlNet åŠ è½½æˆåŠŸ")
        
        vae = AutoencoderKL.from_pretrained(
            base_dir, subfolder="vae", local_files_only=True
        ).to(device)
        unet = UNet2DConditionModel.from_pretrained(
            base_dir, subfolder="unet", local_files_only=True
        ).to(device)
        text_encoder = CLIPTextModel.from_pretrained(
            base_dir, subfolder="text_encoder", local_files_only=True
        ).to(device)
        tokenizer = CLIPTokenizer.from_pretrained(
            base_dir, subfolder="tokenizer", local_files_only=True
        )
        print(f"âœ“ å·²åŠ è½½ Dual ControlNet checkpoint (step {resume_step})")
    else:
        # ä»é¢„è®­ç»ƒæ¨¡å‹å¼€å§‹ï¼ˆFP32ï¼‰
        print("æ­£åœ¨åŠ è½½é¢„è®­ç»ƒçš„ Scribble + Tile ControlNet...")
        controlnet_scribble = ControlNetModel.from_pretrained(
            ctrl_scribble_dir, local_files_only=True
        ).to(device)
        print(f"âœ“ Scribble ControlNet åŠ è½½å®Œæˆ")
        
        controlnet_tile = ControlNetModel.from_pretrained(
            ctrl_tile_dir, local_files_only=True
        ).to(device)
        print(f"âœ“ Tile ControlNet åŠ è½½å®Œæˆ")
        
        vae = AutoencoderKL.from_pretrained(
            base_dir, subfolder="vae", local_files_only=True
        ).to(device)
        unet = UNet2DConditionModel.from_pretrained(
            base_dir, subfolder="unet", local_files_only=True
        ).to(device)
        text_encoder = CLIPTextModel.from_pretrained(
            base_dir, subfolder="text_encoder", local_files_only=True
        ).to(device)
        tokenizer = CLIPTokenizer.from_pretrained(
            base_dir, subfolder="tokenizer", local_files_only=True
        )
        print(f"âœ“ SD 1.5 åŸºç¡€æ¨¡å‹å·²åŠ è½½ï¼ˆFP32 ç²¾åº¦ï¼‰")

    # å†»ç»“ä¸»å¹²ï¼Œåªè®­ç»ƒ ControlNet
    unet.requires_grad_(False)
    vae.requires_grad_(False)
    text_encoder.requires_grad_(False)
    controlnet_scribble.requires_grad_(True)
    controlnet_tile.requires_grad_(True)

    # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    noise_scheduler = DDPMScheduler.from_pretrained(
        base_dir, subfolder="scheduler", local_files_only=True
    )

    # ä¼˜åŒ–å™¨ï¼šåŒæ—¶ä¼˜åŒ–ä¸¤ä¸ªControlNet
    import itertools
    opt = torch.optim.AdamW(
        itertools.chain(controlnet_scribble.parameters(), controlnet_tile.parameters()), 
        lr=5e-5, weight_decay=1e-2
    )
    mse = nn.MSELoss()
    if args.msssim_lambda > 0:
        msssim_loss_fn = MS_SSIM(data_range=1.0, size_average=True, channel=3).to(device)
    vae_sf = vae.config.scaling_factor

    # æ¢å¤ optimizer
    if args.resume_from:
        optimizer_path = os.path.join(args.resume_from, "optimizer.pt")
        if os.path.exists(optimizer_path):
            opt.load_state_dict(torch.load(optimizer_path))
            print("âœ“ å·²æ¢å¤ optimizer çŠ¶æ€")

    # è®¾ç½®è®­ç»ƒæ¨¡å¼
    max_steps = args.max_steps
    global_step = resume_step
    unet.eval()
    vae.eval()
    text_encoder.eval()
    controlnet_scribble.train()
    controlnet_tile.train()

    # è®¡æ—¶å’Œç»Ÿè®¡
    if device.type == "cuda":
        torch.cuda.synchronize()
    t_block = time.time()
    loss_accumulator = []
    msssim_loss_accumulator = []  # v8-3: æ€»æ˜¯åˆå§‹åŒ–
    vessel_loss_accumulator = []  # v8-3: æ–°å¢ (Frangi)
    grad_loss_accumulator = []    # v10-2: æ¢¯åº¦åŒ¹é…æŸå¤±
    
    # ============ æ—©åœæœºåˆ¶ç›¸å…³å˜é‡ ============
    best_val_loss = float("inf")
    best_step = 0
    patience = 8  # v10-3: ä»5æ”¹ä¸º8ï¼Œå¢åŠ è®­ç»ƒè€å¿ƒ
    wait = 0
    best_ckpt_dir = os.path.join(out_dir, "best_checkpoint")
    latest_ckpt_dir = os.path.join(out_dir, "latest_checkpoint")  # æ–°å¢ï¼šæœ€æ–°æ£€æŸ¥ç‚¹ç›®å½•
    validate_every = 500
    early_stopped = False
    min_train_steps = 4000  # v10-3: Warm-upæœŸï¼Œå‰4000æ­¥ä¸è§¦å‘æ—©åœ
    fixed_val_indices = None  # v10-3: å›ºå®šéªŒè¯å­é›†çš„ç´¢å¼•ï¼ˆç¬¬ä¸€æ¬¡éªŒè¯æ—¶åˆå§‹åŒ–ï¼‰

    # ============ éªŒè¯å‡½æ•°ï¼ˆç”¨äºæ—©åœï¼‰ ============
    def evaluate(val_dataset, val_indices=None, num_samples=10):
        """
        åœ¨éªŒè¯é›†ä¸Šè®¡ç®—æ€»æŸå¤±ï¼Œç”¨äºæ—©åœåˆ¤æ–­
        
        ã€v10-3 æ›´æ–°ã€‘ä½¿ç”¨å›ºå®šéªŒè¯å­é›†ï¼Œç¡®ä¿æ¯æ¬¡éªŒè¯çš„æ ·æœ¬ä¸€è‡´
        
        å‚æ•°:
            val_dataset: éªŒè¯é›† Dataset å¯¹è±¡
            val_indices: å›ºå®šçš„éªŒè¯æ ·æœ¬ç´¢å¼•åˆ—è¡¨ï¼ˆå¦‚æœä¸ºNoneåˆ™éšæœºæŠ½å–ï¼‰
            num_samples: é‡‡æ ·æ•°é‡ï¼ˆé»˜è®¤10ä¸ªæ ·æœ¬ï¼‰
        
        è¿”å›:
            avg_total_loss: éªŒè¯é›†å¹³å‡æ€»æŸå¤±
            val_indices: ä½¿ç”¨çš„éªŒè¯ç´¢å¼•ï¼ˆç”¨äºåç»­å¤ç”¨ï¼‰
        """
        print(f"\n{'='*70}")
        print(f"æ­£åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹...")
        print(f"{'='*70}")
        
        controlnet_scribble.eval()
        controlnet_tile.eval()
        
        # ã€v10-3 æ–°å¢ã€‘å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡éªŒè¯ï¼Œéšæœºé€‰æ‹©å›ºå®šå­é›†
        if val_indices is None:
            import random
            random.seed(42)  # å›ºå®šç§å­ç¡®ä¿å¯å¤ç°
            total_val_samples = len(val_dataset)
            num_samples = min(num_samples, total_val_samples)
            val_indices = random.sample(range(total_val_samples), num_samples)
            val_indices.sort()  # æ’åºä¾¿äºæŸ¥çœ‹
            print(f"  ã€é¦–æ¬¡éªŒè¯ã€‘éšæœºé€‰æ‹©å›ºå®šéªŒè¯å­é›†: {val_indices}")
        else:
            print(f"  ã€ä½¿ç”¨å›ºå®šå­é›†ã€‘éªŒè¯ç´¢å¼•: {val_indices}")
        
        val_losses = []
        
        with torch.no_grad():
            for idx in val_indices:
                # ä»æ•°æ®é›†ä¸­ç›´æ¥è·å–æŒ‡å®šç´¢å¼•çš„æ ·æœ¬
                batch_data = val_dataset[idx]
                cond_scribble, cond_tile, tgt, cond_path, tgt_path = batch_data
                
                # æ·»åŠ  batch ç»´åº¦å¹¶ç§»åˆ°è®¾å¤‡
                cond_scribble = cond_scribble.unsqueeze(0).to(device)
                cond_tile = cond_tile.unsqueeze(0).to(device)
                tgt = tgt.unsqueeze(0).to(device)
                b = 1
                
                # VAE ç¼–ç 
                latents = encode_vae(tgt)
                noise = torch.randn_like(latents)
                timesteps = torch.randint(
                    0, noise_scheduler.config.num_train_timesteps, 
                    (b,), device=device, dtype=torch.long
                )
                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
                
                # æ–‡æœ¬ç¼–ç 
                prompt_embeds = get_prompt_embeds(b)
                
                # Dual ControlNet å‰å‘ä¼ æ’­
                down_samples_scribble, mid_sample_scribble = controlnet_scribble(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=prompt_embeds,
                    controlnet_cond=cond_scribble,
                    conditioning_scale=args.scribble_scale,
                    return_dict=False
                )
                
                down_samples_tile, mid_sample_tile = controlnet_tile(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=prompt_embeds,
                    controlnet_cond=cond_tile,
                    conditioning_scale=args.tile_scale,
                    return_dict=False
                )
                
                # åˆå¹¶ä¸¤ä¸ªControlNetçš„è¾“å‡º
                down_samples = [
                    d_scribble + d_tile 
                    for d_scribble, d_tile in zip(down_samples_scribble, down_samples_tile)
                ]
                mid_sample = mid_sample_scribble + mid_sample_tile
                
                # UNet é¢„æµ‹å™ªå£°
                noise_pred = unet(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=prompt_embeds,
                    down_block_additional_residuals=down_samples,
                    mid_block_additional_residual=mid_sample
                ).sample
                
                # ============ ã€v10-2 ä¼˜åŒ–ã€‘è°ƒç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° ============
                total_loss = compute_total_loss(
                    noise_pred, noise, noisy_latents, latents, timesteps,
                    args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                    return_components=False
                )
                
                val_losses.append(total_loss.item())
        
        # æ¢å¤è®­ç»ƒæ¨¡å¼
        controlnet_scribble.train()
        controlnet_tile.train()
        
        avg_total_loss = np.mean(val_losses) if len(val_losses) > 0 else float('inf')
        
        print(f"âœ“ éªŒè¯å®Œæˆ")
        print(f"  éªŒè¯æ ·æœ¬æ•°: {len(val_indices)}")
        print(f"  å¹³å‡æ€»æŸå¤±: {avg_total_loss:.6f}")
        print(f"{'='*70}\n")
        
        return avg_total_loss, val_indices
    
    # ============ è®­ç»ƒä¿¡æ¯æ‰“å° ============
    print("\n" + "="*70)
    print("ã€SD 1.5 + Dual ControlNet è®­ç»ƒé…ç½® v11ã€‘âœ¨ ğŸ¯")
    print("="*70)
    print(f"  æ¨¡å‹: Stable Diffusion 1.5 (512Ã—512)")
    print(f"  ControlNet æ¶æ„: åŒè·¯ (Scribble + Tile)")
    print(f"    - Scribble: ç»¿è‰²é€šé“å¼•å¯¼ (å¼ºåº¦ {args.scribble_scale}) ã€v11æ›´æ–°ã€‘")
    print(f"    - Tile: åŸå›¾ç»†èŠ‚å¼•å¯¼ (å¼ºåº¦ {args.tile_scale})")
    print(f"  æ•°æ®é›†ç±»å‹: {'CF-FA' if is_cffa else ('CF_OCT' if is_cfoct else 'CF-OCTA')}")
    print(f"  è®­ç»ƒæ¨¡å¼: {args.mode}")
    print(f"  è®­ç»ƒå°ºå¯¸: {SIZE}Ã—{SIZE}")
    if is_cffa:
        print(f"  åŸå›¾å°ºå¯¸: {CFFA_ORIGINAL_SIZE[0]}Ã—{CFFA_ORIGINAL_SIZE[1]} (æ¨ç†æ—¶resizeå›)")
    print(f"\n  ã€v11 æ›´æ–°ã€‘âœ¨ ğŸ¯")
    print(f"  â”œâ”€ Scribbleè¾“å…¥æ”¹ç”¨ç»¿è‰²é€šé“ï¼ˆä¸å†ä½¿ç”¨Frangiæ»¤æ³¢ï¼‰")
    print(f"  â”‚   é¿å…è¾¹ç•Œä¼ªå½±é—®é¢˜ï¼Œä¿ç•™æ‰€æœ‰è¡€ç®¡ç»†èŠ‚")
    print(f"  â”‚   æ ¹æ®æ¨¡å¼è‡ªåŠ¨å–åï¼š{args.mode}")
    if args.mode in ['cf2fa', 'cf2octa', 'oct2cf']:
        print(f"  â”‚   â†’ éœ€è¦å–åï¼ˆæš—è¡€ç®¡å˜äº®ï¼‰")
    else:
        print(f"  â”‚   â†’ ä¸å–åï¼ˆä¿æŒåŸæ ·ï¼‰")
    print(f"  â”‚   åº”ç”¨CLAHEå¯¹æ¯”åº¦å¢å¼º")
    print(f"  â”œâ”€ Vessel Lossä¿æŒä½¿ç”¨Frangiæ»¤æ³¢ï¼ˆæ˜¾å¼è¡€ç®¡ç›‘ç£ï¼‰")
    print(f"\n  ã€v10-3 æ›´æ–°ã€‘âœ¨ ğŸ¯")
    print(f"  â”œâ”€ Vessel Loss æ”¹ç”¨ Dice Loss è®¡ç®—ï¼ˆé’ˆå¯¹ç¨€ç–è¡€ç®¡å›¾ä¼˜åŒ–ï¼‰")
    print(f"  â”‚   ä» MS-SSIM æ”¹ä¸º Dice Lossï¼ˆä¸“ä¸ºç¨€ç–äºŒå€¼ç»“æ„è®¾è®¡ï¼‰")
    print(f"  â”‚   è§£å†³èƒŒæ™¯ä¸»å¯¼æ•ˆåº”ï¼ˆ90%é»‘è‰²èƒŒæ™¯æ·¹æ²¡10%è¡€ç®¡ä¿¡å·ï¼‰")
    print(f"  â”‚   Diceç³»æ•°ä¸“æ³¨è¡€ç®¡åŒºåŸŸé‡å ï¼š2Ã—|Aâˆ©B| / (|A|+|B|)")
    print(f"  â”‚   ä¸å—1-2åƒç´ ä½ç½®åç§»å½±å“ï¼ˆå…³æ³¨æ•´ä½“é‡å åº¦ï¼‰")
    print(f"  â”‚   è®­ç»ƒæ›´ç¨³å®šï¼ŒLossä¿¡å·æ›´æ˜ç¡®ï¼Œæ”¶æ•›æ›´å¿«")
    print(f"\n  ã€v10-2 æ›´æ–°ã€‘âœ¨")
    print(f"  â”œâ”€ é‡æ„è¡€ç®¡æå–é€»è¾‘ï¼ˆSingle Source of Truthï¼‰")
    print(f"  â”‚   è¡€ç®¡æå–é€»è¾‘ç§»è‡³ data_loader_all.py ç»Ÿä¸€ç®¡ç†")
    print(f"  â”‚   æ ¸å¿ƒå‡½æ•°: extract_vessel_map_torch + frangi_filter_torch")
    print(f"  â”‚   è®­ç»ƒã€éªŒè¯ã€æ¨ç†ã€æ•°æ®åŠ è½½éƒ½ä½¿ç”¨åŒä¸€å¥—å®ç°")
    print(f"  â”‚   ä¿®æ”¹ä¸€å¤„ï¼Œæ‰€æœ‰åœ°æ–¹è‡ªåŠ¨åŒæ­¥ï¼ˆé¿å…ä¸ä¸€è‡´é—®é¢˜ï¼‰")
    print(f"  â”‚   æ¶ˆé™¤äº† scikit-image å’Œ PyTorch ä¸¤å¥— Frangi å¹¶å­˜çš„é—®é¢˜")
    print(f"  â”œâ”€ æ¨ç†æµ‹è¯•è¾“å‡ºè¡€ç®¡å“åº”å›¾")
    print(f"  â”‚   ä¿å­˜é¢„æµ‹å›¾å’Œç›®æ ‡å›¾çš„è¡€ç®¡æå–ç»“æœ")
    print(f"  â”‚   ä¾¿äºå¯è§†åŒ–è°ƒè¯• Vessel Loss çš„è®¡ç®—è¿‡ç¨‹")
    print(f"\n  ã€v13 æ›´æ–°ã€‘âœ¨ ğŸ¯")
    print(f"  â”œâ”€ CF_OCT é…å‡†æ–¹æ¡ˆå‡çº§ä¸ºé€è§†å˜æ¢")
    print(f"  â”‚   ä½¿ç”¨é€è§†å˜æ¢ï¼ˆHomographyï¼‰æ›¿ä»£ä»¿å°„å˜æ¢")
    print(f"  â”‚   ä¸ç®¡ cf2oct è¿˜æ˜¯ oct2cfï¼Œç»Ÿä¸€é…å‡†åˆ° CF åŸŸï¼ˆ1016Ã—675ï¼‰")
    print(f"  â”‚   é…å‡†åç›´æ¥ resize åˆ° 512Ã—512ï¼ˆä¸ä½¿ç”¨ resize_with_paddingï¼‰")
    print(f"  â”‚   ä½¿ç”¨ registration_cf_oct_v2.register_cfoct_pair() ç»Ÿä¸€æ¥å£")
    print(f"  â”‚   è®­ç»ƒå’Œæ¨ç†ä½¿ç”¨å®Œå…¨ç›¸åŒçš„é…å‡†é€»è¾‘ï¼ˆdata_loader_all_v13ï¼‰")
    print(f"\n  ã€v10 æ›´æ–°ã€‘âœ¨")
    print(f"  â”œâ”€ ä½¿ç”¨ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ï¼ˆdata_loader_all_v13.pyï¼‰")
    print(f"  â”‚   æ•´åˆä¸‰ä¸ªæ•°æ®é›†åŠ è½½å™¨ï¼ˆCF-OCTAã€CF-FAã€CF_OCTï¼‰")
    print(f"  â”œâ”€ Single Source of Truthï¼ˆå•ä¸€æ•°æ®æºï¼‰")
    print(f"  â”‚   æ‰€æœ‰å›¾åƒå¤„ç†å‚æ•°åœ¨ data_loader_all_v13.py ç»Ÿä¸€ç®¡ç†")
    print(f"  â”‚   è®­ç»ƒå’Œæ¨ç†è‡ªåŠ¨ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°")
    print(f"  â”‚   å‚æ•°æ ¹æ® mode è‡ªåŠ¨ä» IMAGE_PROCESSING_PARAMS æŸ¥è¡¨è·å–")
    print(f"  â”œâ”€ gen_mask + ä¾µèš€æ©ç ï¼ˆè§£å†³è¾¹ç•Œè¯¯è¯†åˆ«é—®é¢˜ï¼‰")
    print(f"  â”‚   ä½¿ç”¨ gen_mask æ£€æµ‹é»‘è¾¹åŒºåŸŸ")
    print(f"  â”‚   å¯¹æ©ç å‘å†…ä¾µèš€æŒ‡å®šåƒç´ ï¼ˆCF/OCT/OCTA:10px, FA:20pxï¼‰")
    print(f"  â”‚   å›¾åƒè¾¹ç•Œä¿æŠ¤ï¼ˆCF/OCT/OCTA:5px, FA:10pxï¼‰")
    print(f"  â”‚   åº”ç”¨èŒƒå›´:")
    print(f"  â”‚     - Scribble ControlNet è¾“å…¥: Frangiæ»¤æ³¢ + FOVæ©ç ")
    print(f"  â”‚     - Vessel Loss è®¡ç®—: Frangiæ»¤æ³¢ + FOVæ©ç ï¼ˆä¸è¾“å…¥ä¸€è‡´ï¼‰")
    print(f"  â”‚   è‡ªé€‚åº”ä»»æ„å½¢çŠ¶çš„è§†é‡è¾¹ç•Œï¼Œç§»é™¤è¾¹ç•Œä¼ªå½±")
    print(f"\n  ã€v9-1 æ›´æ–°ã€‘âœ¨")
    print(f"  â”œâ”€ MSE Loss åœ¨å™ªå£°ç©ºé—´åº”ç”¨è’™ç‰ˆæ¶ˆé™¤é»‘è¾¹å½±å“")
    print(f"  â”‚   åœ¨åƒç´ ç©ºé—´æ£€æµ‹GTçš„é»‘è¾¹åŒºåŸŸ")
    print(f"  â”‚   å°†è’™ç‰ˆdownsampleåˆ°latentç©ºé—´ï¼ˆå™ªå£°ç©ºé—´ï¼‰")
    print(f"  â”‚   åœ¨å™ªå£°ç©ºé—´è®¡ç®—MSEï¼ˆä¿æŒæ‰©æ•£æ¨¡å‹æ ‡å‡†è®­ç»ƒèŒƒå¼ï¼‰")
    print(f"  â”‚   MSEæ•°å€¼å°ºåº¦ä¸åŸç‰ˆä¸€è‡´ï¼Œé¿å…æƒé‡å¤±è¡¡")
    print(f"  â”œâ”€ MS-SSIMå’ŒVessel Lossåœ¨åƒç´ ç©ºé—´åº”ç”¨è’™ç‰ˆ")
    print(f"  â”‚   ä¿æŒè¾…åŠ©æŸå¤±çš„è’™ç‰ˆä¼˜åŒ–ç­–ç•¥")
    print(f"  â””â”€ æ ¸å¿ƒä¼˜åŠ¿ï¼šæ—¢æ¶ˆé™¤é»‘è¾¹å½±å“ï¼Œåˆä¸ç ´åæ‰©æ•£æ¨¡å‹è®­ç»ƒ")
    print(f"\n  ã€v8-3-3 æ›´æ–°ã€‘")
    print(f"  â”œâ”€ ä¿®å¤ Vessel Loss é€»è¾‘ (octa2cf æ¨¡å¼)")
    print(f"  â”‚   CFå›¾åœ¨ Vessel Loss è®¡ç®—æ—¶æ­£ç¡®å–åï¼ˆæš—è¡€ç®¡â†’äº®è¡€ç®¡ï¼‰")
    print(f"  â”‚   ä¸ Scribble ControlNet è¾“å…¥å¤„ç†ä¿æŒä¸€è‡´")
    print(f"  â”œâ”€ ä¿®å¤é…å‡†é»‘è¾¹å¹²æ‰°")
    print(f"  â”‚   CFå›¾å–åå‰å…ˆå°†å…¨é»‘åƒç´ æ›¿æ¢æˆçº¯ç™½")
    print(f"  â”‚   é¿å…é»‘è¾¹å–ååå˜ç™½è¢«è¯¯è®¤ä¸ºè¡€ç®¡")
    print(f"\n  ã€v8-3-2 æ–°ç‰¹æ€§ã€‘")
    if not is_cffa:
        print(f"  â”œâ”€ CF-OCTA æ•°æ®é›†æ›´æ–°:")
        print(f"  â”‚   CFè®­ç»ƒé›†å·²æ”¹ä¸ºå½©è‰²åŸå›¾")
        print(f"  â”‚   Tileè¾“å…¥: ç›´æ¥ä½¿ç”¨åŸå›¾ï¼ˆä¸åšé¢„å¤„ç†ï¼‰")
        print(f"  â”‚   ç›®æ ‡å›¾: ç›´æ¥ä½¿ç”¨å½©è‰²åŸå›¾ï¼ˆä¸åšé¢„å¤„ç†ï¼‰")
    print(f"  â”œâ”€ æŸå¤±å‡½æ•°: MSE + MS-SSIM + Vessel Loss (Frangi+Dice) ã€v10-3æ”¹è¿›ã€‘")
    print(f"  â”œâ”€ Frangi æ»¤æ³¢å‚æ•°:")
    print(f"  â”‚   Sigmas: range(1, 16) - å¤šå°ºåº¦è¡€ç®¡æ£€æµ‹")
    if is_cffa:
        print(f"  â”‚   Gamma: 0.015 (CF-FAæ•°æ®é›†ï¼Œä»…ç”¨äºVessel Loss)")
        print(f"  â”‚   Scribbleè¾“å…¥: ç»¿è‰²é€šé“ + {('å–å' if args.mode == 'cf2fa' else 'ä¸å–å')} + CLAHE")
        print(f"  â”‚   Vessel Losså¤„ç†: CFå›¾(Frangi+å–å) / FAå›¾(Frangi)")
        print(f"  â”‚   Dice Loss: ä¸“æ³¨è¡€ç®¡åŒºåŸŸé‡å åº¦ï¼ˆè§£å†³ç¨€ç–å›¾èƒŒæ™¯ä¸»å¯¼é—®é¢˜ï¼‰")
    elif is_cfoct:
        print(f"  â”‚   Gamma: CFå›¾=0.015, OCTå›¾=0.02 (CF_OCTæ•°æ®é›†ï¼Œä»…ç”¨äºVessel Loss)")
        print(f"  â”‚   Scribbleè¾“å…¥: ç»¿è‰²é€šé“ + {('å–å' if args.mode == 'oct2cf' else 'ä¸å–å')} + CLAHE")
        print(f"  â”‚   Vessel Losså¤„ç†: CFå›¾(Frangi+å–å) / OCTå›¾(Frangi+å–å)")
        print(f"  â”‚   Tile: ç›´æ¥ä½¿ç”¨åŸå§‹å½©è‰²å›¾")
        print(f"  â”‚   Dice Loss: ä¸“æ³¨è¡€ç®¡åŒºåŸŸé‡å åº¦ï¼ˆè§£å†³ç¨€ç–å›¾èƒŒæ™¯ä¸»å¯¼é—®é¢˜ï¼‰")
    else:
        print(f"  â”‚   Gamma: CFå›¾=0.008, OCTAå›¾=0.1 (CF-OCTAæ•°æ®é›†ï¼Œä»…ç”¨äºVessel Loss)")
        print(f"  â”‚   Scribbleè¾“å…¥: ç»¿è‰²é€šé“ + {('å–å' if args.mode == 'cf2octa' else 'ä¸å–å')} + CLAHE")
        print(f"  â”‚   Vessel Losså¤„ç†: CFå›¾(Frangi+å–å) / OCTAå›¾(Frangi)")
        print(f"  â”‚   Tile: ç›´æ¥ä½¿ç”¨åŸå§‹å½©è‰²å›¾")
        print(f"  â”‚   Dice Loss: ä¸“æ³¨è¡€ç®¡åŒºåŸŸé‡å åº¦ï¼ˆè§£å†³ç¨€ç–å›¾èƒŒæ™¯ä¸»å¯¼é—®é¢˜ï¼‰")
    print(f"  â”œâ”€ å›ºå®šæŸå¤±æƒé‡:")
    print(f"  â”‚   MSE (å™ªå£°ç©ºé—´ï¼Œè’™ç‰ˆ): 1.0 (å›ºå®š)")
    print(f"  â”‚   MS-SSIM (åƒç´ ç©ºé—´ï¼Œè’™ç‰ˆ): {args.msssim_lambda} (å›ºå®š)")
    print(f"  â”‚   Vessel (åƒç´ ç©ºé—´ï¼Œè’™ç‰ˆ): {args.vessel_lambda} (å›ºå®š)")
    print(f"  â”‚   Gradient (åƒç´ ç©ºé—´ï¼Œè’™ç‰ˆ): {args.grad_lambda} (å›ºå®š)")
    print(f"  â”œâ”€ è’™ç‰ˆç­–ç•¥: MSEåœ¨å™ªå£°ç©ºé—´ï¼ŒSSIM/Vessel/Gradåœ¨åƒç´ ç©ºé—´")
    if args.dynamiclr:
        print(f"  â”œâ”€ å­¦ä¹ ç‡: åŠ¨æ€è¡°å‡ (step<4000: 5e-5, step>=4000: Cosine 5e-5â†’1e-5)")
    else:
        print(f"  â”œâ”€ å­¦ä¹ ç‡: 5e-5 (å›ºå®šï¼Œæ— è¡°å‡)")
    print(f"  â”œâ”€ æ—©åœæœºåˆ¶: éªŒè¯æŸå¤±è¿ç»­ {patience} æ¬¡æœªæå‡åˆ™åœæ­¢ ã€v10-3ä¼˜åŒ–ã€‘")
    print(f"  â”‚   Patience: {patience} æ¬¡ï¼ˆ{patience * validate_every} æ­¥ï¼‰")
    print(f"  â”‚   Warm-up: {min_train_steps} æ­¥ï¼ˆæ­¤å‰ä¸è§¦å‘æ—©åœï¼‰")
    print(f"  â”œâ”€ éªŒè¯é¢‘ç‡: æ¯ {validate_every} æ­¥ï¼ˆå›ºå®šéªŒè¯å­é›†10ä¸ªæ ·æœ¬ï¼‰ã€v10-3ä¼˜åŒ–ã€‘")
    print(f"  â”‚   ç¬¬ä¸€æ¬¡éªŒè¯éšæœºé€‰æ‹©å­é›†ï¼Œåç»­éªŒè¯é‡å¤ä½¿ç”¨")
    print(f"  â”œâ”€ æ£€æŸ¥ç‚¹ä¿å­˜ç­–ç•¥:")
    print(f"  â”‚   - best_checkpoint: ä¿å­˜éªŒè¯æŸå¤±æœ€ä½çš„æ¨¡å‹")
    print(f"  â”‚   - latest_checkpoint: æ¯æ¬¡éªŒè¯è¦†ç›–ä¿å­˜ï¼ˆé˜²æ­¢è®­ç»ƒä¸­æ–­ï¼‰")
    print(f"  â”‚   - step_XXX/: ä»…ä¿å­˜æ¨ç†æµ‹è¯•å›¾åƒï¼ˆä¸ä¿å­˜æƒé‡ï¼‰")
    print(f"  â””â”€ è®­ç»ƒæ—¥å¿—: æ¯100æ­¥è®°å½•åˆ° training_log.txt")
    print(f"\n  ç²¾åº¦: FP32")
    print(f"  ä¼˜åŒ–å™¨: AdamW")
    print(f"  è®­ç»ƒæ ·æœ¬: {len(train_ds)} | æµ‹è¯•æ ·æœ¬: {len(val_ds)}")
    print(f"  è®­ç»ƒCSV: {args.train_csv}")
    print(f"  è¾“å‡ºç›®å½•: {out_dir}")
    if args.resume_from:
        print(f"  æ¢å¤è®­ç»ƒ: step {resume_step} â†’ {max_steps} (å‰©ä½™ {max_steps - resume_step} æ­¥)")
    else:
        print(f"  è®­ç»ƒæ­¥æ•°: 0 â†’ {max_steps}")
    print("="*70 + "\n")

    # ============ è®­ç»ƒå¾ªç¯ ============
    while global_step < max_steps:
        if early_stopped:
            break  # æ—©åœåé€€å‡ºå¤–å±‚å¾ªç¯
        for batch_data in train_loader:
            if global_step >= max_steps:
                break
            
            # æ•°æ®è§£åŒ…ï¼ˆä¸¤ä¸ªæ•°æ®åŠ è½½å™¨è¿”å›æ ¼å¼ç›¸åŒï¼‰
            # CF-FA: [vessel, tile, tgt, paths...]
            # CF-OCTA: [hed, tile, tgt, paths...]
            cond_scribble, cond_tile, tgt, cond_paths, tgt_paths = batch_data
            cond_scribble = cond_scribble.to(device)
            cond_tile = cond_tile.to(device)
            tgt = tgt.to(device)
            b = tgt.shape[0]
            
            # ç¬¬ä¸€æ­¥ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆåŸå›¾ã€é…å‡†å›¾ã€Tileè¾“å…¥ï¼‰
            if global_step == 0:
                debug_dir = os.path.join(out_dir, "debug_images_step0")
                os.makedirs(debug_dir, exist_ok=True)
                
                # æ–‡ä»¶å
                cond_filename = os.path.splitext(os.path.basename(cond_paths[0]))[0]
                tgt_filename = os.path.splitext(os.path.basename(tgt_paths[0]))[0]
                
                # 1. ä¿å­˜Scribbleæ¡ä»¶å›¾ï¼ˆVesselï¼‰
                cond_scribble_save = (cond_scribble[0].cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(cond_scribble_save).save(os.path.join(debug_dir, f"{cond_filename}_scribble_input.png"))
                
                # 2. ä¿å­˜Tileæ¡ä»¶å›¾ï¼ˆåŸå›¾ï¼‰
                cond_tile_save = (cond_tile[0].cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(cond_tile_save).save(os.path.join(debug_dir, f"{cond_filename}_tile_input.png"))
                
                # 3. ä¿å­˜é…å‡†åçš„ç›®æ ‡å›¾
                tgt_save = ((tgt[0].cpu().float().permute(1, 2, 0).numpy() + 1) / 2 * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(tgt_save).save(os.path.join(debug_dir, f"{tgt_filename}_registered.png"))
                
                print(f"\n{'='*70}")
                print(f"âœ“ Step 0 è°ƒè¯•å›¾åƒå·²ä¿å­˜åˆ°: {debug_dir}")
                print(f"  1. {cond_filename}_scribble_input.png - Scribble ControlNet è¾“å…¥ï¼ˆã€v11ã€‘ç»¿è‰²é€šé“+å¯é€‰å–å+CLAHEï¼‰")
                print(f"  2. {cond_filename}_tile_input.png - Tile ControlNet è¾“å…¥ï¼ˆåŸå›¾ï¼‰")
                print(f"  3. {tgt_filename}_registered.png - é…å‡†åç›®æ ‡å›¾")
                print(f"{'='*70}\n")

            # è®­ç»ƒæ­¥éª¤
            with torch.no_grad():
                # VAE ç¼–ç 
                latents = encode_vae(tgt)
                noise = torch.randn_like(latents)
                timesteps = torch.randint(
                    0, noise_scheduler.config.num_train_timesteps, 
                    (b,), device=device, dtype=torch.long
                )
                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
                
                # æ–‡æœ¬ç¼–ç ï¼ˆç©º promptï¼‰
                prompt_embeds = get_prompt_embeds(b)
            
            # Dual ControlNet å‰å‘ä¼ æ’­
            # 1. Scribble ControlNet (Vesselæˆ–HED)
            down_samples_scribble, mid_sample_scribble = controlnet_scribble(
                noisy_latents,
                timesteps,
                encoder_hidden_states=prompt_embeds,
                controlnet_cond=cond_scribble,  # Scribble æ¡ä»¶ï¼šVesselæˆ–HED
                conditioning_scale=args.scribble_scale,  # Scribble å¼ºåº¦
                return_dict=False
            )
            
            # 2. Tile ControlNet
            down_samples_tile, mid_sample_tile = controlnet_tile(
                noisy_latents,
                timesteps,
                encoder_hidden_states=prompt_embeds,
                controlnet_cond=cond_tile,  # Tile æ¡ä»¶ï¼šåŸå›¾
                conditioning_scale=args.tile_scale,  # Tile å¼ºåº¦
                return_dict=False
            )
            
            # 3. åˆå¹¶ä¸¤ä¸ªControlNetçš„è¾“å‡º
            down_samples = [
                d_scribble + d_tile 
                for d_scribble, d_tile in zip(down_samples_scribble, down_samples_tile)
            ]
            mid_sample = mid_sample_scribble + mid_sample_tile
            
            # UNet é¢„æµ‹å™ªå£°
            noise_pred = unet(
                noisy_latents,
                timesteps,
                encoder_hidden_states=prompt_embeds,
                down_block_additional_residuals=down_samples,
                mid_block_additional_residual=mid_sample
            ).sample
            
            # ============ ã€v10-2 ä¼˜åŒ–ã€‘è°ƒç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° ============
            # ç¬¬ä¸€æ­¥ä¿å­˜ Vessel Loss è°ƒè¯•å›¾åƒ
            vessel_debug_dir = os.path.join(out_dir, "debug_vessel_loss_step0") if global_step == 0 else None
            
            # è®¡ç®—æ€»æŸå¤±ï¼ˆè¿”å›å„åˆ†é‡ç”¨äºæ—¥å¿—è®°å½•ï¼‰
            loss, loss_mse, loss_msssim, loss_vessel, loss_grad = compute_total_loss(
                noise_pred, noise, noisy_latents, latents, timesteps,
                args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                return_components=True,
                vessel_debug_dir=vessel_debug_dir
            )
            
            # åå‘ä¼ æ’­
            opt.zero_grad(set_to_none=True)
            loss.backward()
            opt.step()
            
            # ============ å­¦ä¹ ç‡ç­–ç•¥ï¼šæ ¹æ® --dynamiclr å‚æ•°å†³å®š ============
            if args.dynamiclr:
                # åŠ¨æ€å­¦ä¹ ç‡è¡°å‡ï¼ˆCosine Annealingï¼‰
                current_lr = get_dynamic_learning_rate(global_step, max_steps)
                for param_group in opt.param_groups:
                    param_group['lr'] = current_lr
            else:
                # å›ºå®šå­¦ä¹ ç‡ 5e-5ï¼ˆæ—©åœæœºåˆ¶ä¾èµ–éªŒè¯æŸå¤±ï¼‰
                current_lr = 5e-5
            
            # ç»Ÿè®¡
            loss_accumulator.append(loss_mse.item())
            if args.msssim_lambda > 0:
                msssim_loss_accumulator.append(loss_msssim.item())
            if args.vessel_lambda > 0:
                vessel_loss_accumulator.append(loss_vessel.item())
            if args.grad_lambda > 0:
                grad_loss_accumulator.append(loss_grad.item())
            global_step += 1
            
            # æ—¥å¿—è¾“å‡ºï¼ˆæ¯100æ­¥ï¼‰
            if global_step % 100 == 0:
                if device.type == "cuda":
                    torch.cuda.synchronize()
                elapsed = time.time() - t_block
                
                # è®¡ç®—å¹³å‡æŸå¤±
                avg_mse = np.mean(loss_accumulator)
                loss_accumulator = []
                
                # è®¡ç®—è¡€ç®¡æŸå¤±å¹³å‡å€¼
                if args.vessel_lambda > 0 and len(vessel_loss_accumulator) > 0:
                    avg_vessel = np.mean(vessel_loss_accumulator)
                    vessel_loss_accumulator = []
                else:
                    avg_vessel = 0.0
                
                if len(msssim_loss_accumulator) > 0:
                    avg_msssim = np.mean(msssim_loss_accumulator)
                    msssim_loss_accumulator = []
                else:
                    avg_msssim = 0.0

                if args.grad_lambda > 0 and len(grad_loss_accumulator) > 0:
                    avg_grad = np.mean(grad_loss_accumulator)
                    grad_loss_accumulator = []
                else:
                    avg_grad = 0.0
                
                t_val = timesteps[0].item()
                
                # æ„å»ºæ—¥å¿—æ¶ˆæ¯
                msg_parts = [
                    f"[SD15-v10] step {global_step}/{max_steps}",
                    f"lr:{current_lr:.2e}",
                    f"mse:{avg_mse:.4f}",
                ]
                
                # æ˜¾ç¤ºè¡€ç®¡æŸå¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if args.vessel_lambda > 0:
                    msg_parts.append(f"vessel:{avg_vessel:.4f}(Î»={args.vessel_lambda})")
                
                if args.msssim_lambda > 0:
                    msg_parts.append(f"msssim:{avg_msssim:.4f}(Î»={args.msssim_lambda})")

                if args.grad_lambda > 0:
                    msg_parts.append(f"grad:{avg_grad:.4f}(Î»={args.grad_lambda})")

                msg_parts.extend([
                    f"t={t_val:3d}",
                    f"S:{args.scribble_scale}",
                    f"T:{args.tile_scale}",
                    f"{elapsed:.1f}s"
                ])
                msg = " | ".join(msg_parts)
                
                print(msg)
                
                # ä¿å­˜æ—¥å¿—åˆ°ç»Ÿä¸€çš„è®­ç»ƒæ—¥å¿—æ–‡ä»¶
                train_log_path = os.path.join(out_dir, "training_log.txt")
                with open(train_log_path, "a") as f:
                    f.write(msg + "\n")
                
                if device.type == "cuda":
                    torch.cuda.synchronize()
                t_block = time.time()
            
            # ============ v10-3: éªŒè¯é›†è¯„ä¼° + æ—©åœæœºåˆ¶ + ä¿å­˜ checkpointï¼ˆæ¯500æ­¥ï¼‰============
            if global_step % validate_every == 0:
                # 1. å…ˆåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼ˆä½¿ç”¨å›ºå®šéªŒè¯å­é›†ï¼‰
                val_loss, fixed_val_indices = evaluate(val_ds, val_indices=fixed_val_indices, num_samples=10)
                
                # 2. åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
                is_best = False
                if val_loss < best_val_loss - 1e-4:  # æ˜æ˜¾ä¸‹é™ï¼ˆ1e-4 æ˜¯é˜ˆå€¼ï¼‰
                    best_val_loss = val_loss
                    best_step = global_step
                    wait = 0
                    is_best = True
                    
                    print(f"\n{'='*70}")
                    print(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³æ¨¡å‹ï¼")
                    print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
                    print(f"  æœ€ä½³æ­¥æ•°: {best_step}")
                    print(f"{'='*70}\n")
                else:
                    # ã€v10-3 ä¿®å¤ã€‘åªåœ¨ warm-up æœŸä¹‹åæ‰å¢åŠ  wait è®¡æ•°
                    if global_step >= min_train_steps:
                        wait += 1
                        print(f"\n{'='*70}")
                        print(f"âš  éªŒè¯æŸå¤±æœªæå‡ï¼ˆè¿ç»­ {wait}/{patience} æ¬¡ï¼‰")
                        print(f"  å½“å‰éªŒè¯æŸå¤±: {val_loss:.6f}")
                        print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f} (step {best_step})")
                        print(f"{'='*70}\n")
                    else:
                        print(f"\n{'='*70}")
                        print(f"â„¹ï¸  Warm-up æœŸï¼Œä¸è®¡å…¥ patience")
                        print(f"  å½“å‰éªŒè¯æŸå¤±: {val_loss:.6f}")
                        print(f"{'='*70}\n")
                
                # 3. ä¿å­˜ latest_checkpointï¼ˆæ¯æ¬¡è¦†ç›–ï¼‰
                os.makedirs(latest_ckpt_dir, exist_ok=True)
                
                controlnet_scribble.save_pretrained(os.path.join(latest_ckpt_dir, "controlnet_scribble"))
                controlnet_tile.save_pretrained(os.path.join(latest_ckpt_dir, "controlnet_tile"))
                torch.save(opt.state_dict(), os.path.join(latest_ckpt_dir, "optimizer.pt"))
                
                # ä¿å­˜ latest çš„å…ƒä¿¡æ¯ï¼ˆæ ‡æ³¨å½“å‰æ­¥æ•°ï¼‰
                with open(os.path.join(latest_ckpt_dir, "latest_info.txt"), "w") as f:
                    f.write(f"Latest Step: {global_step}\n")
                    f.write(f"Validation Loss: {val_loss:.6f}\n")
                    f.write(f"Best Loss: {best_val_loss:.6f} (step {best_step})\n")
                
                print(f"\n{'='*70}")
                print(f"âœ“ Latest Checkpoint å·²ä¿å­˜: {latest_ckpt_dir}")
                print(f"  - Latest Step: {global_step}")
                print(f"  - Validation Loss: {val_loss:.6f}")
                print(f"  - controlnet_scribble/")
                print(f"  - controlnet_tile/")
                print(f"  - latest_info.txt")
                print(f"{'='*70}\n")
                
                # 4. å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜åˆ° best_checkpoint ç›®å½•
                if is_best:
                    os.makedirs(best_ckpt_dir, exist_ok=True)
                    
                    controlnet_scribble.save_pretrained(os.path.join(best_ckpt_dir, "controlnet_scribble"))
                    controlnet_tile.save_pretrained(os.path.join(best_ckpt_dir, "controlnet_tile"))
                    torch.save(opt.state_dict(), os.path.join(best_ckpt_dir, "optimizer.pt"))
                    
                    # ä¿å­˜æœ€ä½³æ¨¡å‹çš„å…ƒä¿¡æ¯
                    with open(os.path.join(best_ckpt_dir, "best_info.txt"), "w") as f:
                        f.write(f"Best Step: {best_step}\n")
                        f.write(f"Best Validation Loss: {best_val_loss:.6f}\n")
                    
                    print(f"\n{'='*70}")
                    print(f"ğŸ’¾ Best Checkpoint å·²ä¿å­˜: {best_ckpt_dir}")
                    print(f"{'='*70}\n")
                
                # 5. åˆ›å»ºæ¨ç†æµ‹è¯•ç›®å½•ï¼ˆåªä¿å­˜æ¨ç†å›¾åƒï¼Œä¸ä¿å­˜æƒé‡ï¼‰
                step_inference_dir = os.path.join(out_dir, f"step_{global_step}")
                os.makedirs(step_inference_dir, exist_ok=True)
                
                # 6. è¿è¡Œæ¨ç†æµ‹è¯•ï¼ˆæ¨ç†å›¾ä¿å­˜åˆ° step_XXX ç›®å½•ï¼‰
                run_inference_test(fixed_sample_row, step_inference_dir, global_step, args.mode)
                
                # 7. æ—©åœåˆ¤æ–­ï¼ˆåªåœ¨ warm-up æœŸåè§¦å‘ï¼‰
                if global_step >= min_train_steps and wait >= patience:
                    print(f"\n{'='*70}")
                    print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼")
                    print(f"  éªŒè¯æŸå¤±è¿ç»­ {patience} æ¬¡æœªæå‡")
                    print(f"  æœ€ä½³æ­¥æ•°: {best_step}")
                    print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
                    print(f"  å½“å‰æ­¥æ•°: {global_step}")
                    print(f"{'='*70}\n")
                    
                    early_stopped = True
                    break  # é€€å‡ºè®­ç»ƒå¾ªç¯

    # ============ æœ€ç»ˆä¿å­˜ ============
    # ä¸å†ä¿å­˜æœ€ç»ˆæ¨¡å‹åˆ°æ ¹ç›®å½•ï¼Œåªä¿ç•™ best_checkpoint å’Œ latest_checkpoint
    # latest_checkpoint å·²åœ¨æœ€åä¸€æ¬¡éªŒè¯æ—¶ä¿å­˜
    
    print("\n" + "="*70)
    print("ã€è®­ç»ƒå®Œæˆã€‘âœ…")
    print("="*70)
    
    # æ‰“å°æ—©åœä¿¡æ¯
    if early_stopped:
        print(f"  è®­ç»ƒæ–¹å¼: æ—©åœï¼ˆéªŒè¯æŸå¤±è¿ç»­ {patience} æ¬¡æœªæå‡ï¼‰")
        print(f"  å®é™…è®­ç»ƒæ­¥æ•°: {global_step} / {max_steps}")
    else:
        print(f"  è®­ç»ƒæ–¹å¼: æ­£å¸¸å®Œæˆ")
        print(f"  è®­ç»ƒæ­¥æ•°: {max_steps}")
    
    print(f"\n  ã€æœ€ä½³æ¨¡å‹ä¿¡æ¯ (Best Checkpoint)ã€‘")
    print(f"  â”œâ”€ æœ€ä½³æ­¥æ•°: {best_step}")
    print(f"  â”œâ”€ æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    print(f"  â”œâ”€ ä¿å­˜è·¯å¾„: {best_ckpt_dir}")
    print(f"  â””â”€ åŒ…å«æ–‡ä»¶: controlnet_scribble/, controlnet_tile/, optimizer.pt, best_info.txt")
    
    print(f"\n  ã€æœ€æ–°æ¨¡å‹ä¿¡æ¯ (Latest Checkpoint)ã€‘")
    print(f"  â”œâ”€ æœ€æ–°æ­¥æ•°: {global_step}")
    print(f"  â”œâ”€ ä¿å­˜è·¯å¾„: {latest_ckpt_dir}")
    print(f"  â””â”€ åŒ…å«æ–‡ä»¶: controlnet_scribble/, controlnet_tile/, optimizer.pt, latest_info.txt")
    print(f"  â„¹ï¸  latest_info.txt ä¸­è®°å½•äº†ä¿å­˜æ—¶çš„æ­¥æ•°å’ŒéªŒè¯æŸå¤±")
    
    print(f"\n  ã€è®­ç»ƒé…ç½®ã€‘")
    print(f"  â”œâ”€ æ¨¡å‹ç‰ˆæœ¬: SD 1.5 + Dual ControlNet v13 (Scribble + Tile, FP32)")
    print(f"  â”œâ”€ æ•°æ®é›†ç±»å‹: {'CF-FA' if is_cffa else ('CF_OCT' if is_cfoct else 'CF-OCTA')}")
    print(f"  â”œâ”€ v13 æ–°ç‰¹æ€§: CF_OCTé…å‡†å‡çº§ä¸ºé€è§†å˜æ¢ï¼ˆç»Ÿä¸€é…å‡†åˆ°CFåŸŸï¼‰")
    print(f"  â”œâ”€ v11 æ–°ç‰¹æ€§: Scribbleè¾“å…¥æ”¹ç”¨ç»¿è‰²é€šé“ï¼ˆé¿å…Frangiè¾¹ç•Œä¼ªå½±ï¼‰")
    print(f"  â”œâ”€ v10-3 æ–°ç‰¹æ€§: Vessel Loss ä½¿ç”¨ Dice Lossï¼ˆè§£å†³ç¨€ç–è¡€ç®¡å›¾é—®é¢˜ï¼‰")
    print(f"  â”œâ”€ v10-3 æ—©åœä¼˜åŒ–: å›ºå®šéªŒè¯å­é›† + Patience={patience} + Warm-up={min_train_steps}")
    print(f"  â”œâ”€ v10-2 ç‰¹æ€§: å›ºå®šå­¦ä¹ ç‡ 5e-5 + æ—©åœæœºåˆ¶")
    print(f"  â”œâ”€ v10 ç‰¹æ€§: ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ï¼ˆv13ï¼‰ + gen_maskä¾µèš€æ©ç ï¼ˆä»…ç”¨äºVessel Lossï¼‰")
    
    if not is_cffa and not is_cfoct:
        print(f"  â”œâ”€ v8-3-2 æ›´æ–°: CFè®­ç»ƒé›†æ”¹ä¸ºå½©è‰²åŸå›¾ï¼ŒTileè¾“å…¥ç›´æ¥ä½¿ç”¨åŸå›¾")
    
    print(f"  â”œâ”€ ControlNet å¼ºåº¦: Scribble={args.scribble_scale}, Tile={args.tile_scale}")
    print(f"  â”œâ”€ æŸå¤±å‡½æ•°: MSE(å™ªå£°ç©ºé—´) + MS-SSIM(Î»={args.msssim_lambda}) + Vessel(Î»={args.vessel_lambda}) + Grad(Î»={args.grad_lambda})")
    
    if is_cffa:
        print(f"  â”œâ”€ Frangi å‚æ•°: sigmas=range(1,16), gamma_cffa=0.015 (CF-FA)")
    elif is_cfoct:
        print(f"  â”œâ”€ Frangi å‚æ•°: sigmas=range(1,16), gamma_cf=0.015, gamma_oct=0.02 (CF_OCT)")
    else:
        print(f"  â”œâ”€ Frangi å‚æ•°: sigmas=range(1,16), gamma_cf=0.008, gamma_octa=0.1 (CF-OCTA)")
    
    if args.dynamiclr:
        print(f"  â”œâ”€ å­¦ä¹ ç‡: åŠ¨æ€è¡°å‡ (step<4000: 5e-5, step>=4000: Cosine 5e-5â†’1e-5)")
    else:
        print(f"  â”œâ”€ å­¦ä¹ ç‡: 5e-5 (å›ºå®šï¼Œæ— è¡°å‡)")
    print(f"  â”œâ”€ éªŒè¯é¢‘ç‡: æ¯ {validate_every} æ­¥ï¼ˆå›ºå®šéªŒè¯å­é›†ï¼‰")
    print(f"  â”œâ”€ æ—©åœè€å¿ƒ: {patience} æ¬¡ï¼ˆ{patience * validate_every} æ­¥ï¼‰")
    print(f"  â””â”€ Warm-up: {min_train_steps} æ­¥ï¼ˆæ­¤å‰ä¸è§¦å‘æ—©åœï¼‰")
    
    if args.resume_from:
        print(f"\n  ä» step {resume_step} æ¢å¤ï¼Œè®­ç»ƒäº† {global_step - resume_step} æ­¥")
    else:
        print(f"\n  ä»å¤´è®­ç»ƒäº† {global_step} æ­¥")
    
    print("\n" + "="*70)
    print("ğŸ’¡ æ¨èä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œæ¨ç†:")
    print(f"   {best_ckpt_dir}")
    print(f"\nğŸ’¡ å¦‚éœ€æ¢å¤è®­ç»ƒï¼Œä½¿ç”¨æœ€æ–°æ£€æŸ¥ç‚¹:")
    print(f"   {latest_ckpt_dir}")
    print(f"\nğŸ’¡ æ¨ç†æµ‹è¯•å›¾åƒä¿å­˜åœ¨:")
    print(f"   {out_dir}/step_500/, {out_dir}/step_1000/, ...")
    print(f"\nğŸ’¡ è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨:")
    print(f"   {os.path.join(out_dir, 'training_log.txt')}")
    print("="*70 + "\n")


if __name__ == "__main__":
    print("1")
    main()

