# -*- coding: utf-8 -*-
'''
è®­ç»ƒè„šæœ¬ - SD 1.5 + Dual ControlNet v11-1-unified-v2

ã€æ¨¡å‹ã€‘Stable Diffusion 1.5 (512Ã—512) + åŒè·¯ ControlNet (Scribble + Tile)
ã€æ•°æ®é›†ã€‘æ”¯æŒ CF-OCTA / CF-FA / CF_OCT

ã€æ ¸å¿ƒç‰¹æ€§ v11-1-unified-v2ã€‘
1. Vessel Loss ä½¿ç”¨ç›¸å¯¹è¯¯å·®åŠ æƒMSE - æ•°å­¦æ›´ä¸¥è°¨
   - å…¬å¼: |(pred-gt)/(gt+Îµ)|Â² å¯¹æ‰€æœ‰ç²—ç»†è¡€ç®¡å…¬å¹³
   - ç®€åŒ–åŠ æƒ: fine_vessel_boost=3.0 (ç»†è¡€ç®¡3.7å€, ç²—è¡€ç®¡1å€)
   
2. ç»Ÿä¸€Maskç­–ç•¥ - æ‰€æœ‰Lossåªæ’é™¤é…å‡†é»‘è¾¹
   - MSE/MS-SSIM/Gradient/Vessel ç»Ÿä¸€ä½¿ç”¨åŒä¸€mask (RGB<0.01)
   - ä¸é¢å¤–ä¾µèš€FOVè¾¹ç•Œï¼Œç¡®ä¿å…¨å›¾è¡€ç®¡è·å¾—ä¸€è‡´ç›‘ç£

3. Scribbleè¾“å…¥æ”¹ç”¨ç»¿è‰²é€šé“ (ä¸å†ä½¿ç”¨Frangi)
   - é¿å…è¾¹ç•Œä¼ªå½±ï¼Œä¿ç•™æ‰€æœ‰ç»†èŠ‚
   - æ ¹æ®æ¨¡å¼è‡ªåŠ¨å–å + CLAHEå¢å¼º
   
4. Vessel Lossä»ç”¨Frangiæ»¤æ³¢ (ä»…Lossè®¡ç®—)
   - æä¾›æ˜¾å¼è¡€ç®¡ç»“æ„ç›‘ç£

ã€æ¶æ„ã€‘
- ControlNet-Scribble: ç»¿è‰²é€šé“ (å¼ºåº¦0.8)
- ControlNet-Tile: åŸå›¾ç»†èŠ‚ (å¼ºåº¦1.0)
- æŸå¤±å‡½æ•°: MSE(å™ªå£°ç©ºé—´) + MS-SSIM(Î»=0.1) + Vessel-åŠ æƒMSE(Î»=0.5) + Gradient(Î»=0.1)

ã€è®­ç»ƒç­–ç•¥ã€‘
- å­¦ä¹ ç‡: 5e-5å›ºå®š æˆ– åŠ¨æ€è¡°å‡ (--dynamiclr)
- æ—©åœ: patience=8, warm-up=4000æ­¥
- éªŒè¯: æ¯500æ­¥, å›ºå®šå­é›†10æ ·æœ¬
- Checkpoint: best_checkpoint + latest_checkpoint

ã€ä½¿ç”¨æ–¹æ³•ã€‘
python train_controlnet_sd15_v11-1.py --mode cf2fa --name exp_name --max_steps 8000 \\
    --scribble_scale 0.8 --vessel_lambda 0.5 --msssim_lambda 0.1 --grad_lambda 0.1
'''

import os
# ============ è®¾ç½®ç¦»çº¿æ¨¡å¼ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ HF åº“ä¹‹å‰ï¼‰============
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"
os.environ["HF_HUB_DISABLE_TELEMETRY"] = "1"
os.environ["DISABLE_TELEMETRY"] = "1"

import csv, math, itertools
import torch, numpy as np
import cv2
from PIL import Image
from torch import nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from diffusers import (DDPMScheduler, StableDiffusionControlNetPipeline,
                       ControlNetModel, 
                       AutoencoderKL, UNet2DConditionModel)
from transformers import CLIPTextModel, CLIPTokenizer
from pytorch_msssim import MS_SSIM  # ä»…ç”¨äºåƒç´ ç©ºé—´çš„MS-SSIM Lossï¼ŒVessel Losså·²æ”¹ç”¨Dice
import time
import argparse

# å¯¼å…¥ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ï¼ˆv11ï¼‰
from data_loader_all_v11 import (
    UnifiedDataset, SIZE, preprocess_for_vessel_extraction,
    GAMMA_CFFA, GAMMA_CFOCTA_CF, GAMMA_CFOCTA_OCTA,  # v10: Frangiå‚æ•°ï¼ˆä»…ç”¨äºVessel Lossï¼‰
    GAMMA_CFOCT_CF, GAMMA_CFOCT_OCT, FRANGI_SIGMAS, FRANGI_ALPHA, FRANGI_BETA,
    create_eroded_mask,  # v10: FOVæ©ç ç”Ÿæˆï¼ˆç”¨äºVessel Lossï¼‰
    get_image_params,    # v10: ç»Ÿä¸€å›¾åƒå¤„ç†å‚æ•°é…ç½®ï¼ˆè®­ç»ƒå’Œæ¨ç†å…±ç”¨ï¼‰
    frangi_filter_torch, extract_vessel_map_torch  # v10-2: PyTorchå¯å¾®è¡€ç®¡æå–ï¼ˆè®­ç»ƒ/éªŒè¯/æ¨ç†å…±ç”¨ï¼‰
)
from registration_cf_octa import load_affine_matrix, apply_affine_registration

# ============ SD 1.5 + Dual ControlNet æ¨¡å‹è·¯å¾„é…ç½® ============
base_dir = "/data/student/Fengjunming/SDXL_ControlNet/models/sd15-diffusers"
ctrl_scribble_dir = "/data/student/Fengjunming/SDXL_ControlNet/models/controlnet-sd15-scribble"
ctrl_tile_dir = "/data/student/Fengjunming/SDXL_ControlNet/models/controlnet-sd15-tile"

# CSV æ•°æ®è·¯å¾„é…ç½®ï¼ˆæ ¹æ®æ¨¡å¼é€‰æ‹©ï¼‰
CFOCTA_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_v2-2_repaired.csv"
CFOCTA_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_v2-2_repaired.csv"
CFFA_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_cffa.csv"
CFFA_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_cffa.csv"
CFOCT_TRAIN_CSV = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/train_pairs_cfoct.csv"
CFOCT_VAL_CSV   = "/data/student/Fengjunming/SDXL_ControlNet/Scripts/test_pairs_cfoct.csv"

# è¾“å‡ºç›®å½•
out_root  = "/data/student/Fengjunming/SDXL_ControlNet/results/out_ctrl_sd15_dual"
device    = torch.device("cuda")

# CF-FA åŸå§‹å›¾åƒå°ºå¯¸
CFFA_ORIGINAL_SIZE = (720, 576)  # width, height

# æ³¨æ„ï¼šå›¾åƒå¤„ç†å‚æ•°é…ç½®å·²ç§»è‡³ data_loader_all.py
# ä½¿ç”¨ get_image_params(mode, param_type) è·å–ç»Ÿä¸€é…ç½®
# ç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°

# ============ ç¼–ç å·¥å…·å‡½æ•° ============
def get_prompt_embeds(bs):
    """
    SD 1.5 æ–‡æœ¬ç¼–ç ï¼ˆç®€åŒ–ç‰ˆï¼Œåªè¿”å› prompt_embedsï¼‰
    """
    prompts = [""] * bs
    text_inputs = tokenizer(
        prompts,
        padding="max_length",
        max_length=tokenizer.model_max_length,
        truncation=True,
        return_tensors="pt",
    )
    text_input_ids = text_inputs.input_ids.to(device)
    prompt_embeds = text_encoder(text_input_ids)[0]
    return prompt_embeds

def encode_vae(img):
    """VAE ç¼–ç ï¼šimg [-1,1] â†’ latents"""
    latents = vae.encode(img).latent_dist.sample() * vae_sf
    return latents

def decode_vae(latents):
    """VAE è§£ç ï¼šlatents â†’ img [-1,1]"""
    img = vae.decode(latents / vae_sf).sample
    return img


# ============ æ¢¯åº¦åŒ¹é…å·¥å…·å‡½æ•° ============
def _get_sobel_kernels(device, dtype):
    base_kernel = torch.tensor(
        [[1., 0., -1.],
         [2., 0., -2.],
         [1., 0., -1.]],
        device=device,
        dtype=dtype
    )
    kernel_x = base_kernel.view(1, 1, 3, 3)
    kernel_y = base_kernel.t().view(1, 1, 3, 3)
    return kernel_x, kernel_y


def compute_image_gradients(image):
    """
    è®¡ç®—å›¾åƒçš„ Sobel æ¢¯åº¦ã€‚

    Args:
        image: (B, C, H, W) tensorï¼ŒèŒƒå›´ [0, 1]

    Returns:
        grad_x, grad_y: ä¸è¾“å…¥åŒå½¢çŠ¶çš„æ¢¯åº¦å¼ é‡
    """
    kernel_x, kernel_y = _get_sobel_kernels(image.device, image.dtype)
    kernel_x = kernel_x.expand(image.shape[1], 1, 3, 3)
    kernel_y = kernel_y.expand(image.shape[1], 1, 3, 3)
    grad_x = F.conv2d(image, kernel_x, padding=1, groups=image.shape[1])
    grad_y = F.conv2d(image, kernel_y, padding=1, groups=image.shape[1])
    return grad_x, grad_y


def compute_gradient_match_loss(pred_imgs_01, gt_imgs_01, mask=None, reduction="l1"):
    """
    æ¢¯åº¦åŒ¹é…æŸå¤±ï¼šçº¦æŸé¢„æµ‹å›¾ä¸ç›®æ ‡å›¾åœ¨æ¢¯åº¦ç©ºé—´ä¿æŒä¸€è‡´ã€‚

    Args:
        pred_imgs_01: (B, 3, H, W) é¢„æµ‹å›¾åƒï¼ŒèŒƒå›´ [0, 1]
        gt_imgs_01: (B, 3, H, W) ç›®æ ‡å›¾åƒï¼ŒèŒƒå›´ [0, 1]
        mask: (B, 1, H, W) å¯é€‰ï¼Œ0 è¡¨ç¤ºå¿½ç•¥åŒºåŸŸ
        reduction: 'l1' æˆ– 'l2'

    Returns:
        æ ‡é‡æŸå¤±å€¼
    """
    # ä½¿ç”¨ç»¿è‰²é€šé“ä½œä¸ºç°åº¦åŸºç¡€ï¼ˆOCT å¯¹æ¯”åº¦æœ€ä½³ï¼‰
    pred_gray = pred_imgs_01[:, 1:2, :, :]
    gt_gray = gt_imgs_01[:, 1:2, :, :]

    pred_grad_x, pred_grad_y = compute_image_gradients(pred_gray)
    gt_grad_x, gt_grad_y = compute_image_gradients(gt_gray)

    if reduction == "l2":
        diff = (pred_grad_x - gt_grad_x) ** 2 + (pred_grad_y - gt_grad_y) ** 2
    else:
        diff = (pred_grad_x - gt_grad_x).abs() + (pred_grad_y - gt_grad_y).abs()

    if mask is not None:
        diff = diff * mask

    return diff.mean()


# ============ v8-3 æ–°å¢ï¼šFrangi è¡€ç®¡æ»¤æ³¢æŸå¤± ============
# ============ v10-2 é‡æ„ï¼šè¡€ç®¡æå–é€»è¾‘å·²ç§»è‡³ data_loader_all.py ============
# ============ v10-3 æ”¹è¿›ï¼šä» MS-SSIM æ”¹ä¸º Dice Lossï¼ˆè§£å†³ç¨€ç–è¡€ç®¡å›¾é—®é¢˜ï¼‰============
# ============ v11-1 æ”¹è¿›ï¼šä» Dice Loss æ”¹ä¸ºåŠ æƒMSEï¼ˆè§£å†³æƒé‡éš¾è°ƒé—®é¢˜ï¼‰============
# ä» data_loader_all å¯¼å…¥ï¼šfrangi_filter_torch, extract_vessel_map_torch

def compute_vessel_loss_weighted_mse(pred_imgs, gt_imgs, mode='cf2fa', sigmas=FRANGI_SIGMAS, 
                                alpha=FRANGI_ALPHA, beta=FRANGI_BETA, 
                                gamma_cffa=GAMMA_CFFA, 
                                gamma_cfocta_cf=GAMMA_CFOCTA_CF, 
                                gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                                gamma_cfoct_cf=GAMMA_CFOCT_CF, 
                                gamma_oct=GAMMA_CFOCT_OCT,
                                debug_dir=None):
    """
    è¡€ç®¡ç»“æ„æŸå¤± - ä½¿ç”¨ Frangi æ»¤æ³¢ + ç›¸å¯¹è¯¯å·®åŠ æƒMSE
    
    ã€v11-1-unified-v2 æ›´æ–°ã€‘ğŸ¯ ğŸ”¥ âœ¨ ğŸŒŸ
    - **ã€ç›¸å¯¹è¯¯å·®ã€‘** æ”¹ç”¨ç›¸å¯¹è¯¯å·®è®¡ç®—ï¼Œè§£å†³å°ºåº¦ä¸å¹³è¡¡é—®é¢˜
      * ç»å¯¹è¯¯å·®é—®é¢˜ï¼šç»†è¡€ç®¡å€¼å°(0.1)ï¼Œå³ä½¿é”™50%ï¼Œlossä¹Ÿå¾ˆå°(0.0025)
      * ç›¸å¯¹è¯¯å·®ä¼˜åŠ¿ï¼š|(pred-gt)/gt|Â²ï¼Œå¯¹æ‰€æœ‰ç²—ç»†è¡€ç®¡å…¬å¹³
      * æ•°å­¦æ›´ä¸¥è°¨ï¼šå°ºåº¦ä¸å˜æ€§ï¼Œç¬¦åˆäººçœ¼æ„ŸçŸ¥ï¼ˆå…³æ³¨ç›¸å¯¹å˜åŒ–ï¼‰
    - **ã€ç®€åŒ–åŠ æƒã€‘** ç›¸å¯¹è¯¯å·®æä¾›å¤©ç„¶å¹³è¡¡ï¼Œåªéœ€é€‚åº¦åŠ æƒ
      * fine_vessel_boosté™è‡³3.0ï¼ˆåŸ20.0ï¼‰ï¼Œé¿å…è¿‡åº¦å¤æ‚
      * ç»†è¡€ç®¡æƒé‡3.7å€ï¼Œç²—è¡€ç®¡1å€ï¼Œæ¸©å’Œé€‚ä¸­
    
    ã€v11-1-unified æ›´æ–°ã€‘ğŸ¯ ğŸ”¥ âœ¨
    - **ã€ç»Ÿä¸€Maskç­–ç•¥ã€‘** ä¸MSE/MS-SSIM/Gradient Lossä¿æŒä¸€è‡´
    - åªæ’é™¤é…å‡†é»‘è¾¹ï¼ˆRGB<0.01ï¼‰ï¼Œä¸å†é¢å¤–ä¾µèš€FOVè¾¹ç•Œ
    - é¿å…"FOVå¤–ä¸é‡è¦"çš„åè§ï¼Œç¡®ä¿å…¨å›¾è¡€ç®¡ç›‘ç£
    - ç®€åŒ–è®¾è®¡ï¼Œæ¶ˆé™¤å¤šçº§maskå·®å¼‚é—®é¢˜
    
    ã€v11-1 æ›´æ–°ã€‘ğŸ¯ ğŸ”¥
    - æ”¹ç”¨åŠ æƒMSEè®¡ç®—è¡€ç®¡ç»“æ„æŸå¤±ï¼ˆæ›¿ä»£Dice Lossï¼‰
    - è§£å†³Dice Lossæƒé‡éš¾è°ƒé—®é¢˜ï¼ˆDiceå€¼~0.9ï¼Œåªèƒ½ç”¨Î»=0.05ï¼Œç¨é«˜å°±å¤±æ§ï¼‰
    - åŠ æƒMSEæ•°å€¼æ›´å°ï¼ˆ~0.01-0.05ï¼‰ï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨æ›´é«˜æƒé‡ï¼ˆÎ»=0.5-2.0ï¼‰
    - æ¢¯åº¦å±€éƒ¨åŒ–ï¼Œä¸ä¼šåƒDiceé‚£æ ·å…¨å±€å¤±æ§å¯¼è‡´è“é»‘æ¡çº¹
    
    ã€v10-3 æ›´æ–°ã€‘ğŸ¯ï¼ˆå·²æ”¹ä¸ºåŠ æƒMSEï¼‰
    - åŸDice Lossæ–¹æ¡ˆï¼šè§£å†³èƒŒæ™¯ä¸»å¯¼ï¼Œä½†æƒé‡éš¾è°ƒ
    - Diceç³»æ•°ï¼š2Ã—|Aâˆ©B| / (|A|+|B|)ï¼Œå…³æ³¨é‡å åº¦
    - é—®é¢˜ï¼šDiceå€¼å¤ªé«˜ï¼ˆ0.85-0.95ï¼‰ï¼Œå¯¼è‡´Î»=0.1æ—¶å¤±æ§
    
    ã€å¤„ç†é€»è¾‘ã€‘v9 æ›´æ–° - æ”¯æŒ CF_OCT æ•°æ®é›†
    - CF-FA æ•°æ®é›†:
      * CFå›¾: ç»¿è‰²é€šé“ â†’ é»‘è¾¹æ›¿æ¢æˆç™½è‰² â†’ å–åï¼ˆè¡€ç®¡æ˜¯æš—è‰²ï¼‰
      * FAå›¾: ç»¿è‰²é€šé“ + ä¸å–åï¼ˆè¡€ç®¡æ˜¯äº®è‰²ï¼‰
    - CF-OCTA æ•°æ®é›†:
      * CFå›¾: ç»¿è‰²é€šé“ â†’ é»‘è¾¹æ›¿æ¢æˆç™½è‰² â†’ å–åï¼ˆè¡€ç®¡æ˜¯æš—è‰²ï¼‰
      * OCTAå›¾: ç»¿è‰²é€šé“ + ä¸å–åï¼ˆè¡€ç®¡æ˜¯äº®è‰²ï¼‰
    - CF_OCT æ•°æ®é›† (æ–°å¢):
      * CFå›¾: ç»¿è‰²é€šé“ â†’ é»‘è¾¹æ›¿æ¢æˆç™½è‰² â†’ å–åï¼ˆè¡€ç®¡æ˜¯æš—è‰²ï¼‰
      * OCTå›¾: ç»¿è‰²é€šé“ â†’ é»‘è¾¹æ›¿æ¢æˆç™½è‰² â†’ å–åï¼ˆè¡€ç®¡æ˜¯æš—è‰²ï¼‰
    
    æ³¨æ„ï¼šCF/OCTå›¾å–åå‰å…ˆå°†å…¨é»‘åƒç´ ï¼ˆé…å‡†é»‘è¾¹ï¼‰æ›¿æ¢æˆçº¯ç™½ï¼Œ
         é¿å…é»‘è¾¹å–ååå˜ç™½è¢«Frangiè¯¯è®¤ä¸ºè¡€ç®¡
    
    å‚æ•°:
        pred_imgs: é¢„æµ‹å›¾åƒ (B, 3, H, W)ï¼ŒèŒƒå›´ [-1, 1]
        gt_imgs: ç›®æ ‡å›¾åƒ (B, 3, H, W)ï¼ŒèŒƒå›´ [-1, 1]
        mode: è®­ç»ƒæ¨¡å¼ ('cf2fa', 'fa2cf', 'cf2octa', 'octa2cf', 'cf2oct', 'oct2cf')
        sigmas: Frangi å¤šå°ºåº¦å‚æ•°ï¼ˆé»˜è®¤ FRANGI_SIGMASï¼‰
        alpha: Frangi æ¿çŠ¶ç»“æ„æ•æ„Ÿåº¦ï¼ˆé»˜è®¤ FRANGI_ALPHAï¼‰
        beta: Frangi çƒçŠ¶ç»“æ„æ•æ„Ÿåº¦ï¼ˆé»˜è®¤ FRANGI_BETAï¼‰
        gamma_cffa: CF-FAæ¨¡å¼çš„gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFFAï¼‰
        gamma_cfocta_cf: CF-OCTAæ¨¡å¼çš„CFå›¾gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFOCTA_CFï¼‰
        gamma_cfocta_octa: CF-OCTAæ¨¡å¼çš„OCTAå›¾gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFOCTA_OCTAï¼‰
        gamma_cfoct_cf: CF_OCTæ¨¡å¼çš„CFå›¾gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFOCT_CFï¼‰
        gamma_oct: CF_OCTæ¨¡å¼çš„OCTå›¾gammaå€¼ï¼ˆé»˜è®¤ GAMMA_CFOCT_OCTï¼‰
        debug_dir: è°ƒè¯•å›¾åƒä¿å­˜ç›®å½•ï¼ˆä»…ç¬¬ä¸€æ­¥ä½¿ç”¨ï¼‰
    
    è¿”å›:
        loss: åŠ æƒMSEæŸå¤±ï¼ˆæ ‡é‡ï¼‰
    """
    # 1. è½¬æ¢åˆ° [0, 1] èŒƒå›´
    pred_01 = (pred_imgs.clamp(-1, 1) + 1) / 2  # (B, 3, H, W)
    gt_01 = (gt_imgs.clamp(-1, 1) + 1) / 2
    
    # 2. åˆ›å»ºæœ‰æ•ˆåƒç´ æ©ç ï¼ˆæ’é™¤é»‘è‰²é…å‡†è¾¹ç¼˜åŒºåŸŸï¼‰- ä¸MSE/MS-SSIM/Gradientç»Ÿä¸€
    threshold = 0.01
    black_mask_pred = (pred_01 <= threshold).all(dim=1, keepdim=True)  # (B,1,H,W)
    black_mask_gt = (gt_01 <= threshold).all(dim=1, keepdim=True)
    valid_mask = ~(black_mask_pred | black_mask_gt)  # (B,1,H,W)
    
    # 3. ã€v10-2 é‡æ„ + v11-1-unified æ›´æ–°ã€‘è°ƒç”¨ data_loader_all ä¸­çš„ç»Ÿä¸€è¡€ç®¡æå–å‡½æ•°
    # å…³é—­FOV maskåŠŸèƒ½ï¼Œåªä½¿ç”¨Frangiæ»¤æ³¢æœ¬èº«
    # é¢„æµ‹å›¾çš„è¡€ç®¡æå–ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
    pred_vessel, _ = extract_vessel_map_torch(
        pred_01, mode,
        gamma_cffa=gamma_cffa,
        gamma_cfocta_cf=gamma_cfocta_cf,
        gamma_cfocta_octa=gamma_cfocta_octa,
        gamma_cfoct_cf=gamma_cfoct_cf,
        gamma_oct=gamma_oct,
        sigmas=sigmas,
        alpha=alpha,
        beta=beta,
        fov_threshold=10,
        erode_pixels=0,  # ğŸ‘ˆ ä¸ä¾µèš€
        image_border_margin=0,  # ğŸ‘ˆ ä¸ç§»é™¤è¾¹ç•Œ
        apply_fov_mask=False  # ğŸ‘ˆ å…³é—­FOV mask
    )
    
    # GT å›¾çš„è¡€ç®¡æå–ï¼ˆä¸éœ€è¦æ¢¯åº¦ï¼‰
    with torch.no_grad():
        gt_vessel, _ = extract_vessel_map_torch(
            gt_01, mode,
            gamma_cffa=gamma_cffa,
            gamma_cfocta_cf=gamma_cfocta_cf,
            gamma_cfocta_octa=gamma_cfocta_octa,
            gamma_cfoct_cf=gamma_cfoct_cf,
            gamma_oct=gamma_oct,
            sigmas=sigmas,
            alpha=alpha,
            beta=beta,
            fov_threshold=10,
            erode_pixels=0,  # ğŸ‘ˆ ä¸ä¾µèš€
            image_border_margin=0,  # ğŸ‘ˆ ä¸ç§»é™¤è¾¹ç•Œ
            apply_fov_mask=False  # ğŸ‘ˆ å…³é—­FOV mask
        )
    
    # 4. ã€v11-1-unifiedã€‘ä½¿ç”¨ç»Ÿä¸€çš„valid_maskï¼ˆåªæ’é™¤é…å‡†é»‘è¾¹ï¼‰
    # valid_mask (B, 1, H, W)
    
    # 5. ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆä»…ç¬¬ä¸€æ­¥ï¼‰
    if debug_dir is not None:
        os.makedirs(debug_dir, exist_ok=True)
        pred_save = (pred_01[0].detach().cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
        gt_save = (gt_01[0].detach().cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(pred_save).save(os.path.join(debug_dir, "vessel_loss_pred_input.png"))
        Image.fromarray(gt_save).save(os.path.join(debug_dir, "vessel_loss_gt_input.png"))
        pred_vessel_save = (pred_vessel[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        gt_vessel_save = (gt_vessel[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(pred_vessel_save).save(os.path.join(debug_dir, "vessel_loss_pred_frangi.png"))
        Image.fromarray(gt_vessel_save).save(os.path.join(debug_dir, "vessel_loss_gt_frangi.png"))
        valid_mask_save = (valid_mask[0,0].detach().cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
        Image.fromarray(valid_mask_save).save(os.path.join(debug_dir, "vessel_loss_valid_mask.png"))
    
    # 6. åº”ç”¨æ©ç åˆ°è¡€ç®¡å›¾ï¼ˆåªåœ¨æœ‰æ•ˆåŒºåŸŸå†…è®¡ç®—ï¼‰
    pred_vessel_masked = pred_vessel * valid_mask.float()  # (B, 1, H, W)
    gt_vessel_masked = gt_vessel * valid_mask.float()      # (B, 1, H, W)
    
    # 7. ã€v11-1-unified-v2ã€‘è®¡ç®—ç›¸å¯¹è¯¯å·®åŠ æƒMSE Loss
    # æ ¸å¿ƒæ”¹è¿›ï¼šä½¿ç”¨ç›¸å¯¹è¯¯å·®è§£å†³å°ºåº¦ä¸å¹³è¡¡é—®é¢˜
    
    # 7.1 è®¡ç®—ç›¸å¯¹è¯¯å·®ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
    epsilon = 0.1  # å¹³æ»‘å› å­ï¼ˆé¿å…é™¤ä»¥æ¥è¿‘0çš„å€¼ï¼‰
    relative_diff = torch.abs(pred_vessel_masked - gt_vessel_masked) / (gt_vessel_masked + epsilon)
    relative_diff_squared = relative_diff ** 2  # (B, 1, H, W)
    
    # 7.2 ç”Ÿæˆç®€åŒ–çš„æƒé‡å›¾ï¼ˆç›¸å¯¹è¯¯å·®å·²ç»å¹³è¡¡äº†å°ºåº¦ï¼Œåªéœ€ç®€å•åŠ æƒï¼‰
    vessel_threshold = 0.05  # è¡€ç®¡æ£€æµ‹é˜ˆå€¼
    is_vessel = (gt_vessel_masked > vessel_threshold).float()  # 1=è¡€ç®¡ï¼Œ0=èƒŒæ™¯
    
    # å¯é€‰ï¼šå¯¹ç»†è¡€ç®¡ç»™äºˆé€‚åº¦é¢å¤–å…³æ³¨ï¼ˆä¸å†éœ€è¦æç«¯æƒé‡ï¼‰
    # å…¬å¼ï¼šweight = (1.0 - gt_vessel) Ã— k + base
    # - ç»†è¡€ç®¡ï¼ˆgt_vessel=0.1ï¼‰ï¼šweight = (1-0.1)Ã—3+1 = 3.7ï¼ˆé€‚åº¦å¢å¼ºï¼‰
    # - ä¸­è¡€ç®¡ï¼ˆgt_vessel=0.5ï¼‰ï¼šweight = (1-0.5)Ã—3+1 = 2.5
    # - ç²—è¡€ç®¡ï¼ˆgt_vessel=1.0ï¼‰ï¼šweight = (1-1.0)Ã—3+1 = 1.0
    fine_vessel_boost = 3.0   # ç»†è¡€ç®¡å¢å¼ºç³»æ•°ï¼ˆé™ä½åˆ°3.0ï¼Œç›¸å¯¹è¯¯å·®å·²æä¾›å¹³è¡¡ï¼‰
    base_weight = 1.0         # åŸºç¡€æƒé‡
    vessel_weight_map = (1.0 - gt_vessel_masked) * fine_vessel_boost + base_weight
    
    # èƒŒæ™¯åŒºåŸŸï¼šä½æƒé‡
    background_weight = 0.3  # èƒŒæ™¯æƒé‡ï¼ˆé™ä½åˆ°0.3ï¼‰
    
    # ç»„åˆæƒé‡å›¾
    weight_map = is_vessel * vessel_weight_map + (1.0 - is_vessel) * background_weight  # (B, 1, H, W)
    
    # 7.3 åº”ç”¨æƒé‡
    weighted_diff = relative_diff_squared * weight_map  # (B, 1, H, W)
    
    # 7.4 å½’ä¸€åŒ–æ±‚å¹³å‡ï¼ˆé™¤ä»¥æƒé‡æ€»å’Œï¼Œä¿è¯æ•°å€¼ç¨³å®šï¼‰
    loss = weighted_diff.sum() / (weight_map.sum() + 1e-10)
    

    
    return loss


def get_dynamic_learning_rate(global_step, max_steps, base_lr=5e-5, min_lr=1e-5):
    """
    å­¦ä¹ ç‡å¹³æ»‘è¡°å‡ï¼ˆCosine Annealingï¼‰
    
    step < 4000: lr = 5e-5
    step >= 4000: Cosine è¡°å‡ 5e-5 â†’ 1e-5
    
    è¿”å›: å½“å‰å­¦ä¹ ç‡
    """
    if global_step < 4000:
        return base_lr
    else:
        # Cosine è¡°å‡
        progress = min((global_step - 4000) / (max_steps - 4000), 1.0)
        lr = min_lr + (base_lr - min_lr) * (1 + math.cos(progress * math.pi)) / 2
        return lr


def compute_total_loss(noise_pred, noise, noisy_latents, latents, timesteps, 
                       args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                       return_components=False, vessel_debug_dir=None):
    """
    è®¡ç®—æ€»æŸå¤±ï¼ˆè®­ç»ƒå’ŒéªŒè¯å…±ç”¨ï¼‰
    
    ã€v10-2 æ–°å¢ã€‘å°è£…æŸå¤±è®¡ç®—é€»è¾‘ï¼Œç¡®ä¿è®­ç»ƒå’ŒéªŒè¯ä½¿ç”¨å®Œå…¨ç›¸åŒçš„è®¡ç®—æ–¹å¼
    
    å‚æ•°:
        noise_pred: UNet é¢„æµ‹çš„å™ªå£° (B, 4, H/8, W/8)
        noise: çœŸå®å™ªå£° (B, 4, H/8, W/8)
        noisy_latents: åŠ å™ªåçš„ latents (B, 4, H/8, W/8)
        latents: åŸå§‹ latents (B, 4, H/8, W/8)
        timesteps: æ—¶é—´æ­¥ (B,)
        args: å‘½ä»¤è¡Œå‚æ•°ï¼ˆåŒ…å«å„æŸå¤±æƒé‡ï¼‰
        noise_scheduler: DDPM è°ƒåº¦å™¨
        vae_sf: VAE ç¼©æ”¾å› å­
        msssim_loss_fn: MS-SSIM æŸå¤±å‡½æ•°
        device: è®¾å¤‡
        return_components: æ˜¯å¦è¿”å›å„æŸå¤±åˆ†é‡ï¼ˆé»˜è®¤Falseï¼Œåªè¿”å›æ€»æŸå¤±ï¼‰
        vessel_debug_dir: Vessel Loss è°ƒè¯•å›¾åƒä¿å­˜ç›®å½•ï¼ˆé»˜è®¤Noneï¼Œä¸ä¿å­˜ï¼‰
    
    è¿”å›:
        å¦‚æœ return_components=False: total_loss (æ ‡é‡)
        å¦‚æœ return_components=True: (total_loss, loss_mse, loss_msssim, loss_vessel, loss_grad)
    """
    # ============ 1. MSE æŸå¤±ï¼ˆå™ªå£°ç©ºé—´ï¼Œåº”ç”¨è’™ç‰ˆï¼‰============
    with torch.no_grad():
        # è§£ç GTå›¾åƒåˆ°åƒç´ ç©ºé—´ï¼ˆä»…ç”¨äºæ£€æµ‹é»‘è¾¹ï¼‰
        tgt_imgs_for_mask = vae.decode(latents / vae_sf).sample
        tgt_imgs_0_1 = (tgt_imgs_for_mask.clamp(-1, 1) + 1) / 2
        
        # æ£€æµ‹é»‘è¾¹ï¼šGTçš„é»‘è‰²åƒç´ ï¼ˆé…å‡†è¾¹ç¼˜ï¼‰
        threshold = 0.01
        black_mask_pixel = torch.all(tgt_imgs_0_1 <= threshold, dim=1, keepdim=True)  # (B, 1, H, W)
        valid_mask_pixel = ~black_mask_pixel  # (B, 1, H, W)
        
        # å°†åƒç´ ç©ºé—´è’™ç‰ˆ downsample åˆ° latent ç©ºé—´
        valid_mask_latent = F.interpolate(
            valid_mask_pixel.float(), 
            size=(latents.shape[2], latents.shape[3]),
            mode='nearest'
        )  # (B, 1, H/8, W/8)
        
        # æ‰©å±•åˆ°latentçš„é€šé“æ•°ï¼ˆé€šå¸¸æ˜¯4ï¼‰
        valid_mask_latent = valid_mask_latent.expand(-1, latents.shape[1], -1, -1)  # (B, 4, H/8, W/8)
    
    # åœ¨å™ªå£°ç©ºé—´è®¡ç®—MSEï¼ˆä¿æŒæ‰©æ•£æ¨¡å‹æ ‡å‡†è®­ç»ƒèŒƒå¼ï¼‰
    noise_diff = (noise_pred - noise) ** 2  # (B, 4, H/8, W/8)
    loss_mse = (noise_diff * valid_mask_latent).sum() / (valid_mask_latent.sum() + 1e-10)
    
    # ============ 2. åƒç´ ç©ºé—´æŸå¤±ï¼ˆMS-SSIMã€Vesselã€Gradientï¼‰============
    with torch.no_grad():
        # scheduler.alphas_cumprod is on CPU, need to move to device
        alphas_cumprod = noise_scheduler.alphas_cumprod.to(device)
        alphas_cumprod_t = alphas_cumprod[timesteps].view(-1, 1, 1, 1)
    
    # ä»å™ªå£°é¢„æµ‹ä¸­æ¢å¤ x0 (åŸå§‹å›¾åƒçš„ latent)
    pred_x0_latents = (noisy_latents - (1 - alphas_cumprod_t).sqrt() * noise_pred) / alphas_cumprod_t.sqrt()
    
    # VAE è§£ç åˆ°åƒç´ ç©ºé—´
    with torch.no_grad():
        tgt_imgs = vae.decode(latents / vae_sf).sample  # GTå›¾ï¼ˆä¸éœ€è¦æ¢¯åº¦ï¼‰
    pred_imgs = vae.decode(pred_x0_latents / vae_sf).sample  # é¢„æµ‹å›¾ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
    
    # è½¬æ¢åˆ° [0, 1] èŒƒå›´
    tgt_imgs_0_1 = (tgt_imgs.clamp(-1, 1) + 1) / 2
    pred_imgs_0_1 = (pred_imgs.clamp(-1, 1) + 1) / 2
    
    # åˆ›å»ºåƒç´ ç©ºé—´è’™ç‰ˆï¼ˆç”¨äºSSIMã€Vesselã€Gradientï¼‰
    threshold = 0.01
    black_mask_tgt = torch.all(tgt_imgs_0_1 <= threshold, dim=1, keepdim=True)
    black_mask_pred = torch.all(pred_imgs_0_1 <= threshold, dim=1, keepdim=True)
    valid_mask_pixel_3ch = ~(black_mask_tgt | black_mask_pred)  # (B, 1, H, W)
    valid_mask_pixel_3ch = valid_mask_pixel_3ch.expand(-1, 3, -1, -1).float()  # (B, 3, H, W)
    
    # 3. MS-SSIM æŸå¤±ï¼ˆåƒç´ ç©ºé—´åº”ç”¨è’™ç‰ˆï¼‰
    if args.msssim_lambda > 0:
        # å°†é»‘è¾¹åŒºåŸŸåœ¨ä¸¤å¼ å›¾ä¸Šéƒ½ç½®é›¶ï¼ˆ[0, 1] èŒƒå›´ï¼‰
        tgt_imgs_0_1_masked = tgt_imgs_0_1 * valid_mask_pixel_3ch
        pred_imgs_0_1_masked = pred_imgs_0_1 * valid_mask_pixel_3ch
        
        # è®¡ç®— MS-SSIM æŸå¤±
        loss_msssim = 1 - msssim_loss_fn(pred_imgs_0_1_masked, tgt_imgs_0_1_masked)
    else:
        loss_msssim = torch.tensor(0.0, device=device)
    
    # 4. Vessel æŸå¤±ï¼ˆFrangi + åŠ æƒMSEï¼‰ã€v11-1-unified: ç»Ÿä¸€maskç­–ç•¥ã€‘
    loss_vessel = compute_vessel_loss_weighted_mse(
        pred_imgs, tgt_imgs, 
        mode=args.mode,
        sigmas=FRANGI_SIGMAS,
        alpha=FRANGI_ALPHA, 
        beta=FRANGI_BETA, 
        gamma_cffa=GAMMA_CFFA,
        gamma_cfocta_cf=GAMMA_CFOCTA_CF,
        gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
        gamma_cfoct_cf=GAMMA_CFOCT_CF,
        gamma_oct=GAMMA_CFOCT_OCT,
        debug_dir=vessel_debug_dir  # ä½¿ç”¨ä¼ å…¥çš„è°ƒè¯•ç›®å½•å‚æ•°
    )
    
    # 5. æ¢¯åº¦åŒ¹é…æŸå¤±
    grad_mask = valid_mask_pixel_3ch[:, :1, :, :]
    loss_grad = compute_gradient_match_loss(
        pred_imgs_0_1,
        tgt_imgs_0_1,
        mask=grad_mask,
        reduction='l1'
    )
    
    # 6. ç»„åˆæ€»æŸå¤±
    total_loss = (loss_mse + 
                  args.msssim_lambda * loss_msssim + 
                  args.vessel_lambda * loss_vessel +
                  args.grad_lambda * loss_grad)
    
    if return_components:
        return total_loss, loss_mse, loss_msssim, loss_vessel, loss_grad
    else:
        return total_loss


def run_inference_test(row_data, step_dir, step_num, mode, fixed_seed=42):
    """
    è¿è¡Œæ¨ç†æµ‹è¯•ï¼ˆæ¯500æ­¥ï¼‰- Dual ControlNet ç‰ˆæœ¬ v9 (Scribble + Tile)
    æ”¯æŒ CF-OCTAã€CF-FA å’Œ CF_OCT ä¸‰ç§æ•°æ®é›†
    
    å‚æ•°:
        row_data: CSV è¡Œæ•°æ®å­—å…¸
        step_dir: checkpoint ä¿å­˜ç›®å½•
        step_num: å½“å‰æ­¥æ•°
        mode: è®­ç»ƒæ¨¡å¼ (cf2octa/octa2cf/cf2fa/fa2cf/cf2oct/oct2cf)
        fixed_seed: å›ºå®šçš„éšæœºç§å­
    """
    
    # åˆ›å»ºæ¨ç†æµ‹è¯•ç›®å½•
    infer_dir = os.path.join(step_dir, "inference_test")
    os.makedirs(infer_dir, exist_ok=True)
    
    # åˆ¤æ–­æ•°æ®é›†ç±»å‹
    is_cffa = mode in ["cf2fa", "fa2cf"]
    is_cfoct = mode in ["cf2oct", "oct2cf"]
    
    # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©è·¯å¾„
    if is_cffa:
        # CF-FA æ•°æ®é›†
        cf_path = row_data.get("cf_path")
        fa_path = row_data.get("fa_path")
        
        if mode == "cf2fa":
            src_path = cf_path
            target_path = fa_path
        else:  # fa2cf
            src_path = fa_path
            target_path = cf_path
    elif is_cfoct:
        # CF_OCT æ•°æ®é›†
        cf_path = row_data.get("cf_path")
        oct_path = row_data.get("oct_path")
        
        if mode == "cf2oct":
            src_path = cf_path
            target_path = oct_path
        else:  # oct2cf
            src_path = oct_path
            target_path = cf_path
    else:
        # CF-OCTA æ•°æ®é›†
        cf = row_data.get("cf_path")
        octa = row_data.get("octa_path")
        cond = row_data.get("cond_path")
        tgt = row_data.get("target_path")
        affine_cf_to_octa = row_data.get("affine_cf_to_octa_path", "")
        affine_octa_to_cf = row_data.get("affine_octa_to_cf_path", "")
        
        if mode == "cf2octa":
            src_path = cf or cond
            target_path = octa or tgt
            affine_path = affine_octa_to_cf
        else:  # octa2cf
            src_path = octa or cond
            # éœ€è¦å¯¼å…¥ _strip_seg_prefix_in_path
            from data_loader_cfocta import _strip_seg_prefix_in_path
            target_path = cf or _strip_seg_prefix_in_path(cond or tgt) if (cf or cond or tgt) else None
            affine_path = affine_cf_to_octa
    
    if not src_path or not target_path:
        return
    
    # 1. åŠ è½½åŸå§‹å›¾åƒï¼ˆä¸ resizeï¼Œä¿æŒåŸå§‹åˆ†è¾¨ç‡ï¼‰
    src_img_original = Image.open(src_path).convert("RGB")
    
    # ä¿å­˜åŸå§‹å›¾åƒå°ºå¯¸ï¼ˆç”¨äº CF-FA æ¨¡å¼ resize å›åŸå°ºå¯¸ï¼‰
    original_size = src_img_original.size  # (width, height)
    
    # 2. ã€v10 é‡æ„ã€‘ä½¿ç”¨ç»Ÿä¸€çš„é¢„å¤„ç†æ¥å£
    # è‡ªåŠ¨è¯†åˆ«æ•°æ®é›†ç±»å‹
    if is_cffa:
        dataset_type = 'CFFA'
    elif is_cfoct:
        dataset_type = 'CFOCT'
    else:
        dataset_type = 'CFOCTA'
    
    # ã€v10 æ”¹è¿›ã€‘ä¸€è¡Œä»£ç å®Œæˆæ‰€æœ‰é¢„å¤„ç†ï¼Œæ‰€æœ‰å‚æ•°è‡ªåŠ¨ä»é…ç½®è·å–ï¼
    cond_scribble_pil, cond_tile_pil = preprocess_for_vessel_extraction(
        src_img_original,
        mode=mode,
        dataset_type=dataset_type
    )
    
    # 4. ä¿å­˜é¢„å¤„ç†ç»“æœ
    idx = os.path.splitext(os.path.basename(src_path))[0]
    
    # ç¡®å®šScribbleæƒé‡
    scribble_scale = args.scribble_scale
    
    if is_cffa:
        # CF-FA æ¨¡å¼ï¼šä¿å­˜è°ƒè¯•å›¾åƒ
        # 1. åŸå°ºå¯¸åŸå›¾ï¼ˆ720Ã—576ï¼‰
        src_img_original.save(os.path.join(infer_dir, f"{idx}_00_input_original_{original_size[0]}x{original_size[1]}.png"))
        # 2. 512Ã—512 Scribbleè¡€ç®¡å›¾
        cond_scribble_pil.save(os.path.join(infer_dir, f"{idx}_01_scribble_vessel_512x512.png"))
        # 3. 512Ã—512 åŸå›¾ï¼ˆTileè¾“å…¥ï¼‰
        cond_tile_pil.save(os.path.join(infer_dir, f"{idx}_02_tile_512x512.png"))
    elif is_cfoct:
        # CF_OCT æ¨¡å¼ï¼šä¿å­˜è°ƒè¯•å›¾åƒ
        src_img_original.save(os.path.join(infer_dir, f"{idx}_input_original.png"))
        cond_scribble_pil.save(os.path.join(infer_dir, f"{idx}_condition_vessel.png"))
        cond_tile_pil.save(os.path.join(infer_dir, f"{idx}_condition_tile.png"))
    else:
        # CF-OCTA æ¨¡å¼ï¼šç»Ÿä¸€ä¿å­˜è¡€ç®¡å›¾å’ŒåŸå›¾
        src_img_original.save(os.path.join(infer_dir, f"{idx}_input_original.png"))
        cond_scribble_pil.save(os.path.join(infer_dir, f"{idx}_condition_vessel.png"))
        cond_tile_pil.save(os.path.join(infer_dir, f"{idx}_condition_tile.png"))
    
    # 5. æ„å»ºæ¨ç† pipelineï¼ˆDual ControlNet: Scribble + Tileï¼‰
    controlnet_scribble.eval()
    controlnet_tile.eval()
    
    from diffusers import MultiControlNetModel
    multi_controlnet = MultiControlNetModel([controlnet_scribble, controlnet_tile])
    
    pipe = StableDiffusionControlNetPipeline(
        vae=vae,
        text_encoder=text_encoder,
        tokenizer=tokenizer,
        unet=unet,
        controlnet=multi_controlnet,
        scheduler=noise_scheduler,
        safety_checker=None,
        feature_extractor=None
    )
    
    # 6. è¿è¡Œæ¨ç†ï¼ˆä½¿ç”¨å›ºå®šç§å­ï¼‰
    generator = torch.Generator(device=device).manual_seed(fixed_seed)
    
    with torch.no_grad():
        output = pipe(
            prompt="",
            negative_prompt=None,
            image=[cond_scribble_pil, cond_tile_pil],  # [Scribble, Tile] æ¡ä»¶å›¾
            num_inference_steps=30,
            guidance_scale=7.5,
            controlnet_conditioning_scale=[scribble_scale, args.tile_scale],  # [Scribbleæƒé‡, Tileæƒé‡]
            generator=generator
        )
    
    # 6. ä¿å­˜é¢„æµ‹ç»“æœ
    pred_img = output.images[0]
    
    if is_cffa:
        # CF-FA æ¨¡å¼ï¼šä¿å­˜ 512Ã—512 å’Œ resize å›åŸå°ºå¯¸çš„ç»“æœ
        # 3. 512Ã—512 æ¨ç†ç»“æœ
        pred_img.save(os.path.join(infer_dir, f"{idx}_02_pred_512x512_step{step_num}.png"))
        
        # 4. Resize å›åŸå°ºå¯¸çš„æ¨ç†ç»“æœï¼ˆ720Ã—576ï¼‰
        pred_img_resized = pred_img.resize(original_size)  # resize å›åŸå°ºå¯¸
        pred_img_resized.save(os.path.join(infer_dir, f"{idx}_03_pred_{original_size[0]}x{original_size[1]}_step{step_num}.png"))
    elif is_cfoct:
        # CF_OCT æ¨¡å¼ï¼šä¿å­˜é¢„æµ‹ç»“æœ
        suffix = "pred_oct" if mode == "cf2oct" else "pred_cf"
        pred_img.save(os.path.join(infer_dir, f"{idx}_{suffix}_step{step_num}.png"))
    else:
        # CF-OCTA æ¨¡å¼ï¼šä¿æŒåŸæœ‰é€»è¾‘
        suffix = "pred_octa" if mode == "cf2octa" else "pred_cf"
        pred_img.save(os.path.join(infer_dir, f"{idx}_{suffix}_step{step_num}.png"))
    
    # ã€æ–°å¢ã€‘ä¿å­˜é¢„æµ‹å›¾çš„è¡€ç®¡æå–ç»“æœï¼ˆç”¨äºè°ƒè¯• Vessel Lossï¼‰
    # å°†é¢„æµ‹å›¾è½¬æ¢ä¸ºtorch tensorå¹¶æå–è¡€ç®¡
    pred_img_np = np.array(pred_img).astype(np.float32) / 255.0
    pred_img_torch = torch.from_numpy(pred_img_np).permute(2, 0, 1).unsqueeze(0).to(device)  # (1, 3, H, W)
    
    # ã€v11-1-unifiedã€‘æå–é¢„æµ‹å›¾çš„è¡€ç®¡ï¼ˆç»Ÿä¸€maskç­–ç•¥ï¼šä¸ä½¿ç”¨FOV maskï¼‰
    pred_vessel_map, _ = extract_vessel_map_torch(
        pred_img_torch, mode, 
        gamma_cffa=GAMMA_CFFA,
        gamma_cfocta_cf=GAMMA_CFOCTA_CF,
        gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
        gamma_cfoct_cf=GAMMA_CFOCT_CF,
        gamma_oct=GAMMA_CFOCT_OCT,
        sigmas=FRANGI_SIGMAS,
        alpha=FRANGI_ALPHA,
        beta=FRANGI_BETA,
        fov_threshold=10,
        erode_pixels=0,
        image_border_margin=0,
        apply_fov_mask=False  # ğŸ‘ˆ å…³é—­FOV mask
    )
    
    # ä¿å­˜é¢„æµ‹å›¾çš„è¡€ç®¡å›¾
    pred_vessel_save = (pred_vessel_map[0,0].cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
    Image.fromarray(pred_vessel_save).save(os.path.join(infer_dir, f"{idx}_pred_vessel_step{step_num}.png"))
    
    # 7. åŠ è½½å¹¶å¤„ç†ç›®æ ‡å›¾ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    if is_cffa:
        # CF-FA æ¨¡å¼ï¼šç”Ÿæˆé…å‡†åçš„åŸå°ºå¯¸ç›®æ ‡å›¾
        try:
            target_img_original = Image.open(target_path).convert("RGB")
            
            # åŠ è½½å…³é”®ç‚¹å¹¶è®¡ç®—ä»¿å°„çŸ©é˜µ
            cf_pts_path = row_data.get("cf_pts_path")
            fa_pts_path = row_data.get("fa_pts_path")
            
            if cf_pts_path and fa_pts_path and os.path.exists(cf_pts_path) and os.path.exists(fa_pts_path):
                from registration_cf_fa import load_keypoints, compute_affine_from_points, apply_affine_cffa
                
                # åŠ è½½é…å¯¹ç‚¹
                if mode == "cf2fa":
                    # CFâ†’FA: å°† FA é…å‡†åˆ° CF ç©ºé—´
                    cond_points = load_keypoints(cf_pts_path)
                    tgt_points = load_keypoints(fa_pts_path)
                    affine_matrix = compute_affine_from_points(tgt_points, cond_points)
                else:  # fa2cf
                    # FAâ†’CF: å°† CF é…å‡†åˆ° FA ç©ºé—´
                    cond_points = load_keypoints(fa_pts_path)
                    tgt_points = load_keypoints(cf_pts_path)
                    affine_matrix = compute_affine_from_points(tgt_points, cond_points)
                
                # åœ¨åŸå°ºå¯¸ä¸Šåº”ç”¨é…å‡†ï¼ˆä¸resizeï¼‰
                target_np = np.array(target_img_original)
                h, w = target_np.shape[:2]
                registered_np = cv2.warpAffine(
                    target_np, affine_matrix, (w, h),
                    flags=cv2.INTER_LINEAR,
                    borderMode=cv2.BORDER_CONSTANT,
                    borderValue=(0, 0, 0)
                )
                target_img_registered = Image.fromarray(registered_np)
                
                # 5. ä¿å­˜é…å‡†åçš„åŸå°ºå¯¸ç›®æ ‡å›¾
                target_img_registered.save(os.path.join(infer_dir, f"{idx}_04_target_registered_{original_size[0]}x{original_size[1]}.png"))
                
                # ã€æ–°å¢ã€‘æå–å¹¶ä¿å­˜ç›®æ ‡å›¾çš„è¡€ç®¡
                # Resize åˆ° 512Ã—512 ç”¨äºè¡€ç®¡æå–ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
                target_img_512 = target_img_registered.resize((SIZE, SIZE))
                target_img_np = np.array(target_img_512).astype(np.float32) / 255.0
                target_img_torch = torch.from_numpy(target_img_np).permute(2, 0, 1).unsqueeze(0).to(device)
                
                # ã€v11-1-unifiedã€‘ç»Ÿä¸€maskç­–ç•¥ï¼šä¸ä½¿ç”¨FOV mask
                target_vessel_map, _ = extract_vessel_map_torch(
                    target_img_torch, mode,
                    gamma_cffa=GAMMA_CFFA,
                    gamma_cfocta_cf=GAMMA_CFOCTA_CF,
                    gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                    gamma_cfoct_cf=GAMMA_CFOCT_CF,
                    gamma_oct=GAMMA_CFOCT_OCT,
                    sigmas=FRANGI_SIGMAS,
                    alpha=FRANGI_ALPHA,
                    beta=FRANGI_BETA,
                    fov_threshold=10,
                    erode_pixels=0,
                    image_border_margin=0,
                    apply_fov_mask=False  # ğŸ‘ˆ å…³é—­FOV mask
                )
                
                target_vessel_save = (target_vessel_map[0,0].cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(target_vessel_save).save(os.path.join(infer_dir, f"{idx}_target_vessel_step{step_num}.png"))
                
            else:
                print(f"  âš  å…³é”®ç‚¹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ç›®æ ‡å›¾é…å‡†")
                
        except Exception as e:
            print(f"  âš  CF-FA ç›®æ ‡å›¾é…å‡†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    elif is_cfoct:
        # CF_OCT æ¨¡å¼ï¼šã€v9-2 æ–°æ–¹æ¡ˆã€‘ç›´æ¥åœ¨åŸå§‹åæ ‡ç³»è®¡ç®—ä»¿å°„çŸ©é˜µ
        try:
            target_img_original = Image.open(target_path).convert("RGB")
            
            # ã€v9-2 ä¿®å¤ã€‘åŠ è½½æ¡ä»¶å›¾ï¼ˆç”¨äºè·å–é…å‡†ç›®æ ‡å°ºå¯¸ï¼‰
            src_img_original = Image.open(src_path).convert("RGB")
            
            # åŠ è½½å…³é”®ç‚¹å¹¶è®¡ç®—ä»¿å°„çŸ©é˜µ
            cf_pts_path = row_data.get("cf_pts_path")
            oct_pts_path = row_data.get("oct_pts_path")
            
            if cf_pts_path and oct_pts_path and os.path.exists(cf_pts_path) and os.path.exists(oct_pts_path):
                from registration_cf_oct import register_image_with_keypoints  # v9-2: ç»Ÿä¸€é…å‡†æ¥å£
                
                # ã€v9-2 æ–°æ–¹æ¡ˆã€‘ä½¿ç”¨ç»Ÿä¸€é…å‡†æ¥å£
                tgt_pts_path = oct_pts_path if mode == "cf2oct" else cf_pts_path
                cond_pts_path = cf_pts_path if mode == "cf2oct" else oct_pts_path
                
                # ä½¿ç”¨ç»Ÿä¸€é…å‡†æ¥å£ï¼ˆè‡ªåŠ¨å¤„ç†æ‰€æœ‰é…å‡†æ­¥éª¤ï¼‰
                # ã€å…³é”®ä¿®å¤ã€‘ä¼ é€’æ¡ä»¶å›¾ï¼ˆsrc_img_originalï¼‰ä»¥è·å–æ­£ç¡®çš„é…å‡†ç›®æ ‡å°ºå¯¸
                registered_np = register_image_with_keypoints(
                    np.array(target_img_original),      # å¾…é…å‡†å›¾åƒï¼ˆç›®æ ‡å›¾ï¼‰
                    src_keypoints_path=tgt_pts_path,    # æºå›¾å…³é”®ç‚¹
                    dst_keypoints_path=cond_pts_path,   # ç›®æ ‡å›¾å…³é”®ç‚¹
                    dst_img_for_size=src_img_original,  # ã€ä¿®å¤ã€‘æ¡ä»¶å›¾ï¼ˆç”¨äºè·å–åŸå§‹å°ºå¯¸ï¼‰
                    output_size=(SIZE, SIZE),           # è¾“å‡º512Ã—512
                    method='affine',                    # å®Œæ•´ä»¿å°„å˜æ¢
                    use_ransac=True,
                    ransac_threshold=5.0,
                    interpolation='cubic'
                )
                target_img_registered = Image.fromarray(registered_np)
                
                # ä¿å­˜é…å‡†åçš„å›¾åƒ
                target_img_registered.save(os.path.join(infer_dir, f"{idx}_target_registered.png"))
                target_img_original.save(os.path.join(infer_dir, f"{idx}_target_original.png"))
                
                # ã€æ–°å¢ã€‘æå–å¹¶ä¿å­˜ç›®æ ‡å›¾çš„è¡€ç®¡
                target_img_np = np.array(target_img_registered).astype(np.float32) / 255.0
                target_img_torch = torch.from_numpy(target_img_np).permute(2, 0, 1).unsqueeze(0).to(device)
                
                # ã€v11-1-unifiedã€‘ç»Ÿä¸€maskç­–ç•¥ï¼šä¸ä½¿ç”¨FOV mask
                target_vessel_map, _ = extract_vessel_map_torch(
                    target_img_torch, mode,
                    gamma_cffa=GAMMA_CFFA,
                    gamma_cfocta_cf=GAMMA_CFOCTA_CF,
                    gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                    gamma_cfoct_cf=GAMMA_CFOCT_CF,
                    gamma_oct=GAMMA_CFOCT_OCT,
                    sigmas=FRANGI_SIGMAS,
                    alpha=FRANGI_ALPHA,
                    beta=FRANGI_BETA,
                    fov_threshold=10,
                    erode_pixels=0,
                    image_border_margin=0,
                    apply_fov_mask=False  # ğŸ‘ˆ å…³é—­FOV mask
                )
                
                target_vessel_save = (target_vessel_map[0,0].cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(target_vessel_save).save(os.path.join(infer_dir, f"{idx}_target_vessel_step{step_num}.png"))
                
            else:
                print(f"  âš  å…³é”®ç‚¹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ç›®æ ‡å›¾é…å‡†")
                
        except Exception as e:
            print(f"  âš  CF_OCT ç›®æ ‡å›¾é…å‡†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    else:
        # CF-OCTA æ¨¡å¼ï¼ˆv8-3-2ï¼‰ï¼šç›®æ ‡å›¾ç›´æ¥ä½¿ç”¨åŸå›¾ï¼Œä¸åšé¢„å¤„ç†
        try:
            target_img_original = Image.open(target_path).convert("RGB")
            
            # v8-3-2: CFè®­ç»ƒé›†å·²æ”¹ä¸ºå½©è‰²åŸå›¾ï¼Œç›®æ ‡å›¾ä¸éœ€è¦é¢„å¤„ç†
            # cf2octa: ç›®æ ‡æ˜¯OCTAï¼Œç›´æ¥ä½¿ç”¨åŸå›¾
            # octa2cf: ç›®æ ‡æ˜¯CFï¼Œç›´æ¥ä½¿ç”¨å½©è‰²åŸå›¾ï¼ˆä¸åšç»¿è‰²é€šé“+å–åï¼‰
            target_img_preprocessed = target_img_original
            
            # åº”ç”¨é…å‡†å˜æ¢
            if affine_path and os.path.exists(affine_path):
                affine_matrix = load_affine_matrix(affine_path)
                
                # ç›´æ¥åœ¨å½“å‰å°ºå¯¸ä¸Šåº”ç”¨é…å‡†
                target_np = np.array(target_img_preprocessed)
                registered_np = apply_affine_registration(target_np, affine_matrix)
                target_img_registered = Image.fromarray(registered_np)
            else:
                target_img_registered = target_img_preprocessed
            
            # Resizeåˆ°512Ã—512å¹¶ä¿å­˜
            target_img_512 = target_img_registered.resize((SIZE, SIZE))
            target_img_512.save(os.path.join(infer_dir, f"{idx}_target_registered.png"))
            target_img_original.save(os.path.join(infer_dir, f"{idx}_target_original.png"))
            
            # ã€æ–°å¢ã€‘æå–å¹¶ä¿å­˜ç›®æ ‡å›¾çš„è¡€ç®¡
            target_img_np = np.array(target_img_512).astype(np.float32) / 255.0
            target_img_torch = torch.from_numpy(target_img_np).permute(2, 0, 1).unsqueeze(0).to(device)
            
            # ã€v11-1-unifiedã€‘ç»Ÿä¸€maskç­–ç•¥ï¼šä¸ä½¿ç”¨FOV mask
            target_vessel_map, _ = extract_vessel_map_torch(
                target_img_torch, mode,
                gamma_cffa=GAMMA_CFFA,
                gamma_cfocta_cf=GAMMA_CFOCTA_CF,
                gamma_cfocta_octa=GAMMA_CFOCTA_OCTA,
                gamma_cfoct_cf=GAMMA_CFOCT_CF,
                gamma_oct=GAMMA_CFOCT_OCT,
                sigmas=FRANGI_SIGMAS,
                alpha=FRANGI_ALPHA,
                beta=FRANGI_BETA,
                fov_threshold=10,
                erode_pixels=0,
                image_border_margin=0,
                apply_fov_mask=False  # ğŸ‘ˆ å…³é—­FOV mask
            )
            
            target_vessel_save = (target_vessel_map[0,0].cpu().float().numpy() * 255).clip(0, 255).astype(np.uint8)
            Image.fromarray(target_vessel_save).save(os.path.join(infer_dir, f"{idx}_target_vessel_step{step_num}.png"))
            
        except Exception as e:
            print(f"  âš  ç›®æ ‡å›¾å¤„ç†å¤±è´¥: {e}")
    
    
    # æ¢å¤è®­ç»ƒæ¨¡å¼
    controlnet_scribble.train()
    controlnet_tile.train()


def main():
    # ============ å‚æ•°è§£æ ============
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", 
                        choices=["cf2octa", "octa2cf", "cf2fa", "fa2cf", "cf2oct", "oct2cf"], 
                        default="cf2octa",
                        help="è®­ç»ƒæ¨¡å¼ï¼šcf2octa(CFâ†’OCTA), octa2cf(OCTAâ†’CF), cf2fa(CFâ†’FA), fa2cf(FAâ†’CF), cf2oct(CFâ†’OCT), oct2cf(OCTâ†’CF)")
    parser.add_argument("-n", "--name", dest="name", default='sd15_v6',
                        help="å®éªŒåç§°ï¼ˆç”¨äºç»„ç»‡è¾“å‡ºç›®å½•ï¼‰")
    parser.add_argument("--train_csv", default=None,
                        help="è®­ç»ƒé›†CSVè·¯å¾„ï¼ˆä¸æŒ‡å®šåˆ™æ ¹æ®modeè‡ªåŠ¨é€‰æ‹©ï¼‰")
    parser.add_argument("--val_csv", default=None,
                        help="æµ‹è¯•é›†CSVè·¯å¾„ï¼ˆä¸æŒ‡å®šåˆ™æ ¹æ®modeè‡ªåŠ¨é€‰æ‹©ï¼‰")
    parser.add_argument("--resume_from", type=str, default=None,
                        help="ä»æŒ‡å®šcheckpointæ¢å¤è®­ç»ƒï¼Œä¾‹å¦‚: /path/to/step_6000")
    parser.add_argument("--max_steps", type=int, default=15000,
                        help="æ€»è®­ç»ƒæ­¥æ•°")
    
    # Dual ControlNet å¼ºåº¦å‚æ•°
    parser.add_argument("--scribble_scale", type=float, default=0.8,
                        help="Scribble ControlNet å¼ºåº¦ï¼ˆæ¨è 0.6-1.0ï¼‰")
    parser.add_argument("--tile_scale", type=float, default=1.0,
                        help="Tile ControlNet å¼ºåº¦ï¼ˆæ¨è 0.8-1.2ï¼‰")
    parser.add_argument("--msssim_lambda", type=float, default=0.1,
                        help="MS-SSIM æ„ŸçŸ¥æŸå¤±çš„æƒé‡ (è®¾ä¸º0åˆ™ç¦ç”¨)")
    parser.add_argument("--vessel_lambda", type=float, default=0.5,
                        help="Vessel Loss è¡€ç®¡ç»“æ„æŸå¤±çš„æƒé‡ (v11-1åŠ æƒMSE: æ¨è0.5-2.0, é»˜è®¤0.5)")
    parser.add_argument("--grad_lambda", type=float, default=0.1,
                        help="æ¢¯åº¦åŒ¹é…æŸå¤±çš„æƒé‡ (é»˜è®¤0.1)")
    parser.add_argument("--dynamiclr", "-dlr", action="store_true",
                        help="å¯ç”¨å­¦ä¹ ç‡è¡°å‡ (step<4000: 5e-5, step>=4000: Cosineè¡°å‡ 5e-5â†’1e-5)")
    
    global args
    args, _ = parser.parse_known_args()
    
    # åˆ¤æ–­æ•°æ®é›†ç±»å‹
    is_cffa = args.mode in ["cf2fa", "fa2cf"]
    is_cfoct = args.mode in ["cf2oct", "oct2cf"]
    is_cfocta = args.mode in ["cf2octa", "octa2cf"]
    
    # æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©CSVæ–‡ä»¶
    if args.train_csv is None:
        if is_cffa:
            args.train_csv = CFFA_TRAIN_CSV
            args.val_csv = CFFA_VAL_CSV
        elif is_cfoct:
            args.train_csv = CFOCT_TRAIN_CSV
            args.val_csv = CFOCT_VAL_CSV
        else:  # is_cfocta
            args.train_csv = CFOCTA_TRAIN_CSV
            args.val_csv = CFOCTA_VAL_CSV
    elif args.val_csv is None:
        # å¦‚æœæŒ‡å®šäº†train_csvä½†æ²¡æœ‰val_csvï¼Œè‡ªåŠ¨é€‰æ‹©val_csv
        if is_cffa:
            args.val_csv = CFFA_VAL_CSV
        elif is_cfoct:
            args.val_csv = CFOCT_VAL_CSV
        else:
            args.val_csv = CFOCTA_VAL_CSV
    
    # ç¡®å®šæ•°æ®é›†ç±»å‹åç§°
    if is_cffa:
        dataset_type_name = "CF-FA"
    elif is_cfoct:
        dataset_type_name = "CF_OCT"
    else:
        dataset_type_name = "CF-OCTA"
    

    # è¾“å‡ºç›®å½•
    out_dir = os.path.join(out_root, args.mode, args.name)
    os.makedirs(out_dir, exist_ok=True)

    # ============ æ•°æ®åŠ è½½ï¼ˆv10ï¼šä½¿ç”¨ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ + ç»Ÿä¸€é…ç½®ï¼‰============
    # ã€v10 æ”¹è¿›ã€‘æ‰€æœ‰å¤„ç†å‚æ•°è‡ªåŠ¨ä» data_loader_all.py è·å–ï¼Œä¸éœ€è¦å¤–éƒ¨ä¼ å…¥
    # Single Source of Truthï¼šè®­ç»ƒå’Œæ¨ç†ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°
    train_ds = UnifiedDataset(args.train_csv, args.mode)
    val_ds = UnifiedDataset(args.val_csv, args.mode)
    
    train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, 
                             num_workers=4, drop_last=True)
    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, 
                           num_workers=2, drop_last=False)

    # ============ å‡†å¤‡å›ºå®šçš„æ¨ç†æµ‹è¯•æ ·æœ¬ï¼ˆä»æµ‹è¯•é›†éšæœºæŠ½å–ï¼‰============
    import random
    random.seed(42)  # å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œé€‰åŒä¸€ä¸ªæ ·æœ¬
    
    # ä»æµ‹è¯•é›†CSVä¸­è¯»å–å¹¶éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬
    with open(args.val_csv) as f:
        val_rows = list(csv.DictReader(f))
    
    if len(val_rows) == 0:
        raise ValueError(f"æµ‹è¯•é›†ä¸ºç©º: {args.val_csv}")
    
    fixed_sample_idx = random.randint(0, len(val_rows) - 1)
    fixed_sample_row = val_rows[fixed_sample_idx]
    
    # æ ¹æ®æ¨¡å¼å’Œæ•°æ®é›†ç±»å‹è·å–è·¯å¾„
    if is_cffa:
        # CF-FA æ•°æ®é›†
        if args.mode == "cf2fa":
            src_path = fixed_sample_row.get("cf_path")
            tgt_path = fixed_sample_row.get("fa_path")
        else:  # fa2cf
            src_path = fixed_sample_row.get("fa_path")
            tgt_path = fixed_sample_row.get("cf_path")
    else:
        # CF-OCTA æ•°æ®é›†
        if args.mode == "cf2octa":
            src_path = fixed_sample_row.get("cf_path") or fixed_sample_row.get("cond_path")
            tgt_path = fixed_sample_row.get("octa_path") or fixed_sample_row.get("target_path")
        else:  # octa2cf
            src_path = fixed_sample_row.get("octa_path") or fixed_sample_row.get("cond_path")
            from data_loader_cfocta import _strip_seg_prefix_in_path
            tgt_path = fixed_sample_row.get("cf_path") or _strip_seg_prefix_in_path(
                fixed_sample_row.get("cond_path") or fixed_sample_row.get("target_path")
            )
    

    # ============ SD 1.5 + Dual ControlNet æ¨¡å‹åŠ è½½ ============
    global vae, unet, text_encoder, tokenizer, controlnet_scribble, controlnet_tile, vae_sf, noise_scheduler
    
    resume_step = 0
    
    if args.resume_from:
        resume_dir = args.resume_from.strip()
        if not os.path.isabs(resume_dir):
            resume_dir = os.path.abspath(resume_dir)
        if not os.path.exists(resume_dir):
            raise FileNotFoundError(f"Checkpoint ç›®å½•ä¸å­˜åœ¨: {resume_dir}")
        import re
        match = re.search(r'step_(\d+)', resume_dir)
        if match:
            resume_step = int(match.group(1))
        scribble_path = os.path.join(resume_dir, "controlnet_scribble")
        tile_path = os.path.join(resume_dir, "controlnet_tile")
        controlnet_scribble = ControlNetModel.from_pretrained(
            scribble_path, torch_dtype=torch.float32, local_files_only=True
        ).to(device)
        print(f"  âœ“ Scribble ControlNet åŠ è½½æˆåŠŸ")
        controlnet_tile = ControlNetModel.from_pretrained(
            tile_path, torch_dtype=torch.float32, local_files_only=True
        ).to(device)
        print(f"  âœ“ Tile ControlNet åŠ è½½æˆåŠŸ")
        vae = AutoencoderKL.from_pretrained(
            base_dir, subfolder="vae", local_files_only=True
        ).to(device)
        unet = UNet2DConditionModel.from_pretrained(
            base_dir, subfolder="unet", local_files_only=True
        ).to(device)
        text_encoder = CLIPTextModel.from_pretrained(
            base_dir, subfolder="text_encoder", local_files_only=True
        ).to(device)
        tokenizer = CLIPTokenizer.from_pretrained(
            base_dir, subfolder="tokenizer", local_files_only=True
        )
    else:
        controlnet_scribble = ControlNetModel.from_pretrained(
            ctrl_scribble_dir, local_files_only=True
        ).to(device)
        print(f"âœ“ Scribble ControlNet åŠ è½½å®Œæˆ")
        
        controlnet_tile = ControlNetModel.from_pretrained(
            ctrl_tile_dir, local_files_only=True
        ).to(device)
        print(f"âœ“ Tile ControlNet åŠ è½½å®Œæˆ")
        
        vae = AutoencoderKL.from_pretrained(
            base_dir, subfolder="vae", local_files_only=True
        ).to(device)
        unet = UNet2DConditionModel.from_pretrained(
            base_dir, subfolder="unet", local_files_only=True
        ).to(device)
        text_encoder = CLIPTextModel.from_pretrained(
            base_dir, subfolder="text_encoder", local_files_only=True
        ).to(device)
        tokenizer = CLIPTokenizer.from_pretrained(
            base_dir, subfolder="tokenizer", local_files_only=True
        )

    # å†»ç»“ä¸»å¹²ï¼Œåªè®­ç»ƒ ControlNet
    unet.requires_grad_(False)
    vae.requires_grad_(False)
    text_encoder.requires_grad_(False)
    controlnet_scribble.requires_grad_(True)
    controlnet_tile.requires_grad_(True)

    # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    noise_scheduler = DDPMScheduler.from_pretrained(
        base_dir, subfolder="scheduler", local_files_only=True
    )

    # ä¼˜åŒ–å™¨ï¼šåŒæ—¶ä¼˜åŒ–ä¸¤ä¸ªControlNet
    import itertools
    opt = torch.optim.AdamW(
        itertools.chain(controlnet_scribble.parameters(), controlnet_tile.parameters()), 
        lr=5e-5, weight_decay=1e-2
    )
    mse = nn.MSELoss()
    if args.msssim_lambda > 0:
        msssim_loss_fn = MS_SSIM(data_range=1.0, size_average=True, channel=3).to(device)
    vae_sf = vae.config.scaling_factor

    # æ¢å¤ optimizer
    if args.resume_from:
        optimizer_path = os.path.join(args.resume_from, "optimizer.pt")
        if os.path.exists(optimizer_path):
            opt.load_state_dict(torch.load(optimizer_path))

    # è®¾ç½®è®­ç»ƒæ¨¡å¼
    max_steps = args.max_steps
    global_step = resume_step
    unet.eval()
    vae.eval()
    text_encoder.eval()
    controlnet_scribble.train()
    controlnet_tile.train()

    # è®¡æ—¶å’Œç»Ÿè®¡
    if device.type == "cuda":
        torch.cuda.synchronize()
    t_block = time.time()
    loss_accumulator = []
    msssim_loss_accumulator = []  # v8-3: æ€»æ˜¯åˆå§‹åŒ–
    vessel_loss_accumulator = []  # v8-3: æ–°å¢ (Frangi)
    grad_loss_accumulator = []    # v10-2: æ¢¯åº¦åŒ¹é…æŸå¤±
    
    # ============ æ—©åœæœºåˆ¶ç›¸å…³å˜é‡ ============
    best_val_loss = float("inf")
    best_step = 0
    patience = 8  # v10-3: ä»5æ”¹ä¸º8ï¼Œå¢åŠ è®­ç»ƒè€å¿ƒ
    wait = 0
    best_ckpt_dir = os.path.join(out_dir, "best_checkpoint")
    latest_ckpt_dir = os.path.join(out_dir, "latest_checkpoint")  # æ–°å¢ï¼šæœ€æ–°æ£€æŸ¥ç‚¹ç›®å½•
    validate_every = 500
    early_stopped = False
    min_train_steps = 4000  # v10-3: Warm-upæœŸï¼Œå‰4000æ­¥ä¸è§¦å‘æ—©åœ
    fixed_val_indices = None  # v10-3: å›ºå®šéªŒè¯å­é›†çš„ç´¢å¼•ï¼ˆç¬¬ä¸€æ¬¡éªŒè¯æ—¶åˆå§‹åŒ–ï¼‰

    # ============ éªŒè¯å‡½æ•°ï¼ˆç”¨äºæ—©åœï¼‰ ============
    def evaluate(val_dataset, val_indices=None, num_samples=10):
        """
        åœ¨éªŒè¯é›†ä¸Šè®¡ç®—æ€»æŸå¤±ï¼Œç”¨äºæ—©åœåˆ¤æ–­
        
        ã€v10-3 æ›´æ–°ã€‘ä½¿ç”¨å›ºå®šéªŒè¯å­é›†ï¼Œç¡®ä¿æ¯æ¬¡éªŒè¯çš„æ ·æœ¬ä¸€è‡´
        
        å‚æ•°:
            val_dataset: éªŒè¯é›† Dataset å¯¹è±¡
            val_indices: å›ºå®šçš„éªŒè¯æ ·æœ¬ç´¢å¼•åˆ—è¡¨ï¼ˆå¦‚æœä¸ºNoneåˆ™éšæœºæŠ½å–ï¼‰
            num_samples: é‡‡æ ·æ•°é‡ï¼ˆé»˜è®¤10ä¸ªæ ·æœ¬ï¼‰
        
        è¿”å›:
            avg_total_loss: éªŒè¯é›†å¹³å‡æ€»æŸå¤±
            val_indices: ä½¿ç”¨çš„éªŒè¯ç´¢å¼•ï¼ˆç”¨äºåç»­å¤ç”¨ï¼‰
        """

        print(f"æ­£åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹...")

        
        controlnet_scribble.eval()
        controlnet_tile.eval()
        
        # ã€v10-3 æ–°å¢ã€‘å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡éªŒè¯ï¼Œéšæœºé€‰æ‹©å›ºå®šå­é›†
        if val_indices is None:
            import random
            random.seed(42)  # å›ºå®šç§å­ç¡®ä¿å¯å¤ç°
            total_val_samples = len(val_dataset)
            num_samples = min(num_samples, total_val_samples)
            val_indices = random.sample(range(total_val_samples), num_samples)
            val_indices.sort()  # æ’åºä¾¿äºæŸ¥çœ‹
            print(f"  ã€é¦–æ¬¡éªŒè¯ã€‘éšæœºé€‰æ‹©å›ºå®šéªŒè¯å­é›†: {val_indices}")
        else:
            print(f"  ã€ä½¿ç”¨å›ºå®šå­é›†ã€‘éªŒè¯ç´¢å¼•: {val_indices}")
        
        val_losses = []
        
        with torch.no_grad():
            for idx in val_indices:
                # ä»æ•°æ®é›†ä¸­ç›´æ¥è·å–æŒ‡å®šç´¢å¼•çš„æ ·æœ¬
                batch_data = val_dataset[idx]
                cond_scribble, cond_tile, tgt, cond_path, tgt_path = batch_data
                
                # æ·»åŠ  batch ç»´åº¦å¹¶ç§»åˆ°è®¾å¤‡
                cond_scribble = cond_scribble.unsqueeze(0).to(device)
                cond_tile = cond_tile.unsqueeze(0).to(device)
                tgt = tgt.unsqueeze(0).to(device)
                b = 1
                
                # VAE ç¼–ç 
                latents = encode_vae(tgt)
                noise = torch.randn_like(latents)
                timesteps = torch.randint(
                    0, noise_scheduler.config.num_train_timesteps, 
                    (b,), device=device, dtype=torch.long
                )
                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
                
                # æ–‡æœ¬ç¼–ç 
                prompt_embeds = get_prompt_embeds(b)
                
                # Dual ControlNet å‰å‘ä¼ æ’­
                down_samples_scribble, mid_sample_scribble = controlnet_scribble(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=prompt_embeds,
                    controlnet_cond=cond_scribble,
                    conditioning_scale=args.scribble_scale,
                    return_dict=False
                )
                
                down_samples_tile, mid_sample_tile = controlnet_tile(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=prompt_embeds,
                    controlnet_cond=cond_tile,
                    conditioning_scale=args.tile_scale,
                    return_dict=False
                )
                
                # åˆå¹¶ä¸¤ä¸ªControlNetçš„è¾“å‡º
                down_samples = [
                    d_scribble + d_tile 
                    for d_scribble, d_tile in zip(down_samples_scribble, down_samples_tile)
                ]
                mid_sample = mid_sample_scribble + mid_sample_tile
                
                # UNet é¢„æµ‹å™ªå£°
                noise_pred = unet(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=prompt_embeds,
                    down_block_additional_residuals=down_samples,
                    mid_block_additional_residual=mid_sample
                ).sample
                
                # ============ ã€v10-2 ä¼˜åŒ–ã€‘è°ƒç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° ============
                total_loss = compute_total_loss(
                    noise_pred, noise, noisy_latents, latents, timesteps,
                    args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                    return_components=False
                )
                
                val_losses.append(total_loss.item())
        
        # æ¢å¤è®­ç»ƒæ¨¡å¼
        controlnet_scribble.train()
        controlnet_tile.train()
        
        avg_total_loss = np.mean(val_losses) if len(val_losses) > 0 else float('inf')
        
        print(f"âœ“ éªŒè¯å®Œæˆ éªŒè¯æ ·æœ¬æ•°: {len(val_indices)} å¹³å‡æ€»æŸå¤±: {avg_total_loss:.6f}")

        
        return avg_total_loss, val_indices
    
    # ============ è®­ç»ƒä¿¡æ¯æ‰“å° ============
    print(f"\nâœ“ æ¨¡å‹å·²åŠ è½½: SD 1.5 + Dual ControlNet (Scribble+Tile) v11-1-unified-v2")
    print(f"âœ“ æ•°æ®é›†: {dataset_type_name} | è®­ç»ƒ: {len(train_ds)}æ ·æœ¬ | éªŒè¯: {len(val_ds)}æ ·æœ¬")
    print(f"âœ“ é…ç½®: lr={'5e-5(åŠ¨æ€è¡°å‡)' if args.dynamiclr else '5e-5(å›ºå®š)'}, vessel_Î»={args.vessel_lambda}, msssim_Î»={args.msssim_lambda}, grad_Î»={args.grad_lambda}")
    print(f"âœ“ ControlNet: Scribble={args.scribble_scale}, Tile={args.tile_scale}")
    print(f"âœ“ æ—©åœ: patience={patience} (warm-up={min_train_steps}æ­¥)")
    if args.resume_from:
        print(f"âœ“ æ¢å¤è®­ç»ƒ: step {resume_step} â†’ {max_steps}")
    print(f"âœ“ è¾“å‡ºç›®å½•: {out_dir}\n")

    # ============ è®­ç»ƒå¾ªç¯ ============
    while global_step < max_steps:
        if early_stopped:
            break  # æ—©åœåé€€å‡ºå¤–å±‚å¾ªç¯
        for batch_data in train_loader:
            if global_step >= max_steps:
                break
            
            # æ•°æ®è§£åŒ…ï¼ˆä¸¤ä¸ªæ•°æ®åŠ è½½å™¨è¿”å›æ ¼å¼ç›¸åŒï¼‰
            # CF-FA: [vessel, tile, tgt, paths...]
            # CF-OCTA: [hed, tile, tgt, paths...]
            cond_scribble, cond_tile, tgt, cond_paths, tgt_paths = batch_data
            cond_scribble = cond_scribble.to(device)
            cond_tile = cond_tile.to(device)
            tgt = tgt.to(device)
            b = tgt.shape[0]
            
            # ç¬¬ä¸€æ­¥ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆåŸå›¾ã€é…å‡†å›¾ã€Tileè¾“å…¥ï¼‰
            if global_step == 0:
                debug_dir = os.path.join(out_dir, "debug_images_step0")
                os.makedirs(debug_dir, exist_ok=True)
                
                # æ–‡ä»¶å
                cond_filename = os.path.splitext(os.path.basename(cond_paths[0]))[0]
                tgt_filename = os.path.splitext(os.path.basename(tgt_paths[0]))[0]
                
                # 1. ä¿å­˜Scribbleæ¡ä»¶å›¾ï¼ˆVesselï¼‰
                cond_scribble_save = (cond_scribble[0].cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(cond_scribble_save).save(os.path.join(debug_dir, f"{cond_filename}_scribble_input.png"))
                
                # 2. ä¿å­˜Tileæ¡ä»¶å›¾ï¼ˆåŸå›¾ï¼‰
                cond_tile_save = (cond_tile[0].cpu().float().permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(cond_tile_save).save(os.path.join(debug_dir, f"{cond_filename}_tile_input.png"))
                
                # 3. ä¿å­˜é…å‡†åçš„ç›®æ ‡å›¾
                tgt_save = ((tgt[0].cpu().float().permute(1, 2, 0).numpy() + 1) / 2 * 255).clip(0, 255).astype(np.uint8)
                Image.fromarray(tgt_save).save(os.path.join(debug_dir, f"{tgt_filename}_registered.png"))

            # è®­ç»ƒæ­¥éª¤
            with torch.no_grad():
                # VAE ç¼–ç 
                latents = encode_vae(tgt)
                noise = torch.randn_like(latents)
                timesteps = torch.randint(
                    0, noise_scheduler.config.num_train_timesteps, 
                    (b,), device=device, dtype=torch.long
                )
                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
                
                # æ–‡æœ¬ç¼–ç ï¼ˆç©º promptï¼‰
                prompt_embeds = get_prompt_embeds(b)
            
            # Dual ControlNet å‰å‘ä¼ æ’­
            # 1. Scribble ControlNet (Vesselæˆ–HED)
            down_samples_scribble, mid_sample_scribble = controlnet_scribble(
                noisy_latents,
                timesteps,
                encoder_hidden_states=prompt_embeds,
                controlnet_cond=cond_scribble,  # Scribble æ¡ä»¶ï¼šVesselæˆ–HED
                conditioning_scale=args.scribble_scale,  # Scribble å¼ºåº¦
                return_dict=False
            )
            
            # 2. Tile ControlNet
            down_samples_tile, mid_sample_tile = controlnet_tile(
                noisy_latents,
                timesteps,
                encoder_hidden_states=prompt_embeds,
                controlnet_cond=cond_tile,  # Tile æ¡ä»¶ï¼šåŸå›¾
                conditioning_scale=args.tile_scale,  # Tile å¼ºåº¦
                return_dict=False
            )
            
            # 3. åˆå¹¶ä¸¤ä¸ªControlNetçš„è¾“å‡º
            down_samples = [
                d_scribble + d_tile 
                for d_scribble, d_tile in zip(down_samples_scribble, down_samples_tile)
            ]
            mid_sample = mid_sample_scribble + mid_sample_tile
            
            # UNet é¢„æµ‹å™ªå£°
            noise_pred = unet(
                noisy_latents,
                timesteps,
                encoder_hidden_states=prompt_embeds,
                down_block_additional_residuals=down_samples,
                mid_block_additional_residual=mid_sample
            ).sample
            
            # ============ ã€v10-2 ä¼˜åŒ–ã€‘è°ƒç”¨ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° ============
            # ç¬¬ä¸€æ­¥ä¿å­˜ Vessel Loss è°ƒè¯•å›¾åƒ
            vessel_debug_dir = os.path.join(out_dir, "debug_vessel_loss_step0") if global_step == 0 else None
            
            # è®¡ç®—æ€»æŸå¤±ï¼ˆè¿”å›å„åˆ†é‡ç”¨äºæ—¥å¿—è®°å½•ï¼‰
            loss, loss_mse, loss_msssim, loss_vessel, loss_grad = compute_total_loss(
                noise_pred, noise, noisy_latents, latents, timesteps,
                args, noise_scheduler, vae_sf, msssim_loss_fn, device,
                return_components=True,
                vessel_debug_dir=vessel_debug_dir
            )
            
            # åå‘ä¼ æ’­
            opt.zero_grad(set_to_none=True)
            loss.backward()
            opt.step()
            
            # ============ å­¦ä¹ ç‡ç­–ç•¥ï¼šæ ¹æ® --dynamiclr å‚æ•°å†³å®š ============
            if args.dynamiclr:
                # åŠ¨æ€å­¦ä¹ ç‡è¡°å‡ï¼ˆCosine Annealingï¼‰
                current_lr = get_dynamic_learning_rate(global_step, max_steps)
                for param_group in opt.param_groups:
                    param_group['lr'] = current_lr
            else:
                # å›ºå®šå­¦ä¹ ç‡ 5e-5ï¼ˆæ—©åœæœºåˆ¶ä¾èµ–éªŒè¯æŸå¤±ï¼‰
                current_lr = 5e-5
            
            # ç»Ÿè®¡
            loss_accumulator.append(loss_mse.item())
            if args.msssim_lambda > 0:
                msssim_loss_accumulator.append(loss_msssim.item())
            if args.vessel_lambda > 0:
                vessel_loss_accumulator.append(loss_vessel.item())
            if args.grad_lambda > 0:
                grad_loss_accumulator.append(loss_grad.item())
            global_step += 1
            
            # æ—¥å¿—è¾“å‡ºï¼ˆæ¯100æ­¥ï¼‰
            if global_step % 100 == 0:
                if device.type == "cuda":
                    torch.cuda.synchronize()
                elapsed = time.time() - t_block
                
                # è®¡ç®—å¹³å‡æŸå¤±
                avg_mse = np.mean(loss_accumulator)
                loss_accumulator = []
                
                # è®¡ç®—è¡€ç®¡æŸå¤±å¹³å‡å€¼
                if args.vessel_lambda > 0 and len(vessel_loss_accumulator) > 0:
                    avg_vessel = np.mean(vessel_loss_accumulator)
                    vessel_loss_accumulator = []
                else:
                    avg_vessel = 0.0
                
                if len(msssim_loss_accumulator) > 0:
                    avg_msssim = np.mean(msssim_loss_accumulator)
                    msssim_loss_accumulator = []
                else:
                    avg_msssim = 0.0

                if args.grad_lambda > 0 and len(grad_loss_accumulator) > 0:
                    avg_grad = np.mean(grad_loss_accumulator)
                    grad_loss_accumulator = []
                else:
                    avg_grad = 0.0
                
                t_val = timesteps[0].item()
                
                # æ„å»ºæ—¥å¿—æ¶ˆæ¯
                msg_parts = [f"[step {global_step}/{max_steps}]", f"lr:{current_lr:.2e}", f"mse:{avg_mse:.4f}"]
                if args.vessel_lambda > 0:
                    msg_parts.append(f"vessel:{avg_vessel:.4f}(Î»={args.vessel_lambda})")
                if args.msssim_lambda > 0:
                    msg_parts.append(f"msssim:{avg_msssim:.4f}(Î»={args.msssim_lambda})")
                if args.grad_lambda > 0:
                    msg_parts.append(f"grad:{avg_grad:.4f}(Î»={args.grad_lambda})")
                msg_parts.append(f"{elapsed:.1f}s")
                msg = " | ".join(msg_parts)
                
                print(msg)
                
                # ä¿å­˜æ—¥å¿—åˆ°ç»Ÿä¸€çš„è®­ç»ƒæ—¥å¿—æ–‡ä»¶
                train_log_path = os.path.join(out_dir, "training_log.txt")
                with open(train_log_path, "a") as f:
                    f.write(msg + "\n")
                
                if device.type == "cuda":
                    torch.cuda.synchronize()
                t_block = time.time()
            
            # ============ v10-3: éªŒè¯é›†è¯„ä¼° + æ—©åœæœºåˆ¶ + ä¿å­˜ checkpointï¼ˆæ¯500æ­¥ï¼‰============
            if global_step % validate_every == 0:
                # 1. å…ˆåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼ˆä½¿ç”¨å›ºå®šéªŒè¯å­é›†ï¼‰
                val_loss, fixed_val_indices = evaluate(val_ds, val_indices=fixed_val_indices, num_samples=10)
                
                # 2. åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
                is_best = False
                if val_loss < best_val_loss - 1e-4:
                    best_val_loss = val_loss
                    best_step = global_step
                    wait = 0
                    is_best = True
                    print(f"ğŸ‰ å‘ç°æ–°æœ€ä½³æ¨¡å‹! éªŒè¯æŸå¤±: {best_val_loss:.6f} (step {best_step})")
                else:
                    if global_step >= min_train_steps:
                        wait += 1
                        print(f"[step {global_step}] éªŒè¯æŸå¤±: {val_loss:.6f} | æœ€ä½³: {best_val_loss:.6f} (step {best_step}) | ç­‰å¾…: {wait}/{patience}")
                    else:
                        print(f"[step {global_step}] éªŒè¯æŸå¤±: {val_loss:.6f} (Warm-upæœŸ)")
                
                # 3. ä¿å­˜ latest_checkpointï¼ˆæ¯æ¬¡è¦†ç›–ï¼‰
                os.makedirs(latest_ckpt_dir, exist_ok=True)
                
                controlnet_scribble.save_pretrained(os.path.join(latest_ckpt_dir, "controlnet_scribble"))
                controlnet_tile.save_pretrained(os.path.join(latest_ckpt_dir, "controlnet_tile"))
                torch.save(opt.state_dict(), os.path.join(latest_ckpt_dir, "optimizer.pt"))
                
                with open(os.path.join(latest_ckpt_dir, "latest_info.txt"), "w") as f:
                    f.write(f"Latest Step: {global_step}\n")
                    f.write(f"Validation Loss: {val_loss:.6f}\n")
                    f.write(f"Best Loss: {best_val_loss:.6f} (step {best_step})\n")
                
                # 4. å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜åˆ° best_checkpoint ç›®å½•
                if is_best:
                    os.makedirs(best_ckpt_dir, exist_ok=True)
                    controlnet_scribble.save_pretrained(os.path.join(best_ckpt_dir, "controlnet_scribble"))
                    controlnet_tile.save_pretrained(os.path.join(best_ckpt_dir, "controlnet_tile"))
                    torch.save(opt.state_dict(), os.path.join(best_ckpt_dir, "optimizer.pt"))
                    with open(os.path.join(best_ckpt_dir, "best_info.txt"), "w") as f:
                        f.write(f"Best Step: {best_step}\n")
                        f.write(f"Best Validation Loss: {best_val_loss:.6f}\n")
                    print(f"ğŸ’¾ Best checkpoint å·²ä¿å­˜")
                
                # 5. åˆ›å»ºæ¨ç†æµ‹è¯•ç›®å½•ï¼ˆåªä¿å­˜æ¨ç†å›¾åƒï¼Œä¸ä¿å­˜æƒé‡ï¼‰
                step_inference_dir = os.path.join(out_dir, f"step_{global_step}")
                os.makedirs(step_inference_dir, exist_ok=True)
                
                # 6. è¿è¡Œæ¨ç†æµ‹è¯•ï¼ˆæ¨ç†å›¾ä¿å­˜åˆ° step_XXX ç›®å½•ï¼‰
                run_inference_test(fixed_sample_row, step_inference_dir, global_step, args.mode)
                
                # 7. æ—©åœåˆ¤æ–­ï¼ˆåªåœ¨ warm-up æœŸåè§¦å‘ï¼‰
                if global_step >= min_train_steps and wait >= patience:
                    print(f"\nğŸ›‘ æ—©åœè§¦å‘! éªŒè¯æŸå¤±è¿ç»­{patience}æ¬¡æœªæå‡ | æœ€ä½³: step {best_step} (loss {best_val_loss:.6f})\n")
                    early_stopped = True
                    break  # é€€å‡ºè®­ç»ƒå¾ªç¯

    # ============ è®­ç»ƒå®Œæˆ ============
    print(f"\nâœ… è®­ç»ƒå®Œæˆ | æ€»æ­¥æ•°: {global_step}/{max_steps} {'(æ—©åœ)' if early_stopped else ''}")
    print(f"ğŸ“Š æœ€ä½³æ¨¡å‹: step {best_step} | éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    print(f"ğŸ’¾ Best: {best_ckpt_dir}")
    print(f"ğŸ’¾ Latest: {latest_ckpt_dir}")
    print(f"ğŸ“ è®­ç»ƒæ—¥å¿—: {os.path.join(out_dir, 'training_log.txt')}\n")


if __name__ == "__main__":
    main()

